{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J1wRG8laa8Pm"
   },
   "source": [
    "## Arno's Engram keyboard layout\n",
    "\n",
    "Engram is a key layout optimized for comfortable and efficient touch typing in English \n",
    "created by [Arno Klein](https://binarybottle.com), \n",
    "with [open source code](https://github.com/binarybottle/engram) to create other optimized key layouts.\n",
    "You can install the Engram layout on [Windows, macOS, and Linux](https://keyman.com/keyboards/engram)\n",
    "or [try it out online](https://keymanweb.com/#en,Keyboard_engram).\n",
    "An article is under review (see the [preprint](https://www.preprints.org/manuscript/202103.0287/v1) for an earlier (and superceded) version with description).\n",
    "\n",
    "Letters are optimally arranged according to ergonomics factors that promote reduction of lateral finger movements and more efficient typing of high-frequency letter pairs. The most common punctuation marks are logically grouped together in the middle columns and numbers are paired with mathematical and logic symbols (shown as pairs of default and Shift-key-accessed characters):\n",
    "\n",
    "         [{ 1| 2= 3~ 4+  5<  6>  7^ 8& 9% 0* ]} /\\\n",
    "            bB yY oO uU  '(  \")  lL dD wW VV zZ #$ @`\n",
    "            cC iI eE aA  ,;  .:  hH tT sS nN qQ \n",
    "            gG xX jJ kK  -_  ?!  rR MM fF pP\n",
    "            \n",
    "Letter frequencies (Norvig, 2012), showing that the Engram layout emphasizes keys in the home row:\n",
    "\n",
    "          B   Y   O   U           L   D   W   V    Z\n",
    "          C   I   E   A           H   T   S   N    Q\n",
    "          G   X   J   K           R   M   F   P\n",
    "\n",
    "         53  59 272  97          145 136  60  38   3\n",
    "        119 270 445 287          180 331 232 258   4\n",
    "         67   8   6  19          224  90  86  76\n",
    "            \n",
    "See below for a full description and comparisons with other key layouts.\n",
    "\n",
    "### Standard diagonal keyboard (default and Shift-key layers)\n",
    "![Standard keyboard](https://github.com/binarybottle/engram/blob/master/assets/engram-800px.png?raw=true)\n",
    "\n",
    "### \"Ergonomic\" orthonormal keyboard (default and Shift-key layers)\n",
    "![Orthonormal keyboard](https://github.com/binarybottle/engram/blob/master/assets/engram-ergo-squeezed-800px.png?raw=true)\n",
    "\n",
    "(c) 2021 Arno Klein, MIT license\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "awscg4wBa8Po"
   },
   "source": [
    "# Contents\n",
    "1. [Why a new keyboard layout?](#why)\n",
    "2. [How does Engram compare with other key layouts?](#scores)\n",
    "3. [Guiding criteria](#criteria)\n",
    "4. Setup:\n",
    "    - [Dependencies and functions](#import)\n",
    "    - [Speed matrix](#speed)\n",
    "    - [Strength matrix](#strength)\n",
    "    - [Flow matrix and Engram scoring model](#flow)\n",
    "5. Steps:\n",
    "    - [Step 1: Define the shape of the key layout to minimize lateral finger movements](#step1)\n",
    "    - [Step 2: Arrange the most frequent letters based on comfort and bigram frequencies](#step2)\n",
    "    - [Step 3: Optimize assignment of the remaining letters](#step3)\n",
    "    - [Step 4: Evaluate winning layout](#step4)\n",
    "    - [Step 5: Arrange non-letter characters in easy-to-remember places](#step5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SSdE4O9Wa8Pp"
   },
   "source": [
    "## Why a new keyboard layout? <a name=\"why\">\n",
    "\n",
    "**Personal history** <br>\n",
    "In the future, I hope to include an engaging rationale for why I took on this challenge.\n",
    "Suffice to say I love solving problems, and I have battled repetitive strain injury \n",
    "ever since I worked on an old DEC workstation at the MIT Media Lab while composing \n",
    "my thesis back in the 1990s.\n",
    "I have experimented with a wide variety of human interface technologies over the years --\n",
    "voice dictation, one-handed keyboard, keyless keyboard, foot mouse, and ergonomic keyboards \n",
    "like the Kinesis Advantage and [Ergodox](https://configure.ergodox-ez.com/ergodox-ez/layouts/APXBR/latest/0) keyboards with different key switches.\n",
    "While these technologies can significantly improve comfort and reduce strain, \n",
    "if you have to type on a keyboard, it can only help to use a key layout optimized according to sound ergonomics principles. \n",
    "\n",
    "I have used different key layouts (Qwerty, Dvorak, Colemak, etc.)\n",
    "for communications and for writing and programming projects,\n",
    "and have primarily relied on Colemak for the last 10 years. \n",
    "**I find that most to all of these key layouts:**\n",
    "\n",
    "- Demand too much strain on tendons\n",
    "    - *strenuous lateral extension of the index and little fingers*\n",
    "- Ignore the ergonomics of the human hand\n",
    "    - *different finger strengths*\n",
    "    - *different finger lengths*\n",
    "    - *natural roundedness of the hand*\n",
    "    - *easier for shorter fingers to reach below than above longer fingers*\n",
    "    - *easier for longer fingers to reach above than below shorter fingers*\n",
    "    - *ease of little-to-index finger rolls vs. reverse*\n",
    "- Over-emphasize alternation between hands and under-emphasize same-hand, different-finger transitions\n",
    "    - *same-row, adjacent finger transitions are easy and comfortable*\n",
    "    - *little-to-index finger rolls are easy and comfortable*\n",
    "\n",
    "While I used ergonomics principles outlined below and the accompanying code to help generate the Engram layout,\n",
    "I also relied on massive bigram frequency data for the English language. \n",
    "if one were to follow the procedure below and use a different set of bigram frequencies for another language or text corpus,\n",
    "they could create a variant of the Engram layout, say \"Engram-French\", better suited to the French language.\n",
    "    \n",
    "**Why \"Engram\"?** <br>\n",
    "The name is a pun, referring both to \"n-gram\", letter permutations and their frequencies that are used to compute the Engram layout, and \"engram\", or memory trace, the postulated change in neural tissue to account for the persistence of memory, as a nod to my attempt to make this layout easy to remember."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vkv2v3gla8Pt"
   },
   "source": [
    "## How does Engram compare with other key layouts? <a name=\"scores\">\n",
    "\n",
    "Below we compare the Engram layout with different prominent key layouts (Colemak, Dvorak, QWERTY, etc.) for some large, representative, publicly available data (all text sources are listed below and available on [GitHub](https://github.com/binarybottle/text_data)).\n",
    " \n",
    "#### Engram Scoring Model scores (x100) for layouts, based on publicly available text data\n",
    " \n",
    "Engram scores higher for all text and software sources than all other layouts according to its own scoring model (higher scores are better):\n",
    "    \n",
    "| Layout | Google bigrams | Alice | Memento | Tweets_100K | Tweets_20K | Tweets_MASC | Spoken_MASC | COCA_blogs | iweb | Monkey | Coder | Rosetta |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| Engram | 62.48 | 61.67 | 62.30 | 63.03 | 60.28 | 62.49 | 61.56 | 62.19 | 62.38 | 62.23 | 62.51 | 62.48 |\n",
    "| Halmak | 62.40 | 61.60 | 62.23 | 62.93 | 60.26 | 62.43 | 61.51 | 62.13 | 62.31 | 62.16 | 62.46 | 62.40 |\n",
    "| Hieamtsrn | 62.39 | 61.64 | 62.27 | 62.99 | 60.27 | 62.47 | 61.53 | 62.16 | 62.35 | 62.20 | 62.49 | 62.39 |\n",
    "| Norman | 62.35 | 61.57 | 62.20 | 62.86 | 60.21 | 62.39 | 61.47 | 62.08 | 62.27 | 62.12 | 62.40 | 62.35 |\n",
    "| Workman | 62.37 | 61.59 | 62.22 | 62.91 | 60.23 | 62.41 | 61.49 | 62.10 | 62.29 | 62.14 | 62.43 | 62.37 |\n",
    "| MTGap 2.0 | 62.32 | 61.59 | 62.21 | 62.88 | 60.22 | 62.39 | 61.49 | 62.09 | 62.28 | 62.13 | 62.42 | 62.32 |\n",
    "| QGMLWB | 62.31 | 61.58 | 62.21 | 62.90 | 60.25 | 62.40 | 61.49 | 62.10 | 62.29 | 62.14 | 62.43 | 62.31 |\n",
    "| Colemak Mod-DH | 62.36 | 61.60 | 62.22 | 62.90 | 60.26 | 62.41 | 61.49 | 62.12 | 62.30 | 62.16 | 62.44 | 62.36 |\n",
    "| Colemak | 62.36 | 61.58 | 62.20 | 62.89 | 60.25 | 62.40 | 61.48 | 62.10 | 62.29 | 62.14 | 62.43 | 62.36 |\n",
    "| Asset | 62.34 | 61.56 | 62.18 | 62.86 | 60.25 | 62.37 | 61.46 | 62.07 | 62.25 | 62.10 | 62.39 | 62.34 |\n",
    "| Capewell-Dvorak | 62.29 | 61.56 | 62.17 | 62.86 | 60.20 | 62.36 | 61.47 | 62.06 | 62.24 | 62.10 | 62.37 | 62.29 |\n",
    "| Klausler | 62.34 | 61.58 | 62.20 | 62.89 | 60.25 | 62.39 | 61.48 | 62.09 | 62.27 | 62.12 | 62.41 | 62.34 |\n",
    "| Dvorak | 62.31 | 61.56 | 62.17 | 62.85 | 60.23 | 62.35 | 61.46 | 62.06 | 62.24 | 62.09 | 62.35 | 62.31 |\n",
    "| QWERTY | 62.19 | 61.49 | 62.08 | 62.72 | 60.17 | 62.25 | 61.39 | 61.96 | 62.13 | 61.99 | 62.25 | 62.19 |\n",
    "\n",
    "---\n",
    "    \n",
    "[Keyboard Layout Analyzer](http://patorjk.com/keyboard-layout-analyzer/) (KLA) scores for the same text sources\n",
    "    \n",
    "> The optimal layout score is based on a weighted calculation that factors in the distance your fingers moved (33%), how often you use particular fingers (33%), and how often you switch fingers and hands while typing (34%).\n",
    "    \n",
    "Engram scores highest for 7 of the 9 and second highest for 2 of the 9 text sources; Engram scores third and fourth highest for the two software sources, \"Coder\" and \"Rosetta\" (higher scores are better):\n",
    "\n",
    "| Layout | Alice in Wonderland | Memento screenplay | 100K tweets | 20K tweets | MASC tweets | MASC spoken | COCA blogs | iweb | Monkey | Coder | Rosetta |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| Engram    | 70.13 | 57.16 | 64.64 | 58.58 | 60.24 | 64.39 | 69.66 | 68.25 | 67.66 | 46.81 | 47.69 |\n",
    "| Halmak    | 66.25 | 55.03 | 60.86 | 55.53 | 57.13 | 62.32 | 67.29 | 65.50 | 64.75 | 45.68 | 47.60 |\n",
    "| Hieamtsrn | 69.43 | 56.75 | 64.40 | 58.95 | 60.47 | 64.33 | 69.93 | 69.15 | 68.30 | 46.01 | 46.48 | \n",
    "| Colemak Mod-DH | 65.74 | 54.91 | 60.75 | 54.94 | 57.15 | 61.29 | 67.12 | 65.98 | 64.85 | 47.35 | 48.50 |\n",
    "| Norman    | 62.76 | 52.33 | 57.43 | 53.24 | 53.90 | 59.97 | 62.80 | 60.90 | 59.82 | 43.76 | 46.01 |\n",
    "| Workman   | 64.78 | 54.29 | 59.98 | 55.81 | 56.25 | 61.34 | 65.27 | 63.76 | 62.90 | 45.33 | 47.76 |\n",
    "| MTGAP 2.0 | 66.13 | 53.78 | 59.87 | 55.30 | 55.81 | 60.32 | 65.68 | 63.81 | 62.74 | 45.38 | 44.34 | \n",
    "| QGMLWB    | 65.45 | 54.07 | 60.51 | 56.05 | 56.90 | 62.23 | 66.26 | 64.76 | 63.91 | 46.38 | 45.72 |\n",
    "| Colemak   | 65.83 | 54.94 | 60.67 | 54.97 | 57.04 | 61.36 | 67.14 | 66.01 | 64.91 | 47.30 | 48.65 |\n",
    "| Asset     | 64.60 | 53.84 | 58.66 | 54.72 | 55.35 | 60.81 | 64.71 | 63.17 | 62.44 | 45.54 | 47.52 |\n",
    "| Capewell-Dvorak | 66.94 | 55.66 | 62.14 | 56.85 | 57.99 | 62.83 | 66.95 | 65.23 | 64.70 | 45.30 | 45.62 |\n",
    "| Klausler  | 68.24 | 59.91 | 62.57 | 56.45 | 58.34 | 64.04 | 68.34 | 66.89 | 66.31 | 46.83 | 45.66 |\n",
    "| Dvorak    | 65.86 | 58.18 | 60.93 | 55.56 | 56.59 | 62.75 | 66.64 | 64.87 | 64.26 | 45.46 | 45.55 | \n",
    "| QWERTY    | 53.06 | 43.74 | 48.28 | 44.99 | 44.59 | 51.79 | 52.31 | 50.19 | 49.18 | 38.46 | 39.89 | \n",
    "\n",
    "---\n",
    "\n",
    "#### Keyboard Layout Analyzer consecutive same-finger key presses\n",
    "\n",
    "KLA (and other) distance measures may not accurately reflect natural typing, so below is a more reliable measure of one source of effort and strain -- the tally of consecutive key presses with the same finger for different keys. Engram scores lowest for 6 of the 11 texts, second lowest for two texts, and third or fifth lowest for three texts, two of which are software text sources (lower scores are better):\n",
    "\n",
    "KLA (and other) distance measures may not accurately reflect natural typing, so below is a more reliable measure of one source of effort and strain -- the tally of consecutive key presses with the same finger for different keys. Engram scores lowest for 6 of the 9 and second or third lowest for 3 of the 9 text sources, and third or fifth lowest for the two software text sources (lower scores are better):\n",
    "\n",
    "| Layout | Alice | Memento | Tweets_100K | Tweets_20K | Tweets_MASC | Spoken_MASC | COCA_blogs | iweb | Monkey | Coder | Rosetta |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| Engram | 216 | 11476 | 320406 | 120286 | 7728 | 3514 | 137290 | 1064640 | 37534 | 125798 | 5822 |\n",
    "| Halmak | 498 | 13640 | 484702 | 170064 | 11456 | 5742 | 268246 | 2029634 | 68858 | 144790 | 5392 |\n",
    "| Hieamtsrn | 244 | 12096 | 311000 | 119490 | 8316 | 3192 | 155674 | 1100116 | 40882 | 158698 | 7324 |\n",
    "| Norman | 938 | 20012 | 721602 | 213890 | 16014 | 9022 | 595168 | 3885282 | 135844 | 179752 | 7402 |\n",
    "| Workman | 550 | 13086 | 451280 | 136692 | 10698 | 6156 | 287622 | 1975564 | 71150 | 132526 | 5550 |\n",
    "| MTGap 2.0 | 226 | 14550 | 397690 | 139130 | 10386 | 6252 | 176724 | 1532844 | 58144 | 138484 | 7272 |\n",
    "| QGMLWB | 812 | 17820 | 637788 | 189700 | 14364 | 7838 | 456442 | 3027530 | 100750 | 149366 | 8062 |\n",
    "| Colemak Mod-DH | 362 | 10960 | 352578 | 151736 | 9298 | 4644 | 153984 | 1233770 | 47438 | 117842 | 5328 |\n",
    "| Colemak | 362 | 10960 | 352578 | 151736 | 9298 | 4644 | 153984 | 1233770 | 47438 | 117842 | 5328 |\n",
    "| Asset | 520 | 12519 | 519018 | 155246 | 11802 | 5664 | 332860 | 2269342 | 77406 | 140886 | 6020 |\n",
    "| Capewell-Dvorak | 556 | 14226 | 501178 | 163878 | 12214 | 6816 | 335056 | 2391416 | 78152 | 151194 | 9008 |\n",
    "| Klausler | 408 | 14734 | 455658 | 174998 | 11410 | 5212 | 257878 | 1794604 | 59566 | 135782 | 7444 |\n",
    "| Dvorak | 516 | 13970 | 492604 | 171488 | 12208 | 5912 | 263018 | 1993346 | 64994 | 142084 | 6484 |\n",
    "\n",
    "---\n",
    "  \n",
    "#### Inward roll frequencies \n",
    "Here we tally the number of bigrams (in billions of instances from Norvig's analysis of Google data) that engage inward rolls (little-to-index sequences), within the four columns of one hand, or any column across two hands. Engram scores second highest for 32 keys and highest for 24 keys, where the latter ensures that we are comparing Engram's letters with letters in other layouts (higher scores are better):\n",
    "    \n",
    "Total inward roll frequency in billions\n",
    "\n",
    "    Layout             32 / 24 keys\n",
    "    Engram:          4.64 / 4.51\n",
    "    Halmak:          4.59 / 4.25\n",
    "    Hieamtsrn:       4.69 / 4.16\n",
    "    Norman:          3.99 / 3.61\n",
    "    Workman:         4.16 / 3.63\n",
    "    MTGap 2.0:       3.96 / 3.58\n",
    "    QGMLWB:          4.36 / 2.81\n",
    "    Colemak Mod-DH:  4.15 / 3.51\n",
    "    Colemak:         4.17 / 3.16\n",
    "    Asset:           4.03 / 3.05\n",
    "    Capewell-Dvorak: 4.39 / 3.66\n",
    "    Klausler:        4.42 / 3.52\n",
    "    Dvorak:          4.40 / 3.20\n",
    "    QWERTY:          3.62 / 2.13\n",
    "   \n",
    "---\n",
    "    \n",
    "| Layout | Year | Website |\n",
    "| --- | --- | --- |\n",
    "| Engram | 2021 | https://engram.dev |\n",
    "| [Halmak 2.2](https://keyboard-design.com/letterlayout.html?layout=halmak-2-2.en.ansi) | 2016 | https://github.com/MadRabbit/halmak |\n",
    "| [Hieamtsrn](https://www.keyboard-design.com/letterlayout.html?layout=hieamtsrn.en.ansi) | 2014 | https://mathematicalmulticore.wordpress.com/the-keyboard-layout-project/#comment-4976 |\n",
    "| [Colemak Mod-DH](https://keyboard-design.com/letterlayout.html?layout=colemak-mod-DH-full.en.ansi) | 2014 | https://colemakmods.github.io/mod-dh/ | \n",
    "| [Norman](https://keyboard-design.com/letterlayout.html?layout=norman.en.ansi) | 2013 | https://normanlayout.info/ |\n",
    "| [Workman](https://keyboard-design.com/letterlayout.html?layout=workman.en.ansi) | 2010 | https://workmanlayout.org/ | \n",
    "| [MTGAP 2.0](https://www.keyboard-design.com/letterlayout.html?layout=mtgap-2-0.en.ansi) | 2010 | https://mathematicalmulticore.wordpress.com/2010/06/21/mtgaps-keyboard-layout-2-0/ |\n",
    "| [QGMLWB](https://keyboard-design.com/letterlayout.html?layout=qgmlwb.en.ansi) | 2009 | http://mkweb.bcgsc.ca/carpalx/?full_optimization | \n",
    "| [Colemak](https://keyboard-design.com/letterlayout.html?layout=colemak.en.ansi) | 2006 | https://colemak.com/ | \n",
    "| [Asset](https://keyboard-design.com/letterlayout.html?layout=asset.en.ansi) | 2006 | http://millikeys.sourceforge.net/asset/ | \n",
    "| Capewell-Dvorak | 2004 | http://michaelcapewell.com/projects/keyboard/layout_capewell-dvorak.htm |\n",
    "| [Klausler](https://www.keyboard-design.com/letterlayout.html?layout=klausler.en.ansi) | 2002 | https://web.archive.org/web/20031001163722/http://klausler.com/evolved.html |\n",
    "| [Dvorak](https://keyboard-design.com/letterlayout.html?layout=dvorak.en.ansi) | 1936 | https://en.wikipedia.org/wiki/Dvorak_keyboard_layout | \n",
    "| [QWERTY](https://keyboard-design.com/letterlayout.html?layout=qwerty.en.ansi) | 1873 | https://en.wikipedia.org/wiki/QWERTY |\n",
    "\n",
    "---\n",
    "\n",
    "| Text source | Information |\n",
    "| --- | --- |\n",
    "| \"Alice in Wonderland\" | Alice in Wonderland (Ch.1) |\n",
    "| \"Memento screenplay\" | [Memento screenplay](https://www.dailyscript.com/scripts/memento.html) |\n",
    "| \"100K tweets\" | 100,000 tweets from: [Sentiment140 dataset](https://data.world/data-society/twitter-user-data) training data |\n",
    "| \"20K tweets\" | 20,000 tweets from [Gender Classifier Data](https://www.kaggle.com/crowdflower/twitter-user-gender-classification) |\n",
    "| \"MASC tweets\" | [MASC](http://www.anc.org/data/masc/corpus/) tweets (cleaned of html markup) |\n",
    "| \"MASC spoken\" | [MASC](http://www.anc.org/data/masc/corpus/) spoken transcripts (phone and face-to-face: 25,783 words) |\n",
    "| \"COCA blogs\" | [Corpus of Contemporary American English](https://www.english-corpora.org/coca/) [blog samples](https://www.corpusdata.org/) |\n",
    "| \"Rosetta\" | \"Tower of Hanoi\" (programming languages A-Z from [Rosetta Code](https://rosettacode.org/wiki/Towers_of_Hanoi)) |\n",
    "| \"Monkey text\" | Ian Douglas's English-generated [monkey0-7.txt corpus](https://zenodo.org/record/4642460) |\n",
    "| \"Coder text\" | Ian Douglas's software-generated [coder0-7.txt corpus](https://zenodo.org/record/4642460) |\n",
    "| \"iweb cleaned corpus\" | First 150,000 lines of Shai Coleman's [iweb-corpus-samples-cleaned.txt](https://colemak.com/pub/corpus/iweb-corpus-samples-cleaned.txt.xz) |\n",
    "\n",
    "Reference for Monkey and Coder texts:\n",
    "Douglas, Ian. (2021, March 28). Keyboard Layout Analysis: Creating the Corpus, Bigram Chains, and Shakespeare's Monkeys (Version 1.0.0). Zenodo. http://doi.org/10.5281/zenodo.4642460"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wm3T-hmja8Ps"
   },
   "source": [
    "## Guiding criteria   <a name=\"criteria\">\n",
    "\n",
    "    1.  Assign letters to keys that don't require lateral finger movements.\n",
    "    2.  Promote alternating between hands over uncomfortable same-hand transitions.\n",
    "    3.  Assign the most common letters to the most comfortable keys.\n",
    "    4.  Arrange letters so that more frequent bigrams are easier to type.\n",
    "    5.  Promote little-to-index-finger roll-ins over index-to-little-finger roll-outs.\n",
    "    6.  Balance finger loads according to their relative strength.\n",
    "    7.  Avoid stretching shorter fingers up and longer fingers down.\n",
    "    8.  Avoid using the same finger.\n",
    "    9.  Avoid skipping over the home row.\n",
    "    10. Assign the most common punctuation to keys in the middle of the keyboard.\n",
    "    11. Assign easy-to-remember symbols to the Shift-number keys.\n",
    "    \n",
    "### Factors used to compute the Engram layout <a name=\"factors\">\n",
    "  - **N-gram letter frequencies** <br>\n",
    "    \n",
    "    [Peter Norvig's analysis](http://www.norvig.com/mayzner.html) of data from Google's book scanning project\n",
    "  - **Flow factors** (transitions between ordered key pairs) <br>\n",
    "    These factors are influenced by Dvorak's 11 criteria (1936)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2eTQ4jxPa8Pv"
   },
   "source": [
    "### Import dependencies and functions  <a name=\"import\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load code/engram_variables.py\n",
    "# Print .png figures and .txt text files\n",
    "print_output = False # True\n",
    "\n",
    "# Apply strength data\n",
    "apply_strength = True\n",
    "min_strength_factor = 0.9\n",
    "\n",
    "letters24 = ['E','T','A','O','I','N','S','R','H','L','D','C','U','M','F','P','G','W','Y','B','V','K','X','J']\n",
    "keys24 = [1,2,3,4, 5,6,7,8, 9,10,11,12, 13,14,15,16, 17,18,19,20, 21,22,23,24]\n",
    "instances24 = [4.45155E+11,3.30535E+11,2.86527E+11,2.72277E+11,2.69732E+11,2.57771E+11,\n",
    "               2.32083E+11,2.23768E+11,1.80075E+11,1.44999E+11,1.36018E+11,1.19156E+11,\n",
    "               97273082907,89506734085,85635440629,76112599849,66615316232,59712390260,\n",
    "               59331661972,52905544693,37532682260,19261229433,8369138754,5657910830]                        \n",
    "\n",
    "\n",
    "# Establish which layouts are within a small difference of the top-scoring layout \n",
    "# (the smallest difference between two penalties, 0.9^8 - 0.9^9, in one of 24^2 key pairs):\n",
    "delta = 0.9**8 - 0.9**9\n",
    "factor24 = ((24**2 - 1) + (1-delta)) / (24**2)\n",
    "factor32 = ((32**2 - 1) + (1-delta)) / (32**2)\n",
    "\n",
    "# Establish which layouts are within a small difference of each other when using the speed matrix. \n",
    "# We define an epsilon equal to 13.158 ms for a single bigram (of the 32^2 possible bigrams), \n",
    "# where 13.158 ms is one tenth of 131.58 ms, the fastest measured digraph tapping speed (30,000/228 = 131.58 ms) \n",
    "# recorded in the study: \"Estimation of digraph costs for keyboard layout optimization\", \n",
    "# A Iseri, Ma Eksioglu, International Journal of Industrial Ergonomics, 48, 127-138, 2015.\n",
    "#data_matrix_speed = Speed32x32\n",
    "#time_range = 243  # milliseconds\n",
    "#norm_range = np.max(data_matrix_speed) - np.min(data_matrix_speed)  # 0.6535662299854439\n",
    "#ms_norm = norm_range / time_range  # 0.0026895729629030614\n",
    "#epsilon = 131.58/10 * ms_norm / (32**2)\n",
    "epsilon    = 0.00003549615849447514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "q1wNgX_FDzRH",
    "outputId": "7c14cebc-a4b7-4a77-d14f-26cbc7690c28"
   },
   "outputs": [],
   "source": [
    "# %load code/engram_functions.py\n",
    "# Import dependencies\n",
    "import xlrd\n",
    "import numpy as np\n",
    "from sympy.utilities.iterables import multiset_permutations\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt    \n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def permute_optimize_keys(fixed_letters, fixed_letter_indices, open_letter_indices, \n",
    "                          all_letters, keys, data_matrix, bigrams, bigram_frequencies, \n",
    "                          verbose=False, ntop=0):\n",
    "    \"\"\"\n",
    "    Find all permutations of letters, optimize layout, and generate output.\n",
    "    \"\"\"\n",
    "    matrix_selected = select_keys(data_matrix, keys, verbose=False) \n",
    "    \n",
    "    unassigned_letters = []\n",
    "    for all_letter in all_letters:\n",
    "        if all_letter not in fixed_letters:\n",
    "            unassigned_letters.append(all_letter)\n",
    "            if len(unassigned_letters) == len(open_letter_indices):\n",
    "                break\n",
    "\n",
    "    letter_permutations = permute_letters(unassigned_letters, verbose)\n",
    "    top_permutation, scores = optimize_layout(matrix_selected, bigrams, bigram_frequencies, letter_permutations, open_letter_indices, fixed_letters, fixed_letter_indices, verbose)\n",
    "\n",
    "    if ntop > 0:\n",
    "        print_top_scores(letter_permutations, scores, ntop)\n",
    "    \n",
    "    return top_permutation, letter_permutations, scores\n",
    "\n",
    "\n",
    "def permute_optimize(letters, all_letters, all_keys, data_matrix, bigrams, bigram_frequencies, verbose=False, ntop=0):\n",
    "    \"\"\"\n",
    "    Find all permutations of letters, optimize layout, and generate output.\n",
    "    \"\"\"\n",
    "    matrix_selected = select_keys(data_matrix, all_keys, verbose=False)\n",
    "    open_positions = []\n",
    "    fixed_positions = [] \n",
    "    open_letters = []\n",
    "    fixed_letters = []\n",
    "    assigned_letters = []\n",
    "    for iletter, letter in enumerate(letters):\n",
    "        if letter.strip() == \"\":\n",
    "            open_positions.append(iletter)\n",
    "            for all_letter in all_letters:\n",
    "                if all_letter not in letters and all_letter not in assigned_letters:\n",
    "                    open_letters.append(all_letter)\n",
    "                    assigned_letters.append(all_letter)\n",
    "                    break\n",
    "        else:\n",
    "            fixed_positions.append(iletter)\n",
    "            fixed_letters.append(letter)\n",
    "    #print(open_positions, fixed_positions, open_letters, fixed_letters)\n",
    "    letter_permutations = permute_letters(open_letters, verbose)\n",
    "    top_permutation, scores = optimize_layout(matrix_selected, bigrams, bigram_frequencies, letter_permutations, open_positions, fixed_letters, fixed_positions, verbose)\n",
    "    if ntop > 0:\n",
    "        print_top_scores(letter_permutations, scores, ntop)\n",
    "    \n",
    "    return top_permutation, letter_permutations, scores\n",
    "\n",
    "\n",
    "def select_keys(data_matrix, keys, verbose=False):\n",
    "    \"\"\"\n",
    "    Select keys to quantify pairwise relationships.\n",
    "    \"\"\"\n",
    "    # Extract pairwise entries for the keys:\n",
    "    nkeys = len(keys)\n",
    "    Select = np.zeros((nkeys, nkeys))\n",
    "    u = 0\n",
    "    for i in keys:\n",
    "        u += 1\n",
    "        v = 0\n",
    "        for j in keys:\n",
    "            v += 1\n",
    "            Select[u-1,v-1] = data_matrix[i-1,j-1]\n",
    "\n",
    "    # Normalize matrix with min-max scaling to a range with max 1:\n",
    "    newMin = np.min(Select) / np.max(Select)\n",
    "    newMax = 1.0\n",
    "    Select = newMin + (Select - np.min(Select)) * (newMax - newMin) / (np.max(Select) - np.min(Select))\n",
    "    \n",
    "    if verbose:\n",
    "        #print(\"Matrix:\")\n",
    "        #np.set_printoptions(precision=2); print(Select)\n",
    "\n",
    "        # Heatmap of array\n",
    "        heatmap(data=Select, title=\"Matrix heatmap\", xlabel=\"Key 1\", ylabel=\"Key 2\", print_output=False); plt.show()\n",
    "    \n",
    "    return Select\n",
    "\n",
    "\n",
    "def permute_letters(letters, verbose=False):\n",
    "    \"\"\"\n",
    "    Find all permutations of a given set of letters (max: 8-10 letters).\n",
    "    \"\"\"\n",
    "    letter_permutations = []\n",
    "    for p in multiset_permutations(letters):\n",
    "        letter_permutations.append(p)\n",
    "    letter_permutations = np.array(letter_permutations)\n",
    "    #if verbose:\n",
    "    #    print(\"First permutation: {0}\".format(letter_permutations[0])) \n",
    "    \n",
    "    return letter_permutations\n",
    "\n",
    "\n",
    "def score_layout(data_matrix, letters, bigrams, bigram_frequencies, verbose=False):\n",
    "    \"\"\"\n",
    "    Compute the score for a given letter-key layout (NOTE normalization step).\n",
    "    \"\"\"\n",
    "    # Create a matrix of bigram frequencies:\n",
    "    nletters = len(letters)\n",
    "    F2 = np.zeros((nletters, nletters))\n",
    "\n",
    "    # Find the bigram frequency for each ordered pair of letters in the permutation:\n",
    "    for i1 in range(nletters):\n",
    "        for i2 in range(nletters):\n",
    "            bigram = letters[i1] + letters[i2]\n",
    "            i2gram = np.where(bigrams == bigram)\n",
    "            if np.size(i2gram) > 0:\n",
    "                F2[i1, i2] = bigram_frequencies[i2gram][0]\n",
    "\n",
    "    # Normalize matrices with min-max scaling to a range with max 1:\n",
    "    newMax = 1\n",
    "    minF2 = np.min(F2)\n",
    "    maxF2 = np.max(F2)\n",
    "    newMin2 = minF2 / maxF2\n",
    "    F2 = newMin + (F2 - minF2) * (newMax - newMin2) / (maxF2 - minF2)\n",
    "\n",
    "    # Compute the score for this permutation:\n",
    "    score  = np.average(data_matrix * F2) \n",
    "    if verbose:\n",
    "        print(\"Score for letter permutation {0}: {1}\".format(letters, score))\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def tally_bigrams(input_text, bigrams, normalize=True, verbose=False):\n",
    "    \"\"\"\n",
    "    Compute the score for a given letter-key layout (NOTE normalization step).\n",
    "    \"\"\"   \n",
    "    # Find the bigram frequency for each ordered pair of letters in the input text\n",
    "    #input_text = [str.upper(str(x)) for x in input_text]\n",
    "    input_text = [str.upper(x) for x in input_text]\n",
    "    nchars = len(input_text)\n",
    "    F = np.zeros(len(bigrams))\n",
    "\n",
    "    for ichar in range(0, nchars-1):\n",
    "        bigram = input_text[ichar] + input_text[ichar + 1]\n",
    "        i2gram = np.where(bigrams == bigram)\n",
    "        if np.size(i2gram) > 0:\n",
    "            F[i2gram] += 1\n",
    "\n",
    "    # Normalize matrix with min-max scaling to a range with max 1:\n",
    "    if normalize:\n",
    "        newMax = 1\n",
    "        newMin = np.min(F) / np.max(F)\n",
    "        F = newMin + (F - np.min(F)) * (newMax - newMin) / (np.max(F) - np.min(F))\n",
    "\n",
    "    bigram_frequencies_for_input = F\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Bigram frequencies for input: {0}\".format(bigram_frequencies_for_input))\n",
    "\n",
    "    return bigram_frequencies_for_input\n",
    "\n",
    "\n",
    "def tally_layout_samefinger_bigrams(layout, bigrams, bigram_frequencies, nkeys=32, verbose=False):\n",
    "    \"\"\"\n",
    "    Tally the number of same-finger bigrams within (a list of 24 letters representing) a layout:\n",
    "    ['P','Y','O','U','C','I','E','A','G','K','J','X','M','D','L','B','R','T','N','S','H','V','W','F']\n",
    "    \"\"\"  \n",
    "    if nkeys == 32:\n",
    "        #        Left:            Right:\n",
    "        #    1  2  3  4 25   28 13 14 15 16 31 \n",
    "        #    5  6  7  8 26   29 17 18 19 20 32\n",
    "        #    9 10 11 12 27   30 21 22 23 24\n",
    "        same_finger_keys = [[1,5],[5,9],[1,9], [2,6],[6,10],[2,10], \n",
    "                            [3,7],[7,11],[3,11], [4,8],[8,12],[4,12],\n",
    "                            [25,26],[26,27],[25,27], [28,29],[29,30],[28,30], [31,32],\n",
    "                            [4,25],[4,26],[4,27], [8,25],[8,26],[8,27], [12,25],[12,26],[12,27],\n",
    "                            [13,28],[13,29],[13,30], [17,28],[17,29],[17,30], [21,28],[21,29],[21,30],\n",
    "                            [31,16],[31,20],[31,24], [32,16],[32,20],[32,24],\n",
    "                            [13,17],[17,21],[13,21], [14,18],[18,22],[14,22], \n",
    "                            [15,19],[19,23],[15,23], [16,20],[20,24],[16,24]] \n",
    "    elif nkeys == 24:\n",
    "        #    1  2  3  4         13 14 15 16  \n",
    "        #    5  6  7  8         17 18 19 20 \n",
    "        #    9 10 11 12         21 22 23 24\n",
    "        same_finger_keys = [[1,5],[5,9],[1,9], [2,6],[6,10],[2,10], \n",
    "                            [3,7],[7,11],[3,11], [4,8],[8,12],[4,12],\n",
    "                            [13,17],[17,21],[13,21], [14,18],[18,22],[14,22], \n",
    "                            [15,19],[19,23],[15,23], [16,20],[20,24],[16,24]] \n",
    "\n",
    "    layout = [str.upper(x) for x in layout]\n",
    "    max_frequency = 1.00273E+11\n",
    "\n",
    "    samefinger_bigrams = []\n",
    "    samefinger_bigram_counts = []\n",
    "    for bigram_keys in same_finger_keys:\n",
    "        bigram1 = layout[bigram_keys[0]-1] + layout[bigram_keys[1]-1]\n",
    "        bigram2 = layout[bigram_keys[1]-1] + layout[bigram_keys[0]-1]\n",
    "        i2gram1 = np.where(bigrams == bigram1)\n",
    "        i2gram2 = np.where(bigrams == bigram2)\n",
    "        if np.size(i2gram1) > 0:\n",
    "            samefinger_bigrams.append(bigram1)\n",
    "            samefinger_bigram_counts.append(max_frequency * bigram_frequencies[i2gram1] / np.max(bigram_frequencies))\n",
    "        if np.size(i2gram2) > 0:\n",
    "            samefinger_bigrams.append(bigram2)\n",
    "            samefinger_bigram_counts.append(max_frequency * bigram_frequencies[i2gram2] / np.max(bigram_frequencies))\n",
    "\n",
    "    samefinger_bigrams_total = np.sum(samefinger_bigram_counts)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"    Total same-finger bigram frequencies: {0:15.0f}\".format(samefinger_bigrams_total))\n",
    "\n",
    "    return samefinger_bigrams, samefinger_bigram_counts, samefinger_bigrams_total \n",
    "\n",
    "\n",
    "def tally_layout_bigram_rolls(layout, bigrams, bigram_frequencies, nkeys=32, verbose=False):\n",
    "    \"\"\"\n",
    "    Tally the number of bigrams that engage little-to-index finger inward rolls\n",
    "    for (a list of 24 or 32 letters representing) a layout,\n",
    "    within the four columns of one hand, or any column across two hands.\n",
    "    layout = ['P','Y','O','U','C','I','E','A','G','K','J','X','L','D','B','V','N','T','R','S','H','M','W','F']\n",
    "    bigram_rolls, bigram_roll_counts, bigram_rolls_total = tally_layout_bigram_rolls(layout, bigrams, bigram_frequencies, nkeys=24, verbose=True)\n",
    "    \"\"\"   \n",
    "    if nkeys == 32:\n",
    "        #        Left:            Right:\n",
    "        #    1  2  3  4 25   28 13 14 15 16 31 \n",
    "        #    5  6  7  8 26   29 17 18 19 20 32\n",
    "        #    9 10 11 12 27   30 21 22 23 24\n",
    "\n",
    "        roll_keys = [[1,2],[2,3],[3,4], [5,6],[6,7],[7,8], [9,10],[10,11],[11,12],\n",
    "                    [16,15],[15,14],[14,13], [20,19],[19,18],[18,17], [24,23],[23,22],[22,21],\n",
    "                    [1,3],[2,4],[1,4], [5,7],[6,8],[5,8], [9,11],[10,12],[9,12],\n",
    "                    [16,14],[15,13],[16,13], [20,18],[19,17],[20,17], [24,22],[23,21],[24,21],\n",
    "                    [1,6],[1,7],[1,8],[2,7],[2,8],[3,8], \n",
    "                    [5,2],[5,3],[5,4],[6,3],[6,4],[7,4],\n",
    "                    [5,10],[5,11],[5,12],[6,11],[6,12],[7,12], \n",
    "                    [9,6],[9,7],[9,8],[10,7],[10,8],[11,8],\n",
    "                    [16,19],[16,18],[16,17],[15,18],[15,17],[14,17], \n",
    "                    [20,15],[20,14],[20,13],[19,14],[19,13],[18,13],\n",
    "                    [20,23],[20,22],[20,21],[19,22],[19,21],[18,21], \n",
    "                    [24,19],[24,18],[24,17],[23,18],[23,17],[22,17],\n",
    "                    [1,10],[1,11],[1,12],[2,11],[2,12],[3,12],\n",
    "                    [9,2],[9,3],[9,4],[10,3],[10,4],[11,4],\n",
    "                    [16,23],[16,22],[16,21],[15,22],[15,21],[14,21],\n",
    "                    [24,15],[24,14],[24,13],[23,14],[23,13],[22,13]]\n",
    "        for i in [1,2,3,4,5,6,7,8,9,10,11,12, 25,26,27]:\n",
    "            for j in [13,14,15,16,17,18,19,20,21,22,23,24, 28,29,30,31,32]:\n",
    "                roll_keys.append([i,j])\n",
    "        for i in [13,14,15,16,17,18,19,20,21,22,23,24, 28,29,30,31,32]:\n",
    "            for j in [1,2,3,4,5,6,7,8,9,10,11,12, 25,26,27]:\n",
    "                roll_keys.append([i,j])\n",
    "\n",
    "    elif nkeys == 24:\n",
    "        #    1  2  3  4         13 14 15 16  \n",
    "        #    5  6  7  8         17 18 19 20 \n",
    "        #    9 10 11 12         21 22 23 24\n",
    "        roll_keys = [[1,2],[2,3],[3,4], [5,6],[6,7],[7,8], [9,10],[10,11],[11,12],\n",
    "                    [16,15],[15,14],[14,13], [20,19],[19,18],[18,17], [24,23],[23,22],[22,21],\n",
    "                    [1,3],[2,4],[1,4], [5,7],[6,8],[5,8], [9,11],[10,12],[9,12],\n",
    "                    [16,14],[15,13],[16,13], [20,18],[19,17],[20,17], [24,22],[23,21],[24,21],\n",
    "                    [1,6],[1,7],[1,8],[2,7],[2,8],[3,8], [5,2],[5,3],[5,4],[6,3],[6,4],[7,4],\n",
    "                    [5,10],[5,11],[5,12],[6,11],[6,12],[7,12], [9,6],[9,7],[9,8],[10,7],[10,8],[11,8],\n",
    "                    [16,19],[16,18],[16,17],[15,18],[15,17],[14,17], [20,15],[20,14],[20,13],[19,14],[19,13],[18,13],\n",
    "                    [20,23],[20,22],[20,21],[19,22],[19,21],[18,21], [24,19],[24,18],[24,17],[23,18],[23,17],[22,17],\n",
    "                    [1,10],[1,11],[1,12],[2,11],[2,12],[3,12], [9,2],[9,3],[9,4],[10,3],[10,4],[11,4],\n",
    "                    [16,23],[16,22],[16,21],[15,22],[15,21],[14,21], [24,15],[24,14],[24,13],[23,14],[23,13],[22,13]]\n",
    "        for i in range(0,12):\n",
    "            for j in range(12,24):\n",
    "                roll_keys.append([i,j])\n",
    "        for i in range(12,24):\n",
    "            for j in range(0,12):\n",
    "                roll_keys.append([i,j])\n",
    "\n",
    "    layout = [str.upper(x) for x in layout]\n",
    "    max_frequency = 1.00273E+11\n",
    "\n",
    "    bigram_rolls = []\n",
    "    bigram_roll_counts = []\n",
    "    for bigram_keys in roll_keys:\n",
    "        bigram1 = layout[bigram_keys[0]-1] + layout[bigram_keys[1]-1]\n",
    "        bigram2 = layout[bigram_keys[1]-1] + layout[bigram_keys[0]-1]\n",
    "        i2gram1 = np.where(bigrams == bigram1)\n",
    "        i2gram2 = np.where(bigrams == bigram2)\n",
    "        if np.size(i2gram1) > 0:\n",
    "            bigram_rolls.append(bigram1)\n",
    "            bigram_roll_counts.append(max_frequency * bigram_frequencies[i2gram1] / np.max(bigram_frequencies))\n",
    "        if np.size(i2gram2) > 0:\n",
    "            bigram_rolls.append(bigram2)\n",
    "            bigram_roll_counts.append(max_frequency * bigram_frequencies[i2gram2] / np.max(bigram_frequencies))\n",
    "\n",
    "    bigram_rolls_total = np.sum(bigram_roll_counts)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"    Total bigram inward roll frequencies: {0:15.0f}\".format(bigram_rolls_total))\n",
    "\n",
    "    return bigram_rolls, bigram_roll_counts, bigram_rolls_total \n",
    "\n",
    "\n",
    "def optimize_layout(data_matrix, bigrams, bigram_frequencies, letter_permutations, open_positions, fixed_letters, fixed_positions=[], verbose=False):\n",
    "    \"\"\"\n",
    "    Compute scores for all letter-key layouts.\n",
    "    \"\"\"\n",
    "    iter = 0\n",
    "    top_score = 0\n",
    "    scores = []\n",
    "    use_score_function = False\n",
    "\n",
    "    nletters = len(open_positions) + len(fixed_positions)\n",
    "    top_permutation = np.array(['E' for x in range(nletters)])\n",
    "    F2 = np.zeros((nletters, nletters))\n",
    "\n",
    "    # Loop through the permutations of the selected letters:\n",
    "    for p in letter_permutations:\n",
    "        letters = np.array(['E' for x in range(nletters)])  # KEEP to initialize!\n",
    "        for imove, open_position in enumerate(open_positions):\n",
    "            letters[open_position] = p[imove]\n",
    "        for ifixed, fixed_position in enumerate(fixed_positions):\n",
    "            letters[fixed_position] = fixed_letters[ifixed]\n",
    "\n",
    "        # Compute the score for this permutation:\n",
    "        if use_score_function:\n",
    "            score = score_layout(data_matrix, letters, bigrams, bigram_frequencies, verbose=False)\n",
    "        else:\n",
    "            # Find the bigram frequency for each ordered pair of letters in the permutation:\n",
    "            for i1 in range(nletters):\n",
    "                for i2 in range(nletters):\n",
    "                    bigram = letters[i1] + letters[i2]\n",
    "                    i2gram = np.where(bigrams == bigram)\n",
    "                    if np.size(i2gram) > 0:\n",
    "                        F2[i1, i2] = bigram_frequencies[i2gram][0]\n",
    "\n",
    "            # Normalize matrices with min-max scaling to a range with max 1:\n",
    "            newMax = 1\n",
    "            minF2 = np.min(F2)\n",
    "            maxF2 = np.max(F2)\n",
    "            newMin2 = minF2 / maxF2\n",
    "            F = newMin + (F2 - minF2) * (newMax - newMin2) / (maxF2 - minF2)\n",
    "\n",
    "            # Compute the score for this permutation:\n",
    "            score  = np.average(data_matrix * F) \n",
    "\n",
    "        # Store all scores and the top score and permutation:\n",
    "        scores.append(score)\n",
    "        if score > top_score:\n",
    "            top_score = score\n",
    "            top_permutation = letters\n",
    "            \n",
    "    #print(\"Topmost of {0} permutations: {1}\".format(len(letter_permutations), top_score))\n",
    "    if verbose:\n",
    "        print(\"{0:0.8f}\".format(top_score))\n",
    "        print(*top_permutation)\n",
    "        \n",
    "    return top_permutation, scores\n",
    "\n",
    "\n",
    "def exchange_letters(letters, fixed_letter_indices, all_letters, all_keys, data_matrix, \n",
    "                     bigrams, bigram_frequencies, verbose=True, ntop=0):\n",
    "    \"\"\"\n",
    "    Exchange letters, 8 keys at a time (8! = 40,320) selected twice in 32 different ways:\n",
    "\n",
    "    Indices:\n",
    "         0  1  2  3     12 13 14 15\n",
    "         4  5  6  7     16 17 18 19\n",
    "         8  9 10 11     20 21 22 23 \n",
    "\n",
    "    1. Top rows\n",
    "         0  1  2  3     12 13 14 15\n",
    "    2. Bottom rows\n",
    "         8  9 10 11     20 21 22 23 \n",
    "    3. Top and bottom rows on the right side\n",
    "                        12 13 14 15\n",
    "                        20 21 22 23 \n",
    "    4. Top and bottom rows on the left side \n",
    "         0  1  2  3\n",
    "         8  9 10 11 \n",
    "    5. Top right and bottom left rows\n",
    "                        12 13 14 15\n",
    "         8  9 10 11 \n",
    "    6. Top left and bottom right rows \n",
    "         0  1  2  3\n",
    "                        20 21 22 23 \n",
    "    7. Center of the top and bottom rows on both sides\n",
    "            1  2          13 14\n",
    "            9 10          21 22\n",
    "    8. The eight corners\n",
    "         0        3    12       15\n",
    "         8       11    20       23 \n",
    "    9. Left half of the top and bottom rows on both sides \n",
    "         0  1          12 13\n",
    "         8  9          20 21\n",
    "    10. Right half of the top and bottom rows on both sides\n",
    "               2  3          14 15\n",
    "              10 11          22 23 \n",
    "    11. Left half of non-home rows on the left and right half of the same rows on the right \n",
    "         0  1                14 15\n",
    "         8  9                22 23 \n",
    "    12. Right half of non-home rows on the left and left half of the same rows on the right\n",
    "               2  3    12 13\n",
    "              10 11    20 21 \n",
    "    13. Top center and lower sides\n",
    "            1  2           13 14\n",
    "         8       11     20       23 \n",
    "    14. Top sides and lower center\n",
    "         0        3     12       15\n",
    "            9 10           21 22   \n",
    "    15. Repeat 1-14\n",
    "         \n",
    "    \"\"\"\n",
    "    score = score_layout(data_matrix, letters, bigrams, bigram_frequencies, verbose=False)\n",
    "    print('Initial score: {0}'.format(score)) \n",
    "    print(*letters) \n",
    "    top_permutation = letters\n",
    "\n",
    "    lists_of_open_indices = [\n",
    "        [0,1,2,3,12,13,14,15],\n",
    "        [8,9,10,11,20,21,22,23],\n",
    "        [12,13,14,15,20,21,22,23],\n",
    "        [0,1,2,3,8,9,10,11],\n",
    "        [12,13,14,15,8,9,10,11],\n",
    "        [0,1,2,3,20,21,22,23],\n",
    "        [1,2,13,14,9,10,21,22],\n",
    "        [0,3,12,15,8,11,20,23],\n",
    "        [0,1,12,13,8,9,20,21],\n",
    "        [2,3,14,15,10,11,22,23],\n",
    "        [0,1,14,15,8,9,22,23],\n",
    "        [2,3,12,13,10,11,20,21],\n",
    "        [1,2,8,11,13,14,20,23],\n",
    "        [0,3,9,10,12,15,21,22]  \n",
    "    ]\n",
    "    lists_of_print_statements = [\n",
    "        '1. Top rows',\n",
    "        '2. Bottom rows',\n",
    "        '3. Top and bottom rows on the right side',\n",
    "        '4. Top and bottom rows on the left side',\n",
    "        '5. Top right and bottom left rows',\n",
    "        '6. Top left and bottom right rows',\n",
    "        '7. Center of the top and bottom rows on both sides',\n",
    "        '8. The eight corners',\n",
    "        '9. Left half of the top and bottom rows on both sides',\n",
    "        '10. Right half of the top and bottom rows on both sides',\n",
    "        '11. Left half of non-home rows on the left and right half of the same rows on the right',\n",
    "        '12. Right half of non-home rows on the left and left half of the same rows on the right',\n",
    "        '13. Top center and lower sides',\n",
    "        '14. Top sides and lower center'\n",
    "    ]\n",
    "                         \n",
    "    for istep in [1,2]:\n",
    "        if istep == 1:\n",
    "            s = \"First set of 14 letter exchanges: \"\n",
    "        elif istep == 2:\n",
    "            s = \"Second set of 14 letter exchanges: \"\n",
    "\n",
    "        for ilist, open_indices in enumerate(lists_of_open_indices):\n",
    "            print_statement = lists_of_print_statements[ilist]     \n",
    "\n",
    "            if verbose:\n",
    "                print('{0} {1}'.format(s, print_statement))\n",
    "                             \n",
    "            for open_index in open_indices:\n",
    "                if open_index not in fixed_letter_indices:\n",
    "                    top_permutation[open_index] = ''\n",
    "                    \n",
    "            top_permutation, letter_permutations, scores = permute_optimize(top_permutation, letters24, keys24, data_matrix, bigrams, bigram_frequencies, verbose=True, ntop=0)            \n",
    "            top_permutation = top_permutation.tolist()\n",
    "        \n",
    "    if verbose:\n",
    "        print('')\n",
    "        print('    -------- DONE --------') \n",
    "        print('')\n",
    "\n",
    "    return top_permutation\n",
    "                             \n",
    "\n",
    "def rank_within_epsilon(numbers, epsilon, factor=False, verbose=True):\n",
    "    \"\"\"\n",
    "    numbers = np.array([10,9,8,7,6])\n",
    "    epsilon = 1\n",
    "    rank_within_epsilon(numbers, epsilon, factor=False, verbose=True) \n",
    "    >>> array([1., 1., 2., 2., 3.])\n",
    "    numbers = np.array([0.798900824, 0.79899900824, 0.79900824])\n",
    "    epsilon = 0.9**8 - 0.9**9\n",
    "    factor24 = ((24**2 - 1) + (1-epsilon)) / (24**2) # 0.999925266109375\n",
    "    rank_within_epsilon(numbers, factor24, factor=True, verbose=True) \n",
    "    >>> array([2., 1., 1.])\n",
    "    \"\"\"\n",
    "    numbers = np.array(numbers)\n",
    "    Isort = np.argsort(-numbers)\n",
    "    numbers_sorted = numbers[Isort]\n",
    "    count = 1\n",
    "    ranks = np.zeros(np.size(numbers))\n",
    "    for i, num in enumerate(numbers_sorted):\n",
    "        if ranks[i] == 0:\n",
    "            if factor:\n",
    "                lower_bound = num * epsilon\n",
    "            else:\n",
    "                lower_bound = num - epsilon\n",
    "            bounded_nums1 = num >= numbers_sorted\n",
    "            bounded_nums2 = numbers_sorted >= lower_bound\n",
    "            bounded_nums = bounded_nums1 * bounded_nums2\n",
    "            count += 1\n",
    "            for ibounded, bounded_num in enumerate(bounded_nums):\n",
    "                if bounded_num == True:\n",
    "                    ranks[ibounded] = count\n",
    "\n",
    "    uranks = np.unique(ranks)\n",
    "    nranks = np.size(uranks)\n",
    "    new_ranks = ranks.copy()\n",
    "    new_count = 0\n",
    "    for rank in uranks:\n",
    "        new_count += 1\n",
    "        same_ranks = ranks == rank\n",
    "        for isame, same_rank in enumerate(same_ranks):\n",
    "            if same_rank == True:\n",
    "                new_ranks[isame] = new_count\n",
    "\n",
    "    #ranks_sorted = new_ranks[Isort]\n",
    "    ranks_sorted = [np.int(x) for x in new_ranks]\n",
    "    \n",
    "    if verbose:\n",
    "        for i, num in enumerate(numbers_sorted):\n",
    "            print(\"    ({0})    {1}\".format(np.int(ranks_sorted[i]), num))\n",
    "        \n",
    "    return numbers_sorted, ranks_sorted, Isort\n",
    "\n",
    "\n",
    "def print_top_scores(letter_permutations, scores, ntop):\n",
    "    \"\"\"\n",
    "    Print top-scored letter permutations.\n",
    "    \"\"\"\n",
    "    scores_negative = -np.array(scores)\n",
    "    isort = np.argsort(scores_negative)[:ntop]\n",
    "    sorted_scores = [scores[isort[x]] for x in range(len(isort))]\n",
    "    sorted_letter_permutations = [letter_permutations[isort[x]].tolist() for x in range(len(isort))]\n",
    "    for ix, x in enumerate(sorted_letter_permutations):\n",
    "        print(\"{0:0.8f}\".format(sorted_scores[ix]))\n",
    "        print(*x)\n",
    "    \n",
    "def print_matrix_info(matrix_data, matrix_label, nkeys, nlines=10):\n",
    "    \"\"\"\n",
    "    Print matrix output.\n",
    "    \"\"\"\n",
    "    print(\"{0} min = {1}, max = {2}\".format(matrix_label, np.min(matrix_data), np.max(matrix_data)))\n",
    "    matrix_flat = matrix_data.flatten()\n",
    "    argsort = np.argsort(matrix_flat)\n",
    "    print(\"{0} key number pairs with minimum values:\".format(matrix_label))\n",
    "    for x in argsort[0:nlines]:\n",
    "        if x % nkeys == 0:\n",
    "            min_row = np.int(np.ceil(x / nkeys)) + 1\n",
    "            min_col = 1\n",
    "        else:\n",
    "            min_row = np.int(np.ceil(x / nkeys))\n",
    "            min_col = x - nkeys * (min_row-1) + 1                \n",
    "        print(\"        {0} -> {1}        ({2})\".format(min_row, min_col, matrix_flat[x]))\n",
    "    print(\"{0} key number pairs with maximum values:\".format(matrix_label))\n",
    "    max_sort = argsort[-nlines::]\n",
    "    for x in max_sort[::-1]:\n",
    "        if x % nkeys == 0:\n",
    "            max_row = np.int(np.ceil(x / nkeys)) + 1\n",
    "            max_col = 1\n",
    "        else:\n",
    "            max_row = np.int(np.ceil(x / nkeys))\n",
    "            max_col = x - nkeys * (max_row-1) + 1                \n",
    "        print(\"        {0} -> {1}        ({2})\".format(max_row, max_col, matrix_flat[x]))\n",
    "\n",
    "\n",
    "def heatmap(data, title=\"\", xlabel=\"\", ylabel=\"\", x_axis_labels=[], y_axis_labels=[], print_output=True):\n",
    "    \"\"\"\n",
    "    Plot heatmap of matrix.\n",
    "    \"\"\"\n",
    "    # use heatmap function, set the color as viridis and\n",
    "    # make each cell seperate using linewidth parameter\n",
    "    plt.figure()\n",
    "    sns_plot = sns.heatmap(data, xticklabels=x_axis_labels, yticklabels=y_axis_labels, linewidths=1, \n",
    "                           cmap=\"viridis\", square=True, vmin=np.min(data), vmax=np.max(data))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    sns_plot.set_xticklabels(x_axis_labels)  #, rotation=75) \n",
    "    sns_plot.set_yticklabels(y_axis_labels) \n",
    "    if print_output:\n",
    "        sns_plot.figure.savefig(\"{0}_heatmap.png\".format(title))\n",
    "        \n",
    "    \n",
    "def histmap(data, title=\"\", print_output=True):\n",
    "    \"\"\"\n",
    "    Plot histogram.\n",
    "    \"\"\"\n",
    "    sns.distplot(data)\n",
    "    plt.title(title)\n",
    "    if print_output:\n",
    "        sns_plot.figure.savefig(\"{0}_histogram.png\".format(title))\n",
    "        \n",
    "        \n",
    "def print_layout24(layout):\n",
    "    \"\"\"\n",
    "    Print layout.\n",
    "    \"\"\"   \n",
    "    print('    {0}  {1}'.format(' '.join(layout[0:4]),\n",
    "                                ' '.join(layout[12:16])))\n",
    "    print('    {0}  {1}'.format(' '.join(layout[4:8]),\n",
    "                                ' '.join(layout[16:20])))\n",
    "    print('    {0}  {1}'.format(' '.join(layout[8:12]),\n",
    "                                ' '.join(layout[20:24])))\n",
    "\n",
    "\n",
    "def print_layout24_instances(layout, letters24, instances24, bigrams, bigram_frequencies):\n",
    "    \"\"\"\n",
    "    Print billions of instances per letter (not Z or Q) in layout form.\n",
    "    layout = ['P','Y','O','U','C','I','E','A','G','K','J','X','M','D','L','B','R','T','N','S','H','V','W','F']\n",
    "    print_layout24_instances(layout, letters24, instances24, bigrams, bigram_frequencies)\n",
    "    \"\"\"\n",
    "    layout_instances = []\n",
    "    layout_instances_strings = []\n",
    "    for letter in layout:\n",
    "        index = letters24.index(letter)\n",
    "        layout_instances.append(instances24[index])\n",
    "        layout_instances_strings.append('{0:3.0f}'.format(instances24[index]/1000000000))\n",
    " \n",
    "    print('    {0}  {1}'.format(' '.join(layout_instances_strings[0:4]),\n",
    "                                ' '.join(layout_instances_strings[12:16])))\n",
    "    print('    {0}  {1}'.format(' '.join(layout_instances_strings[4:8]),\n",
    "                                ' '.join(layout_instances_strings[16:20])))\n",
    "    print('    {0}  {1}'.format(' '.join(layout_instances_strings[8:12]),\n",
    "                                ' '.join(layout_instances_strings[20:24])))\n",
    "    left_sum = np.sum(layout_instances[0:12])/1000000000000\n",
    "    right_sum = np.sum(layout_instances[12:24])/1000000000000\n",
    "    pL = ''\n",
    "    pR = ''\n",
    "    if left_sum > right_sum:\n",
    "        pL = ' ({0:3.2f}%)'.format(100 * (left_sum - right_sum) / right_sum)\n",
    "    elif right_sum > left_sum:\n",
    "        pR = ' ({0:3.2f}%)'.format(100 * (right_sum - left_sum) / left_sum)\n",
    "    \n",
    "    print('\\n    left: {0:3.3f}T{1}  right: {2:3.3f}T{3}'.format(left_sum, pL, \n",
    "                                                                 right_sum, pR))\n",
    "    \n",
    "    tally_layout_samefinger_bigrams(layout, bigrams, bigram_frequencies, nkeys=24, verbose=True)\n",
    "    tally_layout_bigram_rolls(layout, bigrams, bigram_frequencies, nkeys=24, verbose=True)\n",
    "   \n",
    "\n",
    "def print_bigram_frequency(input_pair, bigrams, bigram_frequencies):\n",
    "    \"\"\"\n",
    "    >>> print_bigram_frequency(['t','h'], bigrams, bigram_frequencies)\n",
    "    \"\"\"\n",
    "    # Find the bigram frequency\n",
    "    max_frequency = 1.00273E+11\n",
    "    input_text = [str.upper(str(x)) for x in input_pair]\n",
    "    nchars = len(input_text)\n",
    "    for ichar in range(0, nchars-1):\n",
    "        bigram1 = input_text[ichar] + input_text[ichar + 1]\n",
    "        bigram2 = input_text[ichar + 1] + input_text[ichar]\n",
    "        i2gram1 = np.where(bigrams == bigram1)\n",
    "        i2gram2 = np.where(bigrams == bigram2)\n",
    "        if np.size(i2gram1) > 0:\n",
    "            freq1 = max_frequency/1e9 * bigram_frequencies[i2gram1[0][0]]\n",
    "            print(\"{0}: {1:3.2f}B\".format(bigram1, freq1))\n",
    "        if np.size(i2gram2) > 0:\n",
    "            freq2 = max_frequency/1e9 * bigram_frequencies[i2gram2[0][0]]\n",
    "            print(\"{0}: {1:3.2f}B\".format(bigram2, freq2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rFiySi8rDzRN"
   },
   "source": [
    "### Bigram frequencies <a name=\"ngrams\">\n",
    "\n",
    "[Peter Norvig's ngrams table](http://www.norvig.com/mayzner.html](http://www.norvig.com/mayzner.html)\n",
    "    \n",
    "[NOTE: If you want to compute an optimized layout for another language, or based on another corpus, you can run the tally_bigrams() function above and replace bigram_frequencies below before running the rest of the code.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K68F0fkqDzRO"
   },
   "outputs": [],
   "source": [
    "# %load code/load_bigram_frequencies.py\n",
    "load_original_ngram_files = False\n",
    "if load_original_ngram_files:\n",
    "    ngrams_table = \"data/bigrams-trigrams-frequencies.xlsx\"\n",
    "    wb = xlrd.open_workbook(ngrams_table) \n",
    "    ngrams_sheet = wb.sheet_by_index(0)\n",
    "    # 1-grams and frequencies\n",
    "    onegrams = np.array(())\n",
    "    onegram_frequencies = np.array(())\n",
    "    i = 0\n",
    "    start1 = 0\n",
    "    stop1 = 0\n",
    "    while stop1 == 0:\n",
    "        if ngrams_sheet.cell_value(i, 0) == \"2-gram\":\n",
    "            stop1 = 1\n",
    "        elif ngrams_sheet.cell_value(i, 0) == \"1-gram\":\n",
    "            start1 = 1\n",
    "        elif start1 == 1:\n",
    "            onegrams = np.append(onegrams, ngrams_sheet.cell_value(i, 0))\n",
    "            onegram_frequencies = np.append(onegram_frequencies, ngrams_sheet.cell_value(i, 1))\n",
    "        i += 1\n",
    "    onegram_frequencies = onegram_frequencies / np.sum(onegram_frequencies)\n",
    "\n",
    "    # 2-grams and frequencies\n",
    "    bigrams = np.array(())\n",
    "    bigram_frequencies = np.array(())\n",
    "    i = 0\n",
    "    start1 = 0\n",
    "    stop1 = 0\n",
    "    while stop1 == 0:\n",
    "        if ngrams_sheet.cell_value(i, 0) == \"3-gram\":\n",
    "            stop1 = 1\n",
    "        elif ngrams_sheet.cell_value(i, 0) == \"2-gram\":\n",
    "            start1 = 1\n",
    "        elif start1 == 1:\n",
    "            bigrams = np.append(bigrams, ngrams_sheet.cell_value(i, 0))\n",
    "            bigram_frequencies = np.append(bigram_frequencies, ngrams_sheet.cell_value(i, 1))\n",
    "        i += 1\n",
    "    bigram_frequencies = bigram_frequencies / np.sum(bigram_frequencies)\n",
    "\n",
    "    # Save:\n",
    "    if print_output:\n",
    "        file = open(\"onegrams.txt\", \"w+\")\n",
    "        file.write(str(onegrams))\n",
    "        file.close()\n",
    "        file = open(\"onegram_frequencies.txt\", \"w+\")\n",
    "        file.write(str(onegram_frequencies))\n",
    "        file.close()\n",
    "        file = open(\"bigrams.txt\", \"w+\")\n",
    "        file.write(str(bigrams))\n",
    "        file.close()\n",
    "        file = open(\"bigram_frequencies.txt\", \"w+\")\n",
    "        file.write(str(bigram_frequencies))\n",
    "        file.close()\n",
    "\n",
    "    # Print:\n",
    "    print(repr(onegrams))\n",
    "    print(repr(onegram_frequencies))\n",
    "    print(repr(bigrams))\n",
    "    print(repr(bigram_frequencies))\n",
    "\n",
    "else:\n",
    "    onegrams = np.array(['E', 'T', 'A', 'O', 'I', 'N', 'S', 'R', 'H', 'L', 'D', 'C', 'U',\n",
    "       'M', 'F', 'P', 'G', 'W', 'Y', 'B', 'V', 'K', 'X', 'J', 'Q', 'Z'],\n",
    "      dtype='<U32')\n",
    "    onegram_frequencies = np.array([0.12492063, 0.09275565, 0.08040605, 0.07640693, 0.07569278,\n",
    "       0.07233629, 0.06512767, 0.06279421, 0.05053301, 0.04068986,\n",
    "       0.03816958, 0.03343774, 0.02729702, 0.02511761, 0.02403123,\n",
    "       0.02135891, 0.01869376, 0.01675664, 0.0166498 , 0.01484649,\n",
    "       0.01053252, 0.00540513, 0.00234857, 0.00158774, 0.00120469,\n",
    "       0.00089951])\n",
    "    bigrams = np.array(['TH', 'HE', 'IN', 'ER', 'AN', 'RE', 'ON', 'AT', 'EN', 'ND', 'TI',\n",
    "       'ES', 'OR', 'TE', 'OF', 'ED', 'IS', 'IT', 'AL', 'AR', 'ST', 'TO',\n",
    "       'NT', 'NG', 'SE', 'HA', 'AS', 'OU', 'IO', 'LE', 'VE', 'CO', 'ME',\n",
    "       'DE', 'HI', 'RI', 'RO', 'IC', 'NE', 'EA', 'RA', 'CE', 'LI', 'CH',\n",
    "       'LL', 'BE', 'MA', 'SI', 'OM', 'UR', 'CA', 'EL', 'TA', 'LA', 'NS',\n",
    "       'DI', 'FO', 'HO', 'PE', 'EC', 'PR', 'NO', 'CT', 'US', 'AC', 'OT',\n",
    "       'IL', 'TR', 'LY', 'NC', 'ET', 'UT', 'SS', 'SO', 'RS', 'UN', 'LO',\n",
    "       'WA', 'GE', 'IE', 'WH', 'EE', 'WI', 'EM', 'AD', 'OL', 'RT', 'PO',\n",
    "       'WE', 'NA', 'UL', 'NI', 'TS', 'MO', 'OW', 'PA', 'IM', 'MI', 'AI',\n",
    "       'SH', 'IR', 'SU', 'ID', 'OS', 'IV', 'IA', 'AM', 'FI', 'CI', 'VI',\n",
    "       'PL', 'IG', 'TU', 'EV', 'LD', 'RY', 'MP', 'FE', 'BL', 'AB', 'GH',\n",
    "       'TY', 'OP', 'WO', 'SA', 'AY', 'EX', 'KE', 'FR', 'OO', 'AV', 'AG',\n",
    "       'IF', 'AP', 'GR', 'OD', 'BO', 'SP', 'RD', 'DO', 'UC', 'BU', 'EI',\n",
    "       'OV', 'BY', 'RM', 'EP', 'TT', 'OC', 'FA', 'EF', 'CU', 'RN', 'SC',\n",
    "       'GI', 'DA', 'YO', 'CR', 'CL', 'DU', 'GA', 'QU', 'UE', 'FF', 'BA',\n",
    "       'EY', 'LS', 'VA', 'UM', 'PP', 'UA', 'UP', 'LU', 'GO', 'HT', 'RU',\n",
    "       'UG', 'DS', 'LT', 'PI', 'RC', 'RR', 'EG', 'AU', 'CK', 'EW', 'MU',\n",
    "       'BR', 'BI', 'PT', 'AK', 'PU', 'UI', 'RG', 'IB', 'TL', 'NY', 'KI',\n",
    "       'RK', 'YS', 'OB', 'MM', 'FU', 'PH', 'OG', 'MS', 'YE', 'UD', 'MB',\n",
    "       'IP', 'UB', 'OI', 'RL', 'GU', 'DR', 'HR', 'CC', 'TW', 'FT', 'WN',\n",
    "       'NU', 'AF', 'HU', 'NN', 'EO', 'VO', 'RV', 'NF', 'XP', 'GN', 'SM',\n",
    "       'FL', 'IZ', 'OK', 'NL', 'MY', 'GL', 'AW', 'JU', 'OA', 'EQ', 'SY',\n",
    "       'SL', 'PS', 'JO', 'LF', 'NV', 'JE', 'NK', 'KN', 'GS', 'DY', 'HY',\n",
    "       'ZE', 'KS', 'XT', 'BS', 'IK', 'DD', 'CY', 'RP', 'SK', 'XI', 'OE',\n",
    "       'OY', 'WS', 'LV', 'DL', 'RF', 'EU', 'DG', 'WR', 'XA', 'YI', 'NM',\n",
    "       'EB', 'RB', 'TM', 'XC', 'EH', 'TC', 'GY', 'JA', 'HN', 'YP', 'ZA',\n",
    "       'GG', 'YM', 'SW', 'BJ', 'LM', 'CS', 'II', 'IX', 'XE', 'OH', 'LK',\n",
    "       'DV', 'LP', 'AX', 'OX', 'UF', 'DM', 'IU', 'SF', 'BT', 'KA', 'YT',\n",
    "       'EK', 'PM', 'YA', 'GT', 'WL', 'RH', 'YL', 'HS', 'AH', 'YC', 'YN',\n",
    "       'RW', 'HM', 'LW', 'HL', 'AE', 'ZI', 'AZ', 'LC', 'PY', 'AJ', 'IQ',\n",
    "       'NJ', 'BB', 'NH', 'UO', 'KL', 'LR', 'TN', 'GM', 'SN', 'NR', 'FY',\n",
    "       'MN', 'DW', 'SB', 'YR', 'DN', 'SQ', 'ZO', 'OJ', 'YD', 'LB', 'WT',\n",
    "       'LG', 'KO', 'NP', 'SR', 'NQ', 'KY', 'LN', 'NW', 'TF', 'FS', 'CQ',\n",
    "       'DH', 'SD', 'VY', 'DJ', 'HW', 'XU', 'AO', 'ML', 'UK', 'UY', 'EJ',\n",
    "       'EZ', 'HB', 'NZ', 'NB', 'MC', 'YB', 'TP', 'XH', 'UX', 'TZ', 'BV',\n",
    "       'MF', 'WD', 'OZ', 'YW', 'KH', 'GD', 'BM', 'MR', 'KU', 'UV', 'DT',\n",
    "       'HD', 'AA', 'XX', 'DF', 'DB', 'JI', 'KR', 'XO', 'CM', 'ZZ', 'NX',\n",
    "       'YG', 'XY', 'KG', 'TB', 'DC', 'BD', 'SG', 'WY', 'ZY', 'AQ', 'HF',\n",
    "       'CD', 'VU', 'KW', 'ZU', 'BN', 'IH', 'TG', 'XV', 'UZ', 'BC', 'XF',\n",
    "       'YZ', 'KM', 'DP', 'LH', 'WF', 'KF', 'PF', 'CF', 'MT', 'YU', 'CP',\n",
    "       'PB', 'TD', 'ZL', 'SV', 'HC', 'MG', 'PW', 'GF', 'PD', 'PN', 'PC',\n",
    "       'RX', 'TV', 'IJ', 'WM', 'UH', 'WK', 'WB', 'BH', 'OQ', 'KT', 'RQ',\n",
    "       'KB', 'CG', 'VR', 'CN', 'PK', 'UU', 'YF', 'WP', 'CZ', 'KP', 'DQ',\n",
    "       'WU', 'FM', 'WC', 'MD', 'KD', 'ZH', 'GW', 'RZ', 'CB', 'IW', 'XL',\n",
    "       'HP', 'MW', 'VS', 'FC', 'RJ', 'BP', 'MH', 'HH', 'YH', 'UJ', 'FG',\n",
    "       'FD', 'GB', 'PG', 'TK', 'KK', 'HQ', 'FN', 'LZ', 'VL', 'GP', 'HZ',\n",
    "       'DK', 'YK', 'QI', 'LX', 'VD', 'ZS', 'BW', 'XQ', 'MV', 'UW', 'HG',\n",
    "       'FB', 'SJ', 'WW', 'GK', 'UQ', 'BG', 'SZ', 'JR', 'QL', 'ZT', 'HK',\n",
    "       'VC', 'XM', 'GC', 'FW', 'PZ', 'KC', 'HV', 'XW', 'ZW', 'FP', 'IY',\n",
    "       'PV', 'VT', 'JP', 'CV', 'ZB', 'VP', 'ZR', 'FH', 'YV', 'ZG', 'ZM',\n",
    "       'ZV', 'QS', 'KV', 'VN', 'ZN', 'QA', 'YX', 'JN', 'BF', 'MK', 'CW',\n",
    "       'JM', 'LQ', 'JH', 'KJ', 'JC', 'GZ', 'JS', 'TX', 'FK', 'JL', 'VM',\n",
    "       'LJ', 'TJ', 'JJ', 'CJ', 'VG', 'MJ', 'JT', 'PJ', 'WG', 'VH', 'BK',\n",
    "       'VV', 'JD', 'TQ', 'VB', 'JF', 'DZ', 'XB', 'JB', 'ZC', 'FJ', 'YY',\n",
    "       'QN', 'XS', 'QR', 'JK', 'JV', 'QQ', 'XN', 'VF', 'PX', 'ZD', 'QT',\n",
    "       'ZP', 'QO', 'DX', 'HJ', 'GV', 'JW', 'QC', 'JY', 'GJ', 'QB', 'PQ',\n",
    "       'JG', 'BZ', 'MX', 'QM', 'MZ', 'QF', 'WJ', 'ZQ', 'XR', 'ZK', 'CX',\n",
    "       'FX', 'FV', 'BX', 'VW', 'VJ', 'MQ', 'QV', 'ZF', 'QE', 'YJ', 'GX',\n",
    "       'KX', 'XG', 'QD', 'XJ', 'SX', 'VZ', 'VX', 'WV', 'YQ', 'BQ', 'GQ',\n",
    "       'VK', 'ZJ', 'XK', 'QP', 'HX', 'FZ', 'QH', 'QJ', 'JZ', 'VQ', 'KQ',\n",
    "       'XD', 'QW', 'JX', 'QX', 'KZ', 'WX', 'FQ', 'XZ', 'ZX'], dtype='<U32')\n",
    "    bigram_frequencies = np.array([3.55620339e-02, 3.07474124e-02, 2.43274529e-02, 2.04826481e-02,\n",
    "       1.98515108e-02, 1.85432319e-02, 1.75804642e-02, 1.48673230e-02,\n",
    "       1.45424846e-02, 1.35228145e-02, 1.34257882e-02, 1.33939375e-02,\n",
    "       1.27653906e-02, 1.20486963e-02, 1.17497528e-02, 1.16812337e-02,\n",
    "       1.12842988e-02, 1.12327374e-02, 1.08744953e-02, 1.07489847e-02,\n",
    "       1.05347566e-02, 1.04126653e-02, 1.04125115e-02, 9.53014842e-03,\n",
    "       9.32114579e-03, 9.25763559e-03, 8.71095073e-03, 8.70002319e-03,\n",
    "       8.34931851e-03, 8.29254235e-03, 8.25280566e-03, 7.93859725e-03,\n",
    "       7.93006486e-03, 7.64818391e-03, 7.63241814e-03, 7.27618866e-03,\n",
    "       7.26724441e-03, 6.98707488e-03, 6.91722265e-03, 6.88165290e-03,\n",
    "       6.85633031e-03, 6.51417363e-03, 6.24352184e-03, 5.97765978e-03,\n",
    "       5.76571076e-03, 5.76283716e-03, 5.65269345e-03, 5.50057242e-03,\n",
    "       5.46256885e-03, 5.42747781e-03, 5.38164098e-03, 5.30301559e-03,\n",
    "       5.29886071e-03, 5.27529444e-03, 5.08937452e-03, 4.92966405e-03,\n",
    "       4.87753568e-03, 4.84902069e-03, 4.77989185e-03, 4.77282719e-03,\n",
    "       4.74470916e-03, 4.64574958e-03, 4.60971757e-03, 4.54257059e-03,\n",
    "       4.47772200e-03, 4.42103298e-03, 4.31534618e-03, 4.25820178e-03,\n",
    "       4.25013516e-03, 4.15745843e-03, 4.12608242e-03, 4.05151268e-03,\n",
    "       4.05075209e-03, 3.97732158e-03, 3.96527277e-03, 3.94413046e-03,\n",
    "       3.86884200e-03, 3.85337077e-03, 3.85189513e-03, 3.84646388e-03,\n",
    "       3.78793431e-03, 3.77605408e-03, 3.74420703e-03, 3.73663638e-03,\n",
    "       3.67956418e-03, 3.65492648e-03, 3.61676413e-03, 3.61373182e-03,\n",
    "       3.60899233e-03, 3.47234973e-03, 3.45829494e-03, 3.39212478e-03,\n",
    "       3.37488213e-03, 3.36877623e-03, 3.30478042e-03, 3.23572471e-03,\n",
    "       3.17759946e-03, 3.17691369e-03, 3.16447752e-03, 3.15240004e-03,\n",
    "       3.15172398e-03, 3.11176534e-03, 2.95503911e-03, 2.89966768e-03,\n",
    "       2.87848219e-03, 2.86282435e-03, 2.84865969e-03, 2.84585627e-03,\n",
    "       2.81484803e-03, 2.69544349e-03, 2.62987083e-03, 2.54961380e-03,\n",
    "       2.54906719e-03, 2.54783715e-03, 2.52606379e-03, 2.47740122e-03,\n",
    "       2.39175226e-03, 2.36573195e-03, 2.33400171e-03, 2.29786417e-03,\n",
    "       2.27503360e-03, 2.27277101e-03, 2.23911052e-03, 2.21754315e-03,\n",
    "       2.18017446e-03, 2.17360835e-03, 2.14044590e-03, 2.13767970e-03,\n",
    "       2.13188615e-03, 2.10259217e-03, 2.04932647e-03, 2.04724906e-03,\n",
    "       2.03256516e-03, 2.02845908e-03, 1.96777866e-03, 1.95449429e-03,\n",
    "       1.95410531e-03, 1.91254221e-03, 1.89316385e-03, 1.88234971e-03,\n",
    "       1.87652262e-03, 1.84944194e-03, 1.83351654e-03, 1.78086545e-03,\n",
    "       1.76468430e-03, 1.75132925e-03, 1.71573739e-03, 1.70683303e-03,\n",
    "       1.66405086e-03, 1.63999785e-03, 1.62732115e-03, 1.62613977e-03,\n",
    "       1.60361051e-03, 1.54749379e-03, 1.51636562e-03, 1.51067364e-03,\n",
    "       1.49901610e-03, 1.49455831e-03, 1.49011351e-03, 1.48460771e-03,\n",
    "       1.48077067e-03, 1.47541326e-03, 1.47480347e-03, 1.46316579e-03,\n",
    "       1.46204465e-03, 1.43745726e-03, 1.41513491e-03, 1.39980075e-03,\n",
    "       1.38382616e-03, 1.36545598e-03, 1.36333253e-03, 1.36012483e-03,\n",
    "       1.35189358e-03, 1.32127808e-03, 1.30185876e-03, 1.28328757e-03,\n",
    "       1.27907576e-03, 1.26260675e-03, 1.23637099e-03, 1.23094105e-03,\n",
    "       1.21386641e-03, 1.20743055e-03, 1.19536134e-03, 1.19032774e-03,\n",
    "       1.17626124e-03, 1.16805780e-03, 1.14618533e-03, 1.11559852e-03,\n",
    "       1.06597119e-03, 1.05782134e-03, 1.04699320e-03, 1.04540205e-03,\n",
    "       1.01153313e-03, 9.97734501e-04, 9.86028683e-04, 9.84491816e-04,\n",
    "       9.79174450e-04, 9.78784303e-04, 9.70343472e-04, 9.68322624e-04,\n",
    "       9.66708177e-04, 9.60690121e-04, 9.59749105e-04, 9.43900197e-04,\n",
    "       9.40242103e-04, 9.28331656e-04, 9.26685761e-04, 9.14014864e-04,\n",
    "       9.02555222e-04, 8.92112065e-04, 8.85803335e-04, 8.77507468e-04,\n",
    "       8.62646840e-04, 8.57695087e-04, 8.54499050e-04, 8.43925356e-04,\n",
    "       8.31382851e-04, 8.23722323e-04, 8.16643644e-04, 7.89875969e-04,\n",
    "       7.86444549e-04, 7.42072946e-04, 7.36927617e-04, 7.27646949e-04,\n",
    "       7.25004577e-04, 7.11071849e-04, 6.92833068e-04, 6.71807283e-04,\n",
    "       6.68638321e-04, 6.56391013e-04, 6.51990243e-04, 6.49048818e-04,\n",
    "       6.43397537e-04, 6.43118050e-04, 6.37839069e-04, 6.21864133e-04,\n",
    "       6.06367626e-04, 5.99162639e-04, 5.87024289e-04, 5.74860663e-04,\n",
    "       5.72519573e-04, 5.68447140e-04, 5.58806800e-04, 5.45711864e-04,\n",
    "       5.37896691e-04, 5.34768852e-04, 5.20071483e-04, 5.18874875e-04,\n",
    "       5.16054649e-04, 5.14388309e-04, 5.11931727e-04, 5.04227393e-04,\n",
    "       5.00890900e-04, 4.97325634e-04, 4.75088970e-04, 4.66605249e-04,\n",
    "       4.58324041e-04, 4.29127437e-04, 4.27514542e-04, 4.17186146e-04,\n",
    "       4.16199437e-04, 3.94646924e-04, 3.94183167e-04, 3.86306652e-04,\n",
    "       3.61812839e-04, 3.50841120e-04, 3.49059129e-04, 3.23402665e-04,\n",
    "       3.22604151e-04, 3.11527347e-04, 3.10032877e-04, 3.07611603e-04,\n",
    "       2.96010489e-04, 2.88197255e-04, 2.77494857e-04, 2.70735751e-04,\n",
    "       2.67122244e-04, 2.64790886e-04, 2.64597695e-04, 2.63237166e-04,\n",
    "       2.61362824e-04, 2.59399816e-04, 2.58614910e-04, 2.57579773e-04,\n",
    "       2.49143242e-04, 2.49036616e-04, 2.47547306e-04, 2.36748821e-04,\n",
    "       2.35282013e-04, 2.32245156e-04, 2.30209194e-04, 2.28229670e-04,\n",
    "       2.27822992e-04, 2.20319919e-04, 2.17945603e-04, 2.13543715e-04,\n",
    "       1.97145202e-04, 1.90526970e-04, 1.90304866e-04, 1.88393786e-04,\n",
    "       1.85754127e-04, 1.85322815e-04, 1.81767370e-04, 1.74089940e-04,\n",
    "       1.71644610e-04, 1.71039222e-04, 1.69557657e-04, 1.66839046e-04,\n",
    "       1.64718022e-04, 1.59561636e-04, 1.57658164e-04, 1.54026397e-04,\n",
    "       1.52211752e-04, 1.51115808e-04, 1.47564559e-04, 1.46841709e-04,\n",
    "       1.36432949e-04, 1.35005671e-04, 1.32141796e-04, 1.27573620e-04,\n",
    "       1.27432415e-04, 1.26388914e-04, 1.25919175e-04, 1.23965197e-04,\n",
    "       1.21174483e-04, 1.18691292e-04, 1.18219114e-04, 1.17637524e-04,\n",
    "       1.17526303e-04, 1.13037594e-04, 1.10863960e-04, 1.09331046e-04,\n",
    "       1.08837112e-04, 1.06567401e-04, 1.05698197e-04, 1.00512685e-04,\n",
    "       1.00106518e-04, 9.85814937e-05, 9.17495595e-05, 9.15174736e-05,\n",
    "       9.09807382e-05, 8.79007001e-05, 8.16240791e-05, 7.91627682e-05,\n",
    "       7.79158645e-05, 7.56940333e-05, 7.44394656e-05, 7.18101849e-05,\n",
    "       6.97589276e-05, 6.81802488e-05, 6.69029567e-05, 6.54143249e-05,\n",
    "       6.08786925e-05, 6.07607969e-05, 6.03570614e-05, 5.98994801e-05,\n",
    "       5.95001291e-05, 5.94970869e-05, 5.86983574e-05, 5.79700512e-05,\n",
    "       5.66119466e-05, 5.50952209e-05, 5.47453912e-05, 5.43839597e-05,\n",
    "       5.25861529e-05, 4.89722417e-05, 4.78187439e-05, 4.77415865e-05,\n",
    "       4.77107257e-05, 4.62616737e-05, 4.60653783e-05, 4.60409299e-05,\n",
    "       4.56730211e-05, 4.54645078e-05, 4.52324283e-05, 4.38982745e-05,\n",
    "       4.36906610e-05, 4.33593810e-05, 4.31226640e-05, 4.29912118e-05,\n",
    "       4.29446346e-05, 4.17137339e-05, 3.93478837e-05, 3.84895449e-05,\n",
    "       3.84390172e-05, 3.81834469e-05, 3.53827628e-05, 3.47222349e-05,\n",
    "       3.37168917e-05, 3.18518637e-05, 3.15951703e-05, 3.12905207e-05,\n",
    "       3.10605585e-05, 3.02567524e-05, 2.91709879e-05, 2.89567711e-05,\n",
    "       2.85652293e-05, 2.82994071e-05, 2.80417376e-05, 2.77861205e-05,\n",
    "       2.77303518e-05, 2.76273746e-05, 2.72172235e-05, 2.69880432e-05,\n",
    "       2.66503046e-05, 2.66033916e-05, 2.62086568e-05, 2.59259584e-05,\n",
    "       2.57640153e-05, 2.56299050e-05, 2.54449453e-05, 2.51909823e-05,\n",
    "       2.47409597e-05, 2.46797892e-05, 2.42472084e-05, 2.35748710e-05,\n",
    "       2.24438116e-05, 2.24317329e-05, 2.23097275e-05, 2.21249597e-05,\n",
    "       2.17815183e-05, 2.15248592e-05, 2.09465192e-05, 2.09125513e-05,\n",
    "       1.96913177e-05, 1.95330853e-05, 1.91064697e-05, 1.88952009e-05,\n",
    "       1.85746459e-05, 1.81220081e-05, 1.78919334e-05, 1.73267658e-05,\n",
    "       1.61874055e-05, 1.60765855e-05, 1.58740992e-05, 1.45486411e-05,\n",
    "       1.40812264e-05, 1.36678429e-05, 1.32768479e-05, 1.31460479e-05,\n",
    "       1.30872012e-05, 1.29588223e-05, 1.25748548e-05, 1.24146066e-05,\n",
    "       1.22821602e-05, 1.22486357e-05, 1.20714645e-05, 1.20448925e-05,\n",
    "       1.19866728e-05, 1.18936663e-05, 1.17590888e-05, 1.17001978e-05,\n",
    "       1.16346360e-05, 1.11092945e-05, 1.08992577e-05, 1.06740258e-05,\n",
    "       1.06735218e-05, 1.06144296e-05, 1.05679067e-05, 1.03656570e-05,\n",
    "       1.03317955e-05, 9.98437559e-06, 9.01036943e-06, 8.85768061e-06,\n",
    "       8.76035160e-06, 8.60019167e-06, 8.19227801e-06, 7.80479658e-06,\n",
    "       7.53516931e-06, 7.44150882e-06, 7.30644125e-06, 7.26777599e-06,\n",
    "       7.06747616e-06, 6.95177332e-06, 6.85925126e-06, 6.74132156e-06,\n",
    "       6.71322068e-06, 6.70106994e-06, 6.66133186e-06, 6.47626505e-06,\n",
    "       6.38130476e-06, 6.29576510e-06, 6.24612583e-06, 5.93271496e-06,\n",
    "       5.92132104e-06, 5.83947722e-06, 5.76779879e-06, 5.76465728e-06,\n",
    "       5.53187023e-06, 5.47131015e-06, 5.33180695e-06, 5.22417954e-06,\n",
    "       5.20732008e-06, 5.15949060e-06, 5.11569104e-06, 4.95336950e-06,\n",
    "       4.94557425e-06, 4.73636484e-06, 4.63955858e-06, 4.53340156e-06,\n",
    "       4.22935422e-06, 4.19307790e-06, 4.17347414e-06, 4.12142146e-06,\n",
    "       4.11855764e-06, 3.80541311e-06, 3.36707879e-06, 3.29563656e-06,\n",
    "       3.17577578e-06, 3.05442971e-06, 2.98983688e-06, 2.97762691e-06,\n",
    "       2.95066092e-06, 2.91720550e-06, 2.89840858e-06, 2.77497857e-06,\n",
    "       2.76265227e-06, 2.74176112e-06, 2.70310579e-06, 2.61648976e-06,\n",
    "       2.60275585e-06, 2.56616744e-06, 2.55465117e-06, 2.49712549e-06,\n",
    "       2.42815484e-06, 2.37933375e-06, 2.35040476e-06, 2.33914845e-06,\n",
    "       2.33036549e-06, 2.32978989e-06, 2.28930419e-06, 2.28804340e-06,\n",
    "       2.26346210e-06, 2.24353844e-06, 2.23182640e-06, 2.23165865e-06,\n",
    "       2.22696341e-06, 2.22115030e-06, 2.21572164e-06, 2.20668084e-06,\n",
    "       2.19243658e-06, 2.17382266e-06, 2.08159887e-06, 2.07762818e-06,\n",
    "       1.95415065e-06, 1.88693410e-06, 1.83219245e-06, 1.81431726e-06,\n",
    "       1.67631850e-06, 1.67169206e-06, 1.63803449e-06, 1.57770706e-06,\n",
    "       1.56577585e-06, 1.53130790e-06, 1.52519015e-06, 1.52439998e-06,\n",
    "       1.49350905e-06, 1.47212210e-06, 1.45715861e-06, 1.40331777e-06,\n",
    "       1.38641504e-06, 1.29786439e-06, 1.27069447e-06, 1.25613209e-06,\n",
    "       1.23105569e-06, 1.22268909e-06, 1.21688094e-06, 1.18065108e-06,\n",
    "       1.18060143e-06, 1.16794389e-06, 1.13216621e-06, 1.12716419e-06,\n",
    "       1.12418866e-06, 1.12412659e-06, 1.05684621e-06, 1.05049722e-06,\n",
    "       1.04986594e-06, 1.03676402e-06, 1.03482230e-06, 9.96847192e-07,\n",
    "       9.75926251e-07, 9.54397081e-07, 9.36101632e-07, 9.30100914e-07,\n",
    "       9.27467975e-07, 8.92801774e-07, 8.85217179e-07, 8.58891337e-07,\n",
    "       7.80484800e-07, 7.67724409e-07, 7.54031637e-07, 7.45052550e-07,\n",
    "       7.32511689e-07, 7.06828122e-07, 6.59585949e-07, 6.40055245e-07,\n",
    "       6.18628925e-07, 6.17142222e-07, 6.09904832e-07, 6.07242457e-07,\n",
    "       5.72270900e-07, 5.49823535e-07, 5.22568859e-07, 5.01838721e-07,\n",
    "       4.91372576e-07, 4.82981856e-07, 4.69688423e-07, 4.59727658e-07,\n",
    "       4.54795508e-07, 4.22875379e-07, 4.13494116e-07, 3.99834682e-07,\n",
    "       3.97288987e-07, 3.87644926e-07, 3.84245584e-07, 3.81268632e-07,\n",
    "       3.67029696e-07, 3.57267536e-07, 3.52642869e-07, 3.51058992e-07,\n",
    "       3.44112772e-07, 3.36167495e-07, 3.24215712e-07, 3.23810344e-07,\n",
    "       3.21814716e-07, 3.21505459e-07, 3.10936465e-07, 2.88018831e-07,\n",
    "       2.86309762e-07, 2.76140106e-07, 2.63218703e-07, 2.56899508e-07,\n",
    "       2.51244222e-07, 2.25386521e-07, 2.15766576e-07, 2.03018243e-07,\n",
    "       1.99078411e-07, 1.97551987e-07, 1.96981706e-07, 1.92415912e-07,\n",
    "       1.84391194e-07, 1.81253585e-07, 1.78663913e-07, 1.77747846e-07,\n",
    "       1.59541769e-07, 1.38003378e-07, 1.36499298e-07, 1.22889160e-07,\n",
    "       1.22576357e-07, 1.19711121e-07, 1.09597855e-07, 9.97477409e-08,\n",
    "       9.65292710e-08, 9.36271510e-08, 9.35785637e-08, 9.34540807e-08,\n",
    "       8.40270671e-08, 7.82629028e-08, 7.54898762e-08, 6.64058115e-08,\n",
    "       5.96748649e-08, 5.79118882e-08, 5.73650143e-08, 5.65688198e-08,\n",
    "       5.34673852e-08, 5.34237630e-08, 5.29956976e-08, 4.84174907e-08,\n",
    "       3.83818937e-08])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "46wIL5xzDzRS"
   },
   "source": [
    "## Speed matrix  <a name=\"speed\">\n",
    "### 24x24 relative Speed matrix between key pair (averaged for left/right symmetry)\n",
    "\n",
    "  - does not take into account order of key pairs (see Flow24x24 matrix)\n",
    "  - the original version was constructed with data from right-handed people\n",
    "  - 24 keys that don't require extending index or little fingers (\"home block keys\")\n",
    "\n",
    "### Home block keys\n",
    "\n",
    "        Left:            Right:\n",
    "     1  2  3  4       13 14 15 16 \n",
    "     5  6  7  8       17 18 19 20\n",
    "     9 10 11 12       21 22 23 24\n",
    "\n",
    "Interkey stroke times in milliseconds from Table 3 of <br>\n",
    "\"Estimation of digraph costs for keyboard layout optimization\", <br>\n",
    "A Iseri, Ma Eksioglu, International Journal of Industrial Ergonomics, 48, 127-138, 2015. <br>\n",
    "Key numbering in article and in spreadsheet:\n",
    "\n",
    "         Left:           Right:\n",
    "     1 4 7 10 13   16 19 22 25 28 31\n",
    "     2 5 8 11 14   17 20 23 26 29 32\n",
    "     3 6 9 12 15   18 21 24 27 30\n",
    "     \n",
    "### Load table of interkey speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "095yG4iPDzRT"
   },
   "outputs": [],
   "source": [
    "# %load data/Time24x24.py\n",
    "# code/load_original_interkey_speeds.py\n",
    "#        Left:            Right:\n",
    "#    1  2  3  4 25   28 13 14 15 16 31 \n",
    "#    5  6  7  8 26   29 17 18 19 20 32\n",
    "#    9 10 11 12 27   30 21 22 23 24\n",
    "Time24x24 = np.array([\n",
    "[196,225,204,164,266,258,231,166,357,325,263,186,169,176,178,186,156,156,158,163,171,175,177,189],\n",
    "[225,181,182,147,239,245,196,150,289,296,229,167,162,169,170,178,148,148,150,155,163,167,169,182],\n",
    "[204,182,170,149,196,194,232,155,237,214,263,166,157,164,165,173,143,143,145,150,158,163,164,177],\n",
    "[164,147,149,169,160,161,157,226,165,185,234,257,154,162,163,171,141,141,143,148,156,160,162,175],\n",
    "[266,239,196,160,196,240,208,166,271,267,208,169,143,150,151,160,129,129,132,137,145,149,151,163],\n",
    "[258,245,194,161,240,181,183,149,245,256,184,150,138,145,146,154,124,124,126,131,139,144,145,158],\n",
    "[231,196,232,157,208,183,170,149,201,215,239,151,134,141,142,150,120,120,122,127,135,140,141,154],\n",
    "[166,150,155,226,166,149,149,169,160,147,170,221,133,140,141,150,119,119,122,126,135,139,141,153],\n",
    "[357,289,237,165,271,245,201,160,196,236,194,161,171,178,179,188,157,157,160,164,173,177,179,191],\n",
    "[325,296,214,185,267,256,215,147,236,181,184,157,166,173,174,182,152,152,154,159,167,172,173,186],\n",
    "[263,229,263,234,208,184,239,170,194,184,170,150,159,166,167,176,145,145,148,153,161,165,167,179],\n",
    "[186,167,166,257,169,150,151,221,161,157,150,169,153,160,161,169,139,139,141,146,154,159,160,173],\n",
    "[169,162,157,154,143,138,134,133,171,166,159,153,151,147,141,145,188,151,142,164,213,204,162,149],\n",
    "[176,169,164,162,150,145,141,140,178,173,166,160,147,151,189,209,137,207,191,206,149,227,208,197],\n",
    "[178,170,165,163,151,146,142,141,179,174,167,161,141,189,157,253,136,188,210,231,155,226,239,276],\n",
    "[186,178,173,171,160,154,150,150,188,182,176,169,145,209,253,170,147,206,251,233,164,268,362,271],\n",
    "[156,148,143,141,129,124,120,119,157,152,145,139,188,137,136,147,151,133,138,152,192,149,139,144],\n",
    "[156,148,143,141,129,124,120,119,157,152,145,139,151,207,188,206,133,151,179,183,145,204,183,201],\n",
    "[158,150,145,143,132,126,122,122,160,154,148,141,142,191,210,251,138,179,157,240,145,185,208,229],\n",
    "[163,155,150,148,137,131,127,126,164,159,153,146,164,206,231,233,152,183,240,170,160,220,293,242],\n",
    "[171,163,158,156,145,139,135,135,173,167,161,154,213,149,155,164,192,145,145,160,151,140,142,145],\n",
    "[175,167,163,160,149,144,140,139,177,172,165,159,204,227,226,268,149,204,185,220,140,151,175,188],\n",
    "[177,169,164,162,151,145,141,141,179,173,167,160,162,208,239,362,139,183,208,293,142,175,157,230],\n",
    "[189,182,177,175,163,158,154,153,191,186,179,173,149,197,276,271,144,201,229,242,145,188,230,170]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load code/load_interkey_speeds24x24.py\n",
    "\n",
    "# Left/right symmetric version of the Time24x24 matrix\n",
    "# (The original version was constructed with data from right-handed people.)\n",
    "# A. Iseri, M. Eksioglu / International Journal of Industrial Ergonomics 48 (2015) 127e138\n",
    "\n",
    "#        Left:            Right:\n",
    "#     1  2  3  4       13 14 15 16 \n",
    "#     5  6  7  8       17 18 19 20\n",
    "#     9 10 11 12       21 22 23 24\n",
    "\n",
    "I = [ 1, 2, 3, 4,   5, 6, 7, 8,   9,10,11,12,  16,15,14,13,  20,19,18,17,  24,23,22,21]\n",
    "J = [16,15,14,13,  20,19,18,17,  24,23,22,21,   1, 2, 3, 4,   5, 6, 7, 8,   9,10,11,12]\n",
    "\n",
    "TimeSymmetric24x24 = np.ones((24,24))\n",
    "for i1, I1 in enumerate(I):\n",
    "    for i2, I2 in enumerate(I):\n",
    "        J1 = J[i1] - 1\n",
    "        J2 = J[i2] - 1\n",
    "        avgvalue = (Time24x24[I1-1,I2-1] + Time24x24[J1,J2]) / 2 \n",
    "        #print(Time24x24[I1-1,I2-1], Time24x24[J1,J2], avgvalue)\n",
    "        TimeSymmetric24x24[I1-1,I2-1] = avgvalue\n",
    "        TimeSymmetric24x24[J1,J2] = avgvalue\n",
    "\n",
    "# Normalize matrix with min-max scaling to a range with maximum = 1:\n",
    "newMin = np.min(Time24x24) / np.max(Time24x24)\n",
    "newMax = 1.0\n",
    "Time24x24 = newMin + (Time24x24 - np.min(Time24x24)) * (newMax - newMin) / (np.max(Time24x24) - np.min(Time24x24))\n",
    "\n",
    "# Convert relative interkey stroke times to relative speeds by subtracting from 1:\n",
    "Speed24x24 = 1 - Time24x24 + np.min(Time24x24)\n",
    "\n",
    "# Normalize matrix with min-max scaling to a range with maximum = 1:\n",
    "newMin = np.min(TimeSymmetric24x24) / np.max(TimeSymmetric24x24)\n",
    "newMax = 1.0\n",
    "TimeSymmetric24x24 = newMin + (TimeSymmetric24x24 - np.min(TimeSymmetric24x24)) * (newMax - newMin) / (np.max(TimeSymmetric24x24) - np.min(TimeSymmetric24x24))\n",
    "\n",
    "# Convert relative interkey stroke times to relative speeds by subtracting from 1:\n",
    "SpeedSymmetric24x24 = 1 - TimeSymmetric24x24 + np.min(TimeSymmetric24x24)\n",
    "\n",
    "# Print:\n",
    "#print_matrix_info(matrix_data=Speed24x24, matrix_label=\"Speed24x24\", nkeys=24, nlines=50)\n",
    "#heatmap(data=Speed24x24, title=\"Speed24x24\", xlabel=\"Key 1\", ylabel=\"Key 2\", print_output=print_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFfuA8zMDzRg"
   },
   "source": [
    "## Strength matrix  <a name=\"strength\">\n",
    "\n",
    "### Relative finger position STRENGTH matrix\n",
    "\n",
    "Finger strengths are based on peak keyboard reaction forces (in newtons) from Table 4 of <br>\n",
    "\"Keyboard Reaction Force and Finger Flexor Electromyograms during Computer Keyboard Work\" <br>\n",
    "BJ Martin, TJ Armstrong, JA Foulke, S Natarajan, Human Factors,1996,38(4),654-664:\n",
    "   \n",
    "    middle     2.36\n",
    "    index      2.26\n",
    "    ring       2.02\n",
    "    little     1.84\n",
    "    \n",
    "    index/middle:  0.9576271186440678\n",
    "    ring/middle:   0.8559322033898306\n",
    "    little/middle: 0.7796610169491526\n",
    "\n",
    "For reference, Table 1 of \"Ergonomic keyboard layout designed for the Filipino language\", 2016 (doi: 10.1007/978-3-319-41694-6_41) presents \"average finger strength of Filipinos [n=30, ages 16-36] measured in pounds\":\n",
    "   \n",
    "                L       R\n",
    "    little     3.77   4.27\n",
    "    ring       4.54   5.08\n",
    "    middle     5.65   6.37\n",
    "    index      6.09   6.57\n",
    "    \n",
    "    6.57/4.27 = 1.54\n",
    "    6.09/3.77 = 1.62\n",
    "    6.37/5.08 = 1.25\n",
    "    5.65/4.54 = 1.24\n",
    "    \n",
    "We won't use these results as I don't feel they represent relative strength relevant for typing: \"Respondents were asked to sit in upright position, with their wrists resting on a flat surface. A pinch gauge was placed within each finger's reach. The respondents were asked to exert maximum pressure on the device.\"\n",
    "    \n",
    "The following does not take into account order of key pairs (see Flow matrix).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load code/load_strength_data.py\n",
    "# Normalize by the highest peak force (middle finger):\n",
    "middle_force = 2.36\n",
    "index_force = 2.26\n",
    "ring_force = 2.02\n",
    "little_force = 1.84\n",
    "middle_norm = 1.0\n",
    "index_norm = index_force / middle_force\n",
    "ring_norm = ring_force / middle_force\n",
    "little_norm = little_force / middle_force\n",
    "print('index/middle: {0}'.format(index_norm))\n",
    "print('ring/middle: {0}'.format(ring_norm))\n",
    "print('little/middle: {0}'.format(little_norm))\n",
    "\n",
    "# Relative left/right hand strength (assume equal):\n",
    "lf = 1.0\n",
    "rf = 1.0\n",
    "\n",
    "strengths24 = np.array((\n",
    "                    lf * little_norm, lf * ring_norm, lf * middle_norm, lf * index_norm,\n",
    "                    lf * little_norm, lf * ring_norm, lf * middle_norm, lf * index_norm,\n",
    "                    lf * little_norm, lf * ring_norm, lf * middle_norm, lf * index_norm,\n",
    "                    rf * index_norm, rf * middle_norm, rf * ring_norm, rf * little_norm,\n",
    "                    rf * index_norm, rf * middle_norm, rf * ring_norm, rf * little_norm,\n",
    "                    rf * index_norm, rf * middle_norm, rf * ring_norm, rf * little_norm))\n",
    "\n",
    "# Create a finger-pair position strength matrix by adding pairs of strength values:\n",
    "Strength24x24 = np.zeros((24, 24))\n",
    "for i in range(24):\n",
    "    Strength24x24[i,:] = strengths24\n",
    "Strength24x24 = (Strength24x24 + Strength24x24.transpose())\n",
    "\n",
    "# Normalize matrix with min-max scaling to a range with maximum = 1:\n",
    "#newMin = strength_factor\n",
    "newMin = min_strength_factor  # np.min(Strength24x24) / np.max(Strength24x24)\n",
    "newMax = 1.0\n",
    "Strength24x24 = newMin + (Strength24x24 - np.min(Strength24x24)) * (newMax - newMin) / (np.max(Strength24x24) - np.min(Strength24x24))\n",
    "\n",
    "# Print:\n",
    "print_matrix_info(matrix_data=Strength24x24, matrix_label=\"Strength24x24\", nkeys=24, nlines=10)\n",
    "heatmap(data=Strength24x24, title=\"Strength24x24\", xlabel=\"Key 1\", ylabel=\"Key 2\", print_output=print_output)\n",
    "\n",
    "# Save:\n",
    "if print_output:\n",
    "    file = open(\"Strength24x24.txt\", \"w+\")\n",
    "    file.write(str(Strength24x24))\n",
    "    file.close()\n",
    "\n",
    "\n",
    "penalty = 1.0  # Penalty for lateral (index, little) finger placement (1 = no penalty)\n",
    "\n",
    "strengths32 = np.array((lf * little_norm, lf * ring_norm, lf * middle_norm, lf * index_norm,\n",
    "                        lf * little_norm, lf * ring_norm, lf * middle_norm, lf * index_norm,\n",
    "                        lf * little_norm, lf * ring_norm, lf * middle_norm, lf * index_norm,\n",
    "                        rf * index_norm, rf * middle_norm, rf * ring_norm, rf * little_norm,\n",
    "                        rf * index_norm, rf * middle_norm, rf * ring_norm, rf * little_norm,\n",
    "                        rf * index_norm, rf * middle_norm, rf * ring_norm, rf * little_norm,\n",
    "                        lf * index_norm * penalty, lf * index_norm * penalty, lf * index_norm * penalty,\n",
    "                        rf * index_norm * penalty, rf * index_norm * penalty, rf * index_norm * penalty,\n",
    "                        rf * little_norm * penalty, rf * little_norm * penalty))\n",
    "\n",
    "# Create a finger-pair position strength matrix by adding pairs of strength values:\n",
    "Strength32x32 = np.zeros((32, 32))\n",
    "for i in range(32):\n",
    "    Strength32x32[i,:] = strengths32\n",
    "Strength32x32 = (Strength32x32 + Strength32x32.transpose())\n",
    "\n",
    "# Normalize matrix with min-max scaling to a range with maximum = 1:\n",
    "newMin = np.min(Strength32x32) / np.max(Strength32x32)\n",
    "newMax = 1.0\n",
    "Strength32x32 = newMin + (Strength32x32 - np.min(Strength32x32)) * (newMax - newMin) / (np.max(Strength32x32) - np.min(Strength32x32))\n",
    "\n",
    "# Print:\n",
    "print_matrix_info(matrix_data=Strength32x32, matrix_label=\"Strength32x32\", nkeys=32, nlines=10)\n",
    "heatmap(data=Strength32x32, title=\"Strength32x32\", xlabel=\"Key 1\", ylabel=\"Key 2\", print_output=print_output)\n",
    "\n",
    "# Save:\n",
    "if print_output:\n",
    "    file = open(\"Strength32x32.txt\", \"w+\")\n",
    "    file.write(str(Strength32x32))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dnn5-8S5DzRy"
   },
   "source": [
    "## Flow matrix and Engram scoring model  <a name=\"flow\">\n",
    "\n",
    "The Flow24x24 matrix takes into account ease of transition between ordered pairs of keys.\n",
    "    \n",
    "Our optimization algorithm finds every permutation of a given set of letters, maps these letter permutations to a set of keys, and ranks these letter-key mappings according to a score reflecting ease of typing key pairs and frequency of letter pairs (bigrams). The score is the average of the scores for all possible bigrams in this arrangement. The score for each bigram is a product of the frequency of occurrence of that bigram, the frequency of each of the bigrams characters, and flow, strength (and optional speed) factors for the key pair.\n",
    "\n",
    "#### Dvorak et al. (1936) defined eleven criteria for the design and evaluation of keyboard layouts:\n",
    "1.  Deviation from the balance of hand and finger loads should be as low as possible.\n",
    "2.  Percentage of tapping with the same fingers should be as low as possible.\n",
    "3.  Percentage of tapping that includes top row should be as low as possible.\n",
    "4.  Percentage of tapping that includes bottom row should be as low as possible.\n",
    "5.  Percentage of tapping in the home row should be as high as possible.\n",
    "6.  Percentage of tapping by alternating hands should be as high as possible.\n",
    "7.  Percentage of hurdles with the same finger should be as low as possible.\n",
    "8.  Percentage of hurdles with adjacent offset fingers should be as low as possible.\n",
    "9.  Percentage of hurdles with remote fingers should be as low as possible.\n",
    "10. Percentage of reach with the same finger should be as low as possible.\n",
    "11. Percentage of reach with adjacent offset fingers should be as low as possible.\n",
    "\n",
    "#### Synopsis of above criteria for pairwise key presses when touch typing:\n",
    "1. Alternate between hands.\n",
    "2. Balance finger loads, and avoid using the same finger.\n",
    "3. Avoid the upper and lower rows, and avoid skipping over the home row.\n",
    "4. Avoid tapping adjacent offset rows with the same or adjacent offset fingers.\n",
    "    \n",
    "### Factors to penalize strenuous key transitions\n",
    "\n",
    "Direction:\n",
    "    \n",
    "    - outward = 0.9: outward roll of fingers from the index to little finger (same hand)\n",
    "\n",
    "Dexterity:\n",
    "    \n",
    "    - side_above_3away = 0.9\n",
    "        - index and little finger type two keys, one or more rows apart (same hand)\n",
    "    - side_above_2away = 0.9^2 = 0.81\n",
    "        - index finger types key a row or two above ring finger key, or\n",
    "        - little finger types key a row or two above middle finger key (same hand)\n",
    "    - side_above_1away = 0.9^3 = 0.729\n",
    "        - index finger types key a row or two above middle finger key, or\n",
    "        - little finger types key a row or two above ring finger key (same hand)\n",
    "    - middle_above_ring = 0.9\n",
    "        - middle finger types key a row or two above ring finger key (same hand)\n",
    "    - ring_above_middle = 0.9^3 = 0.729\n",
    "        - ring finger types key a row or two above middle finger key (same hand)\n",
    "    - lateral = 0.9\n",
    "        - lateral movement of (index or little) finger outside of 8 vertical columns\n",
    "    \n",
    "Distance:\n",
    "    \n",
    "    - skip_row_3away = 0.9       \n",
    "        - index and little fingers type two keys that skip over home row (same hand)\n",
    "        - (e.g., one on bottom row, the other on top row)\n",
    "    - skip_row_2away = 0.9^3 = 0.729\n",
    "        - little and middle or index and ring fingers type two keys that skip over home row (same hand)\n",
    "    - skip_row_1away = 0.9^5 = 0.59049\n",
    "        - little and ring or middle and index fingers type two keys that skip over home row (same hand)\n",
    "\n",
    "Repetition:\n",
    " \n",
    "    - skip_row_0away = 0.9^4 = 0.6561\n",
    "        - same finger types two keys that skip over home row\n",
    "    - same_finger = 0.9^5 = 0.59049\n",
    "        - use same finger again for a different key\n",
    "        - cannot accompany outward, side_above, or adjacent_shorter_above \n",
    "\n",
    "Strength: Accounted for by the strength matrix (minimum value for the little finger = 0.9)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example flow values for left side home block\n",
    "   \n",
    "No penalty (for same hand, both keys in the same row in an inward roll or repeating the same key):\n",
    "\n",
    "    2=>2, 2=>3, 3=>4, 2=>4, 1=>4\n",
    "\n",
    "    1  2  3  4\n",
    "    5  6  7  8\n",
    "    9 10 11 12\n",
    "\n",
    "Penalty = 0.9:\n",
    "\n",
    "    outward: 2=>1, 3=>1, 3=>2, 4=>1, 4=>2, 4=>3, 6=>5, 7=>6, 7=>5, 8=>7, 8=>6, 8=>5,... \n",
    "    middle_above_ring: 6=>3, 10=>7 \n",
    "    side_above_3away: 1=>8, 5=>4, 5=>12, 9=>8\n",
    "    index_above: 1=>4, 2=>4, 3=>4, 4=>4\n",
    "\n",
    "Penalty = 0.9^2:\n",
    "\n",
    "    middle_above_ring * outward: 3=>6, 7=>10\n",
    "    side_above_3away * outward: 8=>1, 4=>5, 12=>5, 8=>9\n",
    "    side_above_2away: 1=>7, 6=>4, 5=>11, 10=>8    \n",
    "    skip_row_3away * side_above_3away: 1=>12, 9=>4\n",
    "    skip_row_2away: 2=>12, 9=>3\n",
    "    ring_above_middle 2=>7, 6=>11\n",
    "    side_above_2away * outward: 7=>1, 4=>6, 11=>5, 8=>10\n",
    "    side_above_1away: 1=>6, 7=>4, 5=>10, 11=>8\n",
    "\n",
    "Penalty = 0.9^3:\n",
    "\n",
    "    skip_row_3away * side_above_3away * outward: 12=>1, 4=>9\n",
    "\n",
    "Penalty = 0.9^4:\n",
    "\n",
    "    ring_above_middle * outward: 7=>2, 11=>6\n",
    "    side_above_1away * outward: 4=>7, 6=>1, 10=>5, 4=>7\n",
    "\n",
    "Penalty = 0.9^5:\n",
    "\n",
    "    same_finger: 4=>8, 8=>4, 1=>5, 5=>1, 5=>9, 9=>5, 2=>6, 6=>2,...\n",
    "    skip_row_2away * side_above_2away: 10=>4, 1=>11\n",
    "    skip_row_1away: 1=>10, 9=>2, 3=>12\n",
    "\n",
    "Penalty = 0.9^6:\n",
    "\n",
    "    skip_row_2away * side_above_2away * outward: 4=>10, 11=>1\n",
    "    skip_row_1away * outward: 10=>1, 2=>9, 12=>3\n",
    "\n",
    "Penalty = 0.9^8\n",
    "\n",
    "    skip_row_1away * ring_above_middle: 2=>11\n",
    "    skip_row_1away * side_above_1away: 1=>10, 11=>4\n",
    "\n",
    "Penalty = 0.9^9\n",
    "\n",
    "    skip_row_1away * ring_above_middle * outward: 11=>2\n",
    "    skip_row_0away * same_finger: 1=>9, 9=>1, 4=>12, 12=>4, 2=>10, 10=>2, 3=>11, 11=>3     \n",
    "    skip_row_1away * side_above_1away * outward: 10=>1, 4=>11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load code/load_flow_matrices.py\n",
    "# Penalizing factors for 24 keys  (1 = no penalty; set to less than 1 to penalize):\n",
    "\n",
    "# Dexterity\n",
    "side_above_3away = 0.9     # index and little finger type two keys, one or more rows apart (same hand)\n",
    "side_above_2away = 0.81    # index finger types key a row or two above ring finger key, or\n",
    "                           # little finger types key a row or two above middle finger key (same hand)\n",
    "side_above_1away = 0.729   # index finger types key a row or two above middle finger key, or\n",
    "                           # little finger types key a row or two above ring finger key (same hand)\n",
    "middle_above_ring = 0.9    # middle finger types key a row or two above ring finger key (same hand)\n",
    "ring_above_middle = 0.729  # ring finger types key a row or two above middle finger key (same hand)\n",
    "lateral = 0.9              # lateral movement of (index or little) finger outside of 8 vertical columns\n",
    "\n",
    "# Direction\n",
    "outward = 0.9              # outward roll of fingers from the index to little finger (same hand)\n",
    "\n",
    "# Distance\n",
    "skip_row_3away = 0.9       # index and little fingers type two keys that skip over home row (same hand)\n",
    "                           # (e.g., one on bottom row, the other on top row)\n",
    "skip_row_2away = 0.729     # little and middle or index and ring fingers type two keys that skip over home row (same hand)\n",
    "skip_row_1away = 0.59049   # little and ring or middle and index fingers type two keys that skip over home row (same hand)\n",
    "\n",
    "# Repetition\n",
    "skip_row_0away = 0.6561    # same finger types two keys that skip over home row\n",
    "same_finger = 0.59049      # use same finger again for a different key\n",
    "\n",
    "\n",
    "# Unused or redundant parameters\n",
    "same_hand = 1.0            # (addressed by splitting up the most frequent letters across left/right sides above)\n",
    "not_home_row = 1.0         # at least one key not on home row\n",
    "side_top = 1.0             # index or little finger types top corner key\n",
    "shorter_above = 1.0        # (taken care of by side_above_[1,2,3]away parameters)\n",
    "adjacent_offset = 1.0      # (taken care of by side_above_1away, middle_above_ring, ring_above_middle parameters)\n",
    "inside_top = 1.0           # index finger types top corner key (taken care of by side_above_1away parameter)\n",
    "index_above = 1.0          # index finger types top corner key (unless other bigram key is in the top row for the same hand)\n",
    "                           # (taken care of by side_above_[1,2,3]away parameters)\n",
    "\n",
    "\n",
    "def create_24x24_flow_matrix(not_home_row, side_top, side_above_3away, side_above_2away, side_above_1away, \n",
    "                             middle_above_ring, ring_above_middle, outward, skip_row_3away, \n",
    "                             skip_row_2away, skip_row_1away, skip_row_0away, same_finger, lateral, \n",
    "                             same_hand, shorter_above, adjacent_offset, inside_top, index_above):\n",
    "\n",
    "    all_24_keys = [1,2,3,4, 5,6,7,8, 9,10,11,12, 13,14,15,16, 17,18,19,20, 21,22,23,24]\n",
    "\n",
    "    # Create a matrix and multiply by flow factors that promote easy interkey transitions:\n",
    "    T = np.ones((24, 24))\n",
    "\n",
    "    # 7.  Promote alternating between hands over uncomfortable transitions with the same hand.\n",
    "    if same_hand < 1.0:\n",
    "    #    1  2  3  4   13 14 15 16  \n",
    "    #    5  6  7  8   17 18 19 20 \n",
    "    #    9 10 11 12   21 22 23 24\n",
    "        for i in range(0,12):\n",
    "            for j in range(0,12):\n",
    "                T[i,j] *= same_hand\n",
    "        for i in range(12,24):\n",
    "            for j in range(12,24):\n",
    "                T[i,j] *= same_hand\n",
    "\n",
    "    # 8.  Promote little-to-index-finger roll-ins over index-to-little-finger outwards.\n",
    "    #    1  2  3  4   13 14 15 16  \n",
    "    #    5  6  7  8   17 18 19 20 \n",
    "    #    9 10 11 12   21 22 23 24\n",
    "    if outward < 1.0:\n",
    "\n",
    "        # same-row roll-outs:\n",
    "        roll_ins = [[1,2],[2,3],[3,4], [5,6],[6,7],[7,8], [9,10],[10,11],[11,12],\n",
    "                    [16,15],[15,14],[14,13], [20,19],[19,18],[18,17], [24,23],[23,22],[22,21]]\n",
    "        for x in roll_ins:\n",
    "            T[x[1]-1, x[0]-1] *= outward\n",
    "\n",
    "        # same-row roll-outs, skipping keys:\n",
    "        roll_ins_skip_keys = [[1,3],[2,4],[1,4], [5,7],[6,8],[5,8], [9,11],[10,12],[9,12],\n",
    "                              [16,14],[15,13],[16,13], [20,18],[19,17],[20,17], [24,22],[23,21],[24,21]]\n",
    "        for x in roll_ins_skip_keys:\n",
    "            T[x[1]-1, x[0]-1] *= outward\n",
    "\n",
    "        # adjacent-row roll-outs:\n",
    "        roll_ins_adj_rows = [[1,6],[1,7],[1,8],[2,7],[2,8],[3,8], [5,2],[5,3],[5,4],[6,3],[6,4],[7,4],\n",
    "                             [5,10],[5,11],[5,12],[6,11],[6,12],[7,12], [9,6],[9,7],[9,8],[10,7],[10,8],[11,8],\n",
    "                             [16,19],[16,18],[16,17],[15,18],[15,17],[14,17], [20,15],[20,14],[20,13],[19,14],[19,13],[18,13],\n",
    "                             [20,23],[20,22],[20,21],[19,22],[19,21],[18,21], [24,19],[24,18],[24,17],[23,18],[23,17],[22,17]]\n",
    "        for x in roll_ins_adj_rows:\n",
    "            T[x[1]-1, x[0]-1] *= outward\n",
    "\n",
    "        # upper<->lower row roll-outs:\n",
    "        roll_ins_skip_home = [[1,10],[1,11],[1,12],[2,11],[2,12],[3,12], [9,2],[9,3],[9,4],[10,3],[10,4],[11,4],\n",
    "                              [16,23],[16,22],[16,21],[15,22],[15,21],[14,21], [24,15],[24,14],[24,13],[23,14],[23,13],[22,13]]\n",
    "        for x in roll_ins_skip_home:\n",
    "            T[x[1]-1, x[0]-1] *= outward\n",
    "\n",
    "    # 9.  Avoid stretching shorter fingers up and longer fingers down.\n",
    "    #    1  2  3  4   13 14 15 16  \n",
    "    #    5  6  7  8   17 18 19 20 \n",
    "    #    9 10 11 12   21 22 23 24\n",
    "    if index_above < 1.0:\n",
    "        for x in [4]:\n",
    "            for y in [4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]:\n",
    "                T[x-1, y-1] *= index_above\n",
    "                T[y-1, x-1] *= index_above\n",
    "        for x in [13]:\n",
    "            for y in [1,2,3,4,5,6,7,8,9,10,11,12,13,17,18,19,20,21,22,23,24]:\n",
    "                T[x-1, y-1] *= index_above\n",
    "                T[y-1, x-1] *= index_above\n",
    "    if inside_top < 1.0:\n",
    "        for x in [4,13]:\n",
    "            for j in range(0,24):\n",
    "                T[x-1, j] *= inside_top\n",
    "                T[j, x-1] *= inside_top\n",
    "    if side_top < 1.0:\n",
    "        for x in [1,4,13,16]:\n",
    "            for j in range(0,24):\n",
    "                T[x-1, j] *= side_top\n",
    "                T[j, x-1] *= side_top\n",
    "    if side_above_1away < 1.0:\n",
    "        for x in [1]:\n",
    "            for y in [6,10]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [5]:\n",
    "            for y in [10]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [4]:\n",
    "            for y in [7,11]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [8]:\n",
    "            for y in [11]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [13]:\n",
    "            for y in [18,22]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [17]:\n",
    "            for y in [22]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [16]:\n",
    "            for y in [19,23]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [20]:\n",
    "            for y in [23]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "    if side_above_2away < 1.0:\n",
    "        for x in [1]:\n",
    "            for y in [7,11]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [5]:\n",
    "            for y in [11]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [4]:\n",
    "            for y in [6,10]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [8]:\n",
    "            for y in [10]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [13]:\n",
    "            for y in [19,23]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [17]:\n",
    "            for y in [23]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [16]:\n",
    "            for y in [18,22]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [20]:\n",
    "            for y in [22]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "    if side_above_3away < 1.0:\n",
    "        for x in [1]:\n",
    "            for y in [8,12]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [5]:\n",
    "            for y in [12]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [4]:\n",
    "            for y in [5,9]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [8]:\n",
    "            for y in [9]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [13]:\n",
    "            for y in [20,24]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [17]:\n",
    "            for y in [24]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [16]:\n",
    "            for y in [17,21]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [20]:\n",
    "            for y in [21]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "    if shorter_above < 1.0:\n",
    "        for x in [1]:\n",
    "            for y in [6,7,8,10,11,12]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [2]:\n",
    "            for y in [7,11]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [4]:\n",
    "            for y in [6,7,10,11]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "\n",
    "        for x in [5]:\n",
    "            for y in [10,11,12]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [6]:\n",
    "            for y in [11]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [8]:\n",
    "            for y in [10,11]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "\n",
    "        for x in [16]:\n",
    "            for y in [17,18,19,21,22,23]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [15]:\n",
    "            for y in [18,22]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [13]:\n",
    "            for y in [18,19,22,23]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "\n",
    "        for x in [20]:\n",
    "            for y in [21,22,23]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [19]:\n",
    "            for y in [22]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [17]:\n",
    "            for y in [22,23]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "\n",
    "    if ring_above_middle < 1.0:\n",
    "        ring_above_middles =  [[2,7],[6,11],[2,11],\n",
    "                            [15,18],[19,22],[15,22]]\n",
    "        for x in ring_above_middles:\n",
    "            T[x[0]-1, x[1]-1] *= ring_above_middle\n",
    "            T[x[1]-1, x[0]-1] *= ring_above_middle\n",
    "\n",
    "    if middle_above_ring < 1.0:\n",
    "        middle_above_rings =  [[6,3],[10,7],[10,3],\n",
    "                            [19,14],[23,18],[23,14]]\n",
    "        for x in middle_above_rings:\n",
    "            T[x[0]-1, x[1]-1] *= middle_above_ring\n",
    "            T[x[1]-1, x[0]-1] *= middle_above_ring\n",
    "\n",
    "    # 10. Avoid using the same finger.\n",
    "    #    1  2  3  4   13 14 15 16  \n",
    "    #    5  6  7  8   17 18 19 20 \n",
    "    #    9 10 11 12   21 22 23 24\n",
    "    if same_finger < 1.0:\n",
    "        same_fingers = [[1,5],[5,9],[1,9], [2,6],[6,10],[2,10], [3,7],[7,11],[3,11], [4,8],[8,12],[4,12],\n",
    "                        [13,17],[17,21],[13,21], [14,18],[18,22],[14,22], [15,19],[19,23],[15,23], [16,20],[20,24],[16,24]] \n",
    "        for x in same_fingers:\n",
    "            T[x[0]-1, x[1]-1] *= same_finger\n",
    "            T[x[1]-1, x[0]-1] *= same_finger\n",
    "\n",
    "    # 11. Avoid the upper and lower rows.\n",
    "    #    1  2  3  4   13 14 15 16  \n",
    "    #    5  6  7  8   17 18 19 20 \n",
    "    #    9 10 11 12   21 22 23 24\n",
    "    if not_home_row < 1.0:\n",
    "        not_home_row_keys = [1,2,3,4, 9,10,11,12, 13,14,15,16, 21,22,23,24]\n",
    "        for x in not_home_row_keys:\n",
    "            for j in range(0,23):\n",
    "                T[x-1, j] *= not_home_row\n",
    "                T[j, x-1] *= not_home_row\n",
    "\n",
    "    # 12. Avoid skipping over the home row.\n",
    "    #    1  2  3  4   13 14 15 16  \n",
    "    #    5  6  7  8   17 18 19 20 \n",
    "    #    9 10 11 12   21 22 23 24\n",
    "    if skip_row_0away < 1.0:\n",
    "        skip_top = [1, 2, 3, 4, 13,14,15,16] \n",
    "        skip_bot = [9,10,11,12, 21,22,23,24] \n",
    "        for ix, x in enumerate(skip_top):\n",
    "            y = skip_bot[ix]\n",
    "            T[x-1, y-1] *= skip_row_0away\n",
    "            T[y-1, x-1] *= skip_row_0away\n",
    "    if skip_row_1away < 1.0:\n",
    "        skip_top = [1, 2, 2, 3, 3, 4, 13,14,14,15,15,16] \n",
    "        skip_bot = [10,9,11,10,12,11, 22,21,23,22,24,23] \n",
    "        for ix, x in enumerate(skip_top):\n",
    "            y = skip_bot[ix]\n",
    "            T[x-1, y-1] *= skip_row_1away\n",
    "            T[y-1, x-1] *= skip_row_1away\n",
    "    if skip_row_2away < 1.0:\n",
    "        skip_top = [1,  2,3, 4, 13,14,15,16] \n",
    "        skip_bot = [11,12,9,10, 23,24,21,22] \n",
    "        for ix, x in enumerate(skip_top):\n",
    "            y = skip_bot[ix]\n",
    "            T[x-1, y-1] *= skip_row_2away\n",
    "            T[y-1, x-1] *= skip_row_2away\n",
    "    if skip_row_3away < 1.0:\n",
    "        skip_top = [1, 4, 13,16] \n",
    "        skip_bot = [12,9, 24,21] \n",
    "        for ix, x in enumerate(skip_top):\n",
    "            y = skip_bot[ix]\n",
    "            T[x-1, y-1] *= skip_row_3away\n",
    "            T[y-1, x-1] *= skip_row_3away\n",
    "\n",
    "    Flow24x24 = T\n",
    "\n",
    "    # Normalize matrix with min-max scaling to a range with maximum = 1:\n",
    "    newMin = np.min(Flow24x24) / np.max(Flow24x24)\n",
    "    newMax = 1.0\n",
    "    Flow24x24 = newMin + (Flow24x24 - np.min(Flow24x24)) * (newMax - newMin) / (np.max(Flow24x24) - np.min(Flow24x24))\n",
    "\n",
    "    return Flow24x24\n",
    "\n",
    "Flow24x24 = create_24x24_flow_matrix(not_home_row, side_top, \n",
    "    side_above_3away, side_above_2away, side_above_1away, middle_above_ring, ring_above_middle, outward, \n",
    "    skip_row_3away, skip_row_2away, skip_row_1away, skip_row_0away, same_finger, lateral, same_hand, \n",
    "    shorter_above, adjacent_offset, inside_top, index_above)\n",
    "\n",
    "# Print:\n",
    "print_matrix_info(matrix_data=Flow24x24, matrix_label=\"Flow24x24\", nkeys=24, nlines=30)\n",
    "heatmap(data=Flow24x24, title=\"Flow24x24\", xlabel=\"Key 1\", ylabel=\"Key 2\", print_output=print_output)\n",
    "\n",
    "\n",
    "def create_32x32_flow_matrix(not_home_row, side_top, side_above_3away, side_above_2away, side_above_1away, \n",
    "                             middle_above_ring, ring_above_middle, outward, skip_row_3away, \n",
    "                             skip_row_2away, skip_row_1away, skip_row_0away, same_finger, lateral, \n",
    "                             same_hand, shorter_above, adjacent_offset, inside_top, index_above):\n",
    "\n",
    "    all_32_keys = [1,2,3,4, 5,6,7,8, 9,10,11,12, 13,14,15,16, 17,18,19,20, 21,22,23,24, \n",
    "                   25,26,27, 28,29,30, 31,32]\n",
    "\n",
    "    # Create a matrix and multiply by flow factors that promote easy interkey transitions:\n",
    "    T = np.ones((32, 32))\n",
    "\n",
    "    if lateral < 1.0:\n",
    "        for x in all_32_keys:\n",
    "            for y in [25,26,27, 28,29,30, 31,32]:\n",
    "                T[x-1, y-1] *= lateral\n",
    "                T[y-1, x-1] *= lateral    \n",
    "\n",
    "    # 7.  Promote alternating between hands over uncomfortable transitions with the same hand.\n",
    "    if same_hand < 1.0:\n",
    "        for i in [1,2,3,4,5,6,7,8,9,10,11,12, 25,26,27]:\n",
    "            for j in [1,2,3,4,5,6,7,8,9,10,11,12, 25,26,27]:\n",
    "                T[i-1,j-1] *= same_hand\n",
    "        for i in [13,14,15,16,17,18,19,20,21,22,23,24, 28,29,30,31,32]:\n",
    "            for j in [13,14,15,16,17,18,19,20,21,22,23,24, 28,29,30,31,32]:\n",
    "                T[i-1,j-1] *= same_hand\n",
    "\n",
    "    # 8.  Promote little-to-index-finger roll-ins over index-to-little-finger outsward rolls.\n",
    "    # Penalize (index, little) finger lateral movements:\n",
    "    #  1  2  3  4 25   28 13 14 15 16 31 \n",
    "    #  5  6  7  8 26   29 17 18 19 20 32\n",
    "    #  9 10 11 12 27   30 21 22 23 24\n",
    "    if outward < 1.0:\n",
    "\n",
    "        # same-row roll-outs:\n",
    "        roll_ins = [[1,2],[2,3],[3,4], [5,6],[6,7],[7,8], [9,10],[10,11],[11,12],\n",
    "                    [16,15],[15,14],[14,13], [20,19],[19,18],[18,17], [24,23],[23,22],[22,21]]\n",
    "        for x in roll_ins:\n",
    "            T[x[1]-1, x[0]-1] *= outward\n",
    "\n",
    "        # same-row roll-outs, skipping keys:\n",
    "        roll_ins_skip_keys = [[1,3],[2,4],[1,4], [5,7],[6,8],[5,8], [9,11],[10,12],[9,12],\n",
    "                              [16,14],[15,13],[16,13], [20,18],[19,17],[20,17], [24,22],[23,21],[24,21]]\n",
    "                              #[1,25],[2,25],[3,25],\n",
    "                              #[5,26],[6,26],[7,26],\n",
    "                              #[9,27],[10,27],[11,27],\n",
    "                              #[16,28],[15,28],[14,28],\n",
    "                              #[20,29],[19,29],[18,29],\n",
    "                              #[24,30],[23,30],[22,30],\n",
    "                              #[31,15],[31,14],[31,13],[31,28],\n",
    "                              #[32,19],[32,18],[32,17],[32,29]]\n",
    "        for x in roll_ins_skip_keys:\n",
    "            T[x[1]-1, x[0]-1] *= outward\n",
    "\n",
    "        # adjacent-row roll-outs:\n",
    "        #  1  2  3  4 25   28 13 14 15 16 31 \n",
    "        #  5  6  7  8 26   29 17 18 19 20 32\n",
    "        #  9 10 11 12 27   30 21 22 23 24\n",
    "        roll_ins_adj_rows = [[1,6],[1,7],[1,8],[2,7],[2,8],[3,8], \n",
    "                             [5,2],[5,3],[5,4],[6,3],[6,4],[7,4],\n",
    "                             [5,10],[5,11],[5,12],[6,11],[6,12],[7,12], \n",
    "                             [9,6],[9,7],[9,8],[10,7],[10,8],[11,8],\n",
    "                             [16,19],[16,18],[16,17],[15,18],[15,17],[14,17], \n",
    "                             [20,15],[20,14],[20,13],[19,14],[19,13],[18,13],\n",
    "                             [20,23],[20,22],[20,21],[19,22],[19,21],[18,21], \n",
    "                             [24,19],[24,18],[24,17],[23,18],[23,17],[22,17]]\n",
    "                             #[5,25],[6,25],[7,25],[8,25],\n",
    "                             #[5,27],[6,27],[7,27],[8,27],\n",
    "                             #[1,26],[2,26],[3,26],[4,26],\n",
    "                             #[9,26],[10,26],[11,26],[12,26],\n",
    "                             #[16,29],[15,29],[14,29],[13,29],\n",
    "                             #[24,29],[23,29],[22,29],[21,29],\n",
    "                             #[20,28],[19,28],[18,28],[17,28],\n",
    "                             #[20,30],[19,30],[18,30],[17,30],\n",
    "                             #[31,20],[31,19],[31,18],[31,17],[31,29],\n",
    "                             #[32,16],[32,15],[32,14],[32,13],[32,28],\n",
    "                             #[32,24],[32,23],[32,22],[32,21],[32,30]]\n",
    "        for x in roll_ins_adj_rows:\n",
    "            T[x[1]-1, x[0]-1] *= outward\n",
    "\n",
    "        # upper<->lower row roll-outs:\n",
    "        roll_ins_skip_home = [[1,10],[1,11],[1,12],[2,11],[2,12],[3,12],\n",
    "                              [9,2],[9,3],[9,4],[10,3],[10,4],[11,4],\n",
    "                              [16,23],[16,22],[16,21],[15,22],[15,21],[14,21],\n",
    "                              [24,15],[24,14],[24,13],[23,14],[23,13],[22,13]]\n",
    "                              #[16,30],[15,30],[14,30],[13,30],\n",
    "                              #[9,25],[10,25],[11,25],[12,25],\n",
    "                              #[24,28],[23,28],[22,28],[21,28],\n",
    "                              #[1,27],[2,27],[3,27],[4,27], \n",
    "                              #[31,24],[31,23],[31,22],[31,21],[31,30]]\n",
    "        for x in roll_ins_skip_home:\n",
    "            T[x[1]-1, x[0]-1] *= outward\n",
    "\n",
    "    # 9.  Avoid stretching shorter fingers up and longer fingers down.\n",
    "    #  1  2  3  4 25   28 13 14 15 16 31 \n",
    "    #  5  6  7  8 26   29 17 18 19 20 32\n",
    "    #  9 10 11 12 27   30 21 22 23 24\n",
    "    if index_above < 1.0:\n",
    "        for x in [4]:\n",
    "            for y in [4,5,6,7,8,26,9,10,11,12,27,28,13,14,15,16,31,29,17,18,19,20,32,30,21,22,23,24]:\n",
    "                T[x-1, y-1] *= index_above\n",
    "                T[y-1, x-1] *= index_above\n",
    "        for x in [25]:\n",
    "            for y in [25,5,6,7,8,26,9,10,11,12,27,28,13,14,15,16,31,29,17,18,19,20,32,30,21,22,23,24]:\n",
    "                T[x-1, y-1] *= index_above\n",
    "                T[y-1, x-1] *= index_above\n",
    "        for x in [13]:\n",
    "            for y in [1,2,3,4,25,5,6,7,8,26,9,10,11,12,27,13,29,17,18,19,20,32,30,21,22,23,24]:\n",
    "                T[x-1, y-1] *= index_above\n",
    "                T[y-1, x-1] *= index_above\n",
    "        for x in [28]:\n",
    "            for y in [1,2,3,4,25,5,6,7,8,26,9,10,11,12,27,28,29,17,18,19,20,32,30,21,22,23,24]:\n",
    "                T[x-1, y-1] *= index_above\n",
    "                T[y-1, x-1] *= index_above\n",
    "    if inside_top < 1.0:\n",
    "        for x in [4,25,28,13]:\n",
    "            for j in range(0,32):\n",
    "                T[x-1, j] *= inside_top\n",
    "                T[j, x-1] *= inside_top\n",
    "    if side_top < 1.0:\n",
    "        for x in [1,4,25,28,13,16,31]:\n",
    "            for j in range(0,32):\n",
    "                T[x-1, j] *= side_top\n",
    "                T[j, x-1] *= side_top\n",
    "    if side_above_1away < 1.0:\n",
    "        for x in [1]:\n",
    "            for y in [6,10]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [5]:\n",
    "            for y in [10]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [4,25]:\n",
    "            for y in [7,11]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [8,26]:\n",
    "            for y in [11]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [13,28]:\n",
    "            for y in [18,22]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [17,29]:\n",
    "            for y in [22]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [16,31]:\n",
    "            for y in [19,23]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [20,32]:\n",
    "            for y in [23]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "    if side_above_2away < 1.0:\n",
    "        for x in [1]:\n",
    "            for y in [7,11]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [5]:\n",
    "            for y in [11]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [4,25]:\n",
    "            for y in [6,10]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [8,26]:\n",
    "            for y in [10]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [13,28]:\n",
    "            for y in [19,23]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [17,29]:\n",
    "            for y in [23]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [16,31]:\n",
    "            for y in [18,22]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [20,32]:\n",
    "            for y in [22]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "    if side_above_3away < 1.0:\n",
    "        for x in [1]:\n",
    "            for y in [8,12,26,27]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [5]:\n",
    "            for y in [12,27]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [4,25]:\n",
    "            for y in [5,9]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [8,26]:\n",
    "            for y in [9]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [13,28]:\n",
    "            for y in [20,24,32]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [17,29]:\n",
    "            for y in [24]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [16,31]:\n",
    "            for y in [17,21,29,30]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [20,32]:\n",
    "            for y in [21,30]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "\n",
    "\n",
    "    #  1  2  3  4 25   28 13 14 15 16 31 \n",
    "    #  5  6  7  8 26   29 17 18 19 20 32\n",
    "    #  9 10 11 12 27   30 21 22 23 24\n",
    "    if shorter_above < 1.0:\n",
    "        for x in [1]:\n",
    "            for y in [6,7,8,26,10,11,12,27]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [2]:\n",
    "            for y in [7,11]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [4]:\n",
    "            for y in [6,7,10,11]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [25]:\n",
    "            for y in [6,7,10,11]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "\n",
    "        for x in [5]:\n",
    "            for y in [10,11,12,27]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [6]:\n",
    "            for y in [11]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [8]:\n",
    "            for y in [10,11]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [26]:\n",
    "            for y in [10,11]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "\n",
    "        for x in [16]:\n",
    "            for y in [29,17,18,19,30,21,22,23]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [31]:\n",
    "            for y in [29,17,18,19,30,21,22,23]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [15]:\n",
    "            for y in [18,22]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [13]:\n",
    "            for y in [18,19,22,23]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [28]:\n",
    "            for y in [18,19,22,23]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "\n",
    "        for x in [20]:\n",
    "            for y in [30,21,22,23]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [32]:\n",
    "            for y in [30,21,22,23]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [19]:\n",
    "            for y in [22]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [17]:\n",
    "            for y in [22,23]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [29]:\n",
    "            for y in [22,23]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "\n",
    "    if ring_above_middle < 1.0:\n",
    "        ring_above_middles =  [[2,7],[6,11],[2,11],\n",
    "                            [15,18],[19,22],[15,22]]\n",
    "        for x in ring_above_middles:\n",
    "            T[x[0]-1, x[1]-1] *= ring_above_middle\n",
    "            T[x[1]-1, x[0]-1] *= ring_above_middle\n",
    "\n",
    "    if middle_above_ring < 1.0:\n",
    "        middle_above_rings =  [[6,3],[10,7],[10,3],\n",
    "                            [19,14],[23,18],[23,14]]\n",
    "        for x in middle_above_rings:\n",
    "            T[x[0]-1, x[1]-1] *= middle_above_ring\n",
    "            T[x[1]-1, x[0]-1] *= middle_above_ring\n",
    "\n",
    "    # 10. Avoid using the same finger.\n",
    "    #  1  2  3  4 25   28 13 14 15 16 31 \n",
    "    #  5  6  7  8 26   29 17 18 19 20 32\n",
    "    #  9 10 11 12 27   30 21 22 23 24\n",
    "    if same_finger < 1.0:\n",
    "        same_fingers = [[1,5],[5,9],[1,9], [2,6],[6,10],[2,10], \n",
    "                        [3,7],[7,11],[3,11], [4,8],[8,12],[4,12],\n",
    "                        [25,26],[26,27],[25,27], [28,29],[29,30],[28,30], [31,32],\n",
    "                        [4,25],[4,26],[4,27], [8,25],[8,26],[8,27], [12,25],[12,26],[12,27],\n",
    "                        [13,28],[13,29],[13,30], [17,28],[17,29],[17,30], [21,28],[21,29],[21,30],\n",
    "                        [31,16],[31,20],[31,24], [32,16],[32,20],[32,24],\n",
    "                        [13,17],[17,21],[13,21], [14,18],[18,22],[14,22], \n",
    "                        [15,19],[19,23],[15,23], [16,20],[20,24],[16,24]] \n",
    "        for x in same_fingers:\n",
    "            T[x[0]-1, x[1]-1] *= same_finger\n",
    "            T[x[1]-1, x[0]-1] *= same_finger\n",
    "\n",
    "    # 11. Avoid the upper and lower rows.\n",
    "    if not_home_row < 1.0:\n",
    "        not_home_row_keys = [1,2,3,4,25, 9,10,11,12,27, 28,13,14,15,16,31, 30,21,22,23,24]\n",
    "        for x in not_home_row_keys:\n",
    "            for j in range(0,32):\n",
    "                T[x-1, j] *= not_home_row\n",
    "                T[j, x-1] *= not_home_row\n",
    "                \n",
    "    # 12. Avoid skipping over the home row.\n",
    "    #  1  2  3  4 25   28 13 14 15 16 31 \n",
    "    #  5  6  7  8 26   29 17 18 19 20 32\n",
    "    #  9 10 11 12 27   30 21 22 23 24\n",
    "    if skip_row_0away < 1.0:\n",
    "        skip_top = [1, 2, 3, 4, 4,25,25, 28,28,13,13,14,15,16,31] \n",
    "        skip_bot = [9,10,11,12,27,12,27, 30,21,30,21,22,23,24,24] \n",
    "        for ix, x in enumerate(skip_top):\n",
    "            y = skip_bot[ix]\n",
    "            T[x-1, y-1] *= skip_row_0away\n",
    "            T[y-1, x-1] *= skip_row_0away\n",
    "    if skip_row_1away < 1.0:\n",
    "        skip_top = [1, 2, 2, 3, 3, 4, 4,25, 28,13,13,14,14,15,15,16,31] \n",
    "        skip_bot = [10,9,11,10,12,11,27,11, 22,30,22,21,23,22,24,23,23] \n",
    "        for ix, x in enumerate(skip_top):\n",
    "            y = skip_bot[ix]\n",
    "            T[x-1, y-1] *= skip_row_1away\n",
    "            T[y-1, x-1] *= skip_row_1away\n",
    "    if skip_row_2away < 1.0:\n",
    "        skip_top = [1,  2,3, 4,25, 28,13,14,15,16,31] \n",
    "        skip_bot = [11,12,9,10,10, 23,23,24,21,22,22] \n",
    "        for ix, x in enumerate(skip_top):\n",
    "            y = skip_bot[ix]\n",
    "            T[x-1, y-1] *= skip_row_2away\n",
    "            T[y-1, x-1] *= skip_row_2away\n",
    "    if skip_row_3away < 1.0:\n",
    "        skip_top = [1, 4,25, 28,13,16,16,31,31] \n",
    "        skip_bot = [12,9, 9, 24,24,21,30,21,30] \n",
    "        for ix, x in enumerate(skip_top):\n",
    "            y = skip_bot[ix]\n",
    "            T[x-1, y-1] *= skip_row_3away\n",
    "            T[y-1, x-1] *= skip_row_3away\n",
    "                \n",
    "    Flow32x32 = T\n",
    "\n",
    "    # Normalize matrix with min-max scaling to a range with maximum = 1:\n",
    "    newMin = np.min(Flow32x32) / np.max(Flow32x32)\n",
    "    newMax = 1.0\n",
    "    Flow32x32 = newMin + (Flow32x32 - np.min(Flow32x32)) * (newMax - newMin) / (np.max(Flow32x32) - np.min(Flow32x32))\n",
    "\n",
    "    return Flow32x32\n",
    "\n",
    "Flow32x32 = create_32x32_flow_matrix(not_home_row, side_top, \n",
    "    side_above_3away, side_above_2away, side_above_1away, middle_above_ring, ring_above_middle, outward, \n",
    "    skip_row_3away, skip_row_2away, skip_row_1away, skip_row_0away, same_finger, lateral, same_hand, \n",
    "    shorter_above, adjacent_offset, inside_top, index_above)\n",
    "\n",
    "# Print:\n",
    "print_matrix_info(matrix_data=Flow32x32, matrix_label=\"Flow32x32\", nkeys=32, nlines=30)\n",
    "heatmap(data=Flow32x32, title=\"Flow32x32\", xlabel=\"Key 1\", ylabel=\"Key 2\", print_output=print_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WMvP493uDzSU"
   },
   "source": [
    "## Combine Strength and Flow matrices  <a name=\"strengthflow\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 695
    },
    "colab_type": "code",
    "id": "UP7FUBR2DzSX",
    "outputId": "5dc11788-2c69-4f69-ab60-a07ac17e092f"
   },
   "outputs": [],
   "source": [
    "# %load code/combine_scoring_matrices.py\n",
    "# 24 keys:\n",
    "Factors24x24 = Flow24x24\n",
    "if apply_strength:\n",
    "    Factors24x24 = Strength24x24 * Factors24x24\n",
    "\n",
    "# Print:\n",
    "print_matrix_info(matrix_data=Factors24x24, matrix_label=\"Factors24x24\", nkeys=24, nlines=30)\n",
    "heatmap(data=Factors24x24, title=\"Factors24x24\", xlabel=\"Key 1\", ylabel=\"Key 2\", print_output=print_output)\n",
    "\n",
    "# Save:\n",
    "if print_output:\n",
    "    file = open(\"Factors24x24.txt\", \"w+\")\n",
    "    file.write(str(Factors24x24))\n",
    "    file.close()\n",
    "\n",
    "\n",
    "# 32 keys:\n",
    "Factors32x32 = Flow32x32\n",
    "if apply_strength:\n",
    "    Factors32x32 = Strength32x32 * Factors32x32\n",
    "\n",
    "# Print:\n",
    "print_matrix_info(matrix_data=Factors32x32, matrix_label=\"Factors32x32\", nkeys=32, nlines=30)\n",
    "heatmap(data=Factors32x32, title=\"Factors32x32\", xlabel=\"Key 1\", ylabel=\"Key 2\", print_output=print_output)\n",
    "\n",
    "# Save:\n",
    "if print_output:\n",
    "    file = open(\"Factors32x32.txt\", \"w+\")\n",
    "    file.write(str(Factors32x32))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four steps\n",
    "\n",
    "We will assign letters to keys by choosing the arrangement with the highest score according to our scoring model. However, there are over four hundred septillion, or four hundred trillion trillion (26! = 403,291,461,126,605,635,584,000,000, or 4.032914611 E+26) possible arrangements of 26 letters (24! = 6.204484017 E+23), so we will arrange the letters in four steps, based on ergonomics principles. These consist of (Step 1) assigning the eight most frequent letters to different keys, optimizing assignment of the remaining (Step 2) eight most frequent letters, and (Step 3) eight least frequent letters (besides Z and Q), and (Step 4) exchanging letters. \n",
    "\n",
    "## Step 1: Define the shape of the key layout to minimize lateral finger movements<a name=\"step1\">\n",
    "\n",
    "We will assign 24 letters to 8 columns of keys separated by two middle columns reserved for punctuation. These 8 columns require no lateral finger movements when touch typing, since there is one column per finger. The most comfortable keys include the left and right home rows (keys 5-8 and 17-20), the top-center keys (2,3 and 14,15) that allow the longer middle and ring fingers to uncurl upwards, as well as the bottom corner keys (9,12 and 21,24) that allow the shorter fingers to curl downwards. We will assign the two least frequent letters, Z and Q (or J), to the two hardest-to-reach keys lying outside the 24-key columns in the upper right (25 and 26):\n",
    "\n",
    "        Left:            Right:\n",
    "     1  2  3  4       13 14 15 16 25\n",
    "     5  6  7  8       17 18 19 20 26\n",
    "     9 10 11 12       21 22 23 24\n",
    "\n",
    "We will consider the most comfortable keys to be those typed by either hand on the home row, by the ring and middle finger above the home row, and by the index and little finger below the home row, with a preference for the strongest (index and middle) fingers:\n",
    "    \n",
    "     -  2  3  -        - 14 15  -  \n",
    "     5  6  7  8       17 18 19 20  \n",
    "     9  -  - 12       21  -  - 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "REInHU9tdYLP"
   },
   "source": [
    "## Step 2: Arrange the most frequent letters based on comfort and bigram frequencies  <a name=\"step2\">\n",
    "\n",
    "In prior experiments using the methods below, all vowels consistently automatically clustered together. Below, we will arrange vowels on one side and the most frequent consonants to the other side to encourage balance and alternation across hands. Since aside from the letters Z and Q there is symmetry across left and right sides, we will decide later which side the vowels and which side the most frequent consonants should go.\n",
    "\n",
    "### Vowels\n",
    "    \n",
    "**E**, T, **A, O, I**, N, S, R, H, L, D, C, U, M, F, P, G, W, Y, B, V, K, X, J, Q, Z\n",
    "\n",
    "The highest frequency bigrams that contain two vowels are listed below in bold, with more than 10 billion instances in Peter Norvig's analysis of Google data:\n",
    "\n",
    "**OU, IO, EA, IE**, AI, IA, EI, UE, UA, AU, UI, OI, EO, OA, OE \n",
    "    \n",
    "     OU  24,531,132,241\n",
    "     IO  23,542,263,265\n",
    "     EA  19,403,941,063\n",
    "     IE  10,845,731,320\n",
    "     AI   8,922,759,715\n",
    "     IA   8,072,199,471   \n",
    "     EI   5,169,898,489\n",
    "     UE   4,158,448,570       \n",
    "     UA   3,844,138,094   \n",
    "     AU   3,356,322,923\n",
    "     UI   2,852,182,384\n",
    "     OI   2,474,275,212\n",
    "     EO   2,044,268,477\n",
    "     OA   1,620,913,259\n",
    "     OE   1,089,254,517 \n",
    "   \n",
    "We will assign the most frequent vowels with over 100 billion instances in Norvig's analysis (E=445,A=331,O=272,I=270) to four of the six most comfortable keys on the left side of the keyboard (keys 2,3,5,6,7,8). We will assign the letter E, the most frequent in the English language, to either of the strongest (index and middle) fingers on the home row, and assign the other three vowels such that (1) the home row keys typed by the index and middle fingers are not left vacant, and any top-frequency bigram (more than 10 billion instances in Norvig's analysis) (2) does not use the same finger and (3) reads from left to right (ex: EA, not AE) for ease of typing (inward roll from little to index finger vs. outward roll from index to little finger). These constraints lead to three arrangements of the four vowels:\n",
    "\n",
    "    - - O -    - - O -    - - - -    \n",
    "    - I E A    I - E A    I O E A\n",
    "    - - - -    - - - -    - - - -\n",
    "\n",
    "### Consonants\n",
    "\n",
    "On the right side of the keyboard, we will assign four of the five most frequent consonants (with over 5% or 150 billion instances in Norvig's analysis: T=331, N=258, S=232, R=224, and H=180) to the four home row keys. We will assign the letter T, the most frequent consonant in the English language, to either of the strongest (index and middle) fingers on the home row. As with the left side, letters are placed so that top-frequency bigrams read from right to left (ex: HT, not TH) for ease of typing. The top-frequency bigrams (more than 10 billion instances in Norvig's analysis) include: TH, ND, ST, NT, CH, NS, CT, TR, RS, NC, and RT (below 10 billion instances these bigrams start to occur in reverse, such as RT and TS): \n",
    "    \n",
    "     TH 100,272,945,963  3.56% \n",
    "     ND  38,129,777,631  1.35%\n",
    "     ST  29,704,461,829  1.05%\n",
    "     NT  29,359,771,944  1.04%\n",
    "     CH  16,854,985,236  0.60%\n",
    "     NS  14,350,320,288   \n",
    "     CT  12,997,849,406\n",
    "     TR  12,006,693,396       \n",
    "     RS  11,180,732,354   \n",
    "     NC  11,722,631,112\n",
    "     RT  10,198,055,461   \n",
    "    \n",
    "The above constraints lead to five arrangements of the consonants:\n",
    "\n",
    "    - - - -    - - - -    - - - -    - - - -    - - - -\n",
    "    R T S N    H T S N    H T S R    H T N R    T S N R\n",
    "    - - - -    - - - -    - - - -    - - - -    - - - -\n",
    "\n",
    "We will assign the fifth consonant to a vacant key on the left home row if there is a vacancy, otherwise to the key below the right index finger (any other assignment requires the same finger to type a high-frequency bigram). The resulting 19 initial layouts, each with 15 unassigned keys, are represented below with the three rows on the left and right side of the keyboard as a linear string of letters, with unassigned keys denoted by -.\n",
    "    \n",
    "    --O- HIEA ----    ---- RTSN ----\n",
    "    --O- RIEA ----    ---- HTSN ----\n",
    "    --O- NIEA ----    ---- HTSR ----\n",
    "    --O- SIEA ----    ---- HTNR ----\n",
    "    --O- IHEA ----    ---- RTSN ----\n",
    "    --O- IREA ----    ---- HTSN ----\n",
    "    --O- INEA ----    ---- HTSR ----\n",
    "    --O- ISEA ----    ---- HTNR ----\n",
    "    --O- -IEA ----    ---- RTSN H---\n",
    "    --O- -IEA ----    ---- HTSN R---\n",
    "    --O- -IEA ----    ---- HTSR N---\n",
    "    --O- I-EA ----    ---- RTSN H---\n",
    "    --O- I-EA ----    ---- HTSN R---\n",
    "    --O- I-EA ----    ---- HTSR N---\n",
    "    ---- IOEA ----    ---- RTSN H---\n",
    "    ---- IOEA ----    ---- HTSN R---\n",
    "    ---- IOEA ----    ---- HTSR N---\n",
    "    --O- HIEA ----    ---- TSNR ----\n",
    "    --O- IHEA ----    ---- TSNR ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Optimize assignment of the remaining letters <a name=\"step3\">\n",
    "    \n",
    "We want to assign letters to the 17 unassigned keys in each of the above 19 layouts based on our scoring model. That would mean scoring all possible arrangements for each layout and choosing the arrangement with the highest score, but since there are over 355 trillion (17!) possible ways of arranging 17 letters, we will break up the assignment into two stages for the most frequent and least frequent remaining letters. \n",
    "    \n",
    "### Most frequent letters\n",
    "We will compute scores for every possible arrangement of the seven most frequent of the remaining letters (in bold below) assigned to vacancies among the most comfortable sixteen keys.\n",
    "\n",
    "E, T, A, O, I, N, S, R, H, **L, D, C, U, M, F, P**, G, W, Y, B, V, K, X, J, Q, Z\n",
    "\n",
    "        Left:            Right:\n",
    "     -  2  3  -        - 14 15  -\n",
    "     5  6  7  8       17 18 19 20\n",
    "     9  -  - 12       21  -  - 24\n",
    "\n",
    "Since there are 5,040 (7!) possible combinations of eight letters for each of the 19 layouts, we need to score and evaluate 95,760 layouts. To score each arrangement of letters, we construct a frequency matrix where we multiply a matrix containing the frequency of each ordered pair of letters (bigram) by our flow and strength matrices to compute a score.\n",
    "    \n",
    "### Least frequent letters\n",
    "Next we will compute scores for every possible (40,320 = 8!) arrangement of the least frequent eight letters (in bold below, besides Z and Q) in the remaining keys, after substituting in the 19 results of the above for an additional 766,080 layouts:\n",
    "\n",
    "E, T, A, O, I, N, S, R, H, L, D, C, U, M, F, P, **G, W, Y, B, V, K, X, J**, Q, Z\n",
    "\n",
    "        Left:            Right:\n",
    "     1  -  -  4       13  -  - 16\n",
    "     -  -  -  -        -  -  -  -\n",
    "     - 10 11  -        - 22 23  -\n",
    "     \n",
    "### Further optimize layouts by exchanging more letters\n",
    "\n",
    "If we relax the above fixed initializations and permit further exchange of letters, then we can search for even higher-scoring layouts. As a final optimization step we exchange letters, eight keys at a time (8! = 40,320) selected twice in 14 different ways, in each of the above 19 layouts, to score a total of 21,450,240 more combinations. We allow the following keys to exchange letters:\n",
    "\n",
    "    1. Top rows\n",
    "    2. Bottom rows\n",
    "    3. Top and bottom rows on the right side\n",
    "    4. Top and bottom rows on the left side\n",
    "    5. Top right and bottom left rows\n",
    "    6. Top left and bottom right rows\n",
    "    7. Center of the top and bottom rows on both sides\n",
    "    8. The eight corners\n",
    "    9. Left half of the top and bottom rows on both sides\n",
    "    10. Right half of the top and bottom rows on both sides\n",
    "    11. Left half of non-home rows on the left and right half of the same rows on the right\n",
    "    12. Right half of non-home rows on the left and left half of the same rows on the right\n",
    "    13. Top center and lower sides\n",
    "    14. Top sides and lower center\n",
    "    15. Repeat 1-14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NOTE: This procedure takes hours to run.\n",
    "\n",
    "    --O- HIEA ----    ---- RTSN ----\n",
    "    --O- RIEA ----    ---- HTSN ----\n",
    "    --O- NIEA ----    ---- HTSR ----\n",
    "    --O- SIEA ----    ---- HTNR ----\n",
    "    --O- IHEA ----    ---- RTSN ----\n",
    "    --O- IREA ----    ---- HTSN ----\n",
    "    --O- INEA ----    ---- HTSR ----\n",
    "    --O- ISEA ----    ---- HTNR ----\n",
    "    --O- -IEA ----    ---- RTSN H---\n",
    "    --O- -IEA ----    ---- HTSN R---\n",
    "    --O- -IEA ----    ---- HTSR N---\n",
    "    --O- I-EA ----    ---- RTSN H---\n",
    "    --O- I-EA ----    ---- HTSN R---\n",
    "    --O- I-EA ----    ---- HTSR N---\n",
    "    ---- IOEA ----    ---- RTSN H---\n",
    "    ---- IOEA ----    ---- HTSN R---\n",
    "    ---- IOEA ----    ---- HTSR N---\n",
    "    --O- HIEA ----    ---- TSNR ----\n",
    "    --O- IHEA ----    ---- TSNR ----\n",
    "\n",
    "\"\"\"\n",
    "fixed_letter_lists1 = [\n",
    "    ['O','H','I','E','A','R','T','S','N'],\n",
    "    ['O','R','I','E','A','H','T','S','N'],\n",
    "    ['O','N','I','E','A','H','T','S','R'],\n",
    "    ['O','S','I','E','A','H','T','N','R'],\n",
    "    ['O','I','H','E','A','R','T','S','N'],\n",
    "    ['O','I','R','E','A','H','T','S','N'],\n",
    "    ['O','I','N','E','A','H','T','S','R'],\n",
    "    ['O','I','S','E','A','H','T','N','R'],\n",
    "    ['O','I','E','A','R','T','S','N','H'],\n",
    "    ['O','I','E','A','H','T','S','N','R'],\n",
    "    ['O','I','E','A','H','T','S','R','N'],\n",
    "    ['O','I','E','A','R','T','S','N','H'],\n",
    "    ['O','I','E','A','H','T','S','N','R'],\n",
    "    ['O','I','E','A','H','T','S','R','N'],\n",
    "    ['I','O','E','A','R','T','S','N','H'],\n",
    "    ['I','O','E','A','H','T','S','N','R'],\n",
    "    ['I','O','E','A','H','T','S','R','N'],\n",
    "    ['O','H','I','E','A','T','S','N','R'],\n",
    "    ['O','I','H','E','A','T','S','N','R']]\n",
    "\n",
    "# Keys for step 1:\n",
    "#     -  2  3  -        - 14 15  -\n",
    "#     5  6  7  8       17 18 19 20\n",
    "#     9  -  - 12       21  -  - 24\n",
    "keys1  = [2,3,   5,6,7,8, 9,12,  14,15, 17,18,19,20, 21,24]\n",
    "\n",
    "# Indices for step 1:\n",
    "#     -  0  1  -        -  8  9  -\n",
    "#     2  3  4  5       10 11 12 13\n",
    "#     6  -  -  7       14  -  - 15\n",
    "fixed_letter_index_lists1 = [[1, 2,3,4,5, 10,11,12,13],\n",
    "                             [1, 2,3,4,5, 10,11,12,13],\n",
    "                             [1, 2,3,4,5, 10,11,12,13],\n",
    "                             [1, 2,3,4,5, 10,11,12,13],\n",
    "                             [1, 2,3,4,5, 10,11,12,13],\n",
    "                             [1, 2,3,4,5, 10,11,12,13],\n",
    "                             [1, 2,3,4,5, 10,11,12,13],\n",
    "                             [1, 2,3,4,5, 10,11,12,13],\n",
    "                             [1,   3,4,5, 10,11,12,13, 14],\n",
    "                             [1,   3,4,5, 10,11,12,13, 14],\n",
    "                             [1,   3,4,5, 10,11,12,13, 14],\n",
    "                             [1, 2,  4,5, 10,11,12,13, 14],\n",
    "                             [1, 2,  4,5, 10,11,12,13, 14],\n",
    "                             [1, 2,  4,5, 10,11,12,13, 14],\n",
    "                             [   2,3,4,5, 10,11,12,13, 14],\n",
    "                             [   2,3,4,5, 10,11,12,13, 14],\n",
    "                             [   2,3,4,5, 10,11,12,13, 14],\n",
    "                             [1, 2,3,4,5, 10,11,12,13],\n",
    "                             [1, 2,3,4,5, 10,11,12,13]]\n",
    "open_letter_index_lists1  = [[0, 6,7, 8,9, 14,15],\n",
    "                             [0, 6,7, 8,9, 14,15],\n",
    "                             [0, 6,7, 8,9, 14,15],\n",
    "                             [0, 6,7, 8,9, 14,15],\n",
    "                             [0, 6,7, 8,9, 14,15],\n",
    "                             [0, 6,7, 8,9, 14,15],\n",
    "                             [0, 6,7, 8,9, 14,15],\n",
    "                             [0, 6,7, 8,9, 14,15],\n",
    "                             [0, 2, 6,7, 8,9, 15],\n",
    "                             [0, 2, 6,7, 8,9, 15],\n",
    "                             [0, 2, 6,7, 8,9, 15],\n",
    "                             [0, 3, 6,7, 8,9, 15],\n",
    "                             [0, 3, 6,7, 8,9, 15],\n",
    "                             [0, 3, 6,7, 8,9, 15],\n",
    "                             [0,1,  6,7, 8,9, 15],\n",
    "                             [0,1,  6,7, 8,9, 15],\n",
    "                             [0,1,  6,7, 8,9, 15],\n",
    "                             [0, 6,7, 8,9, 14,15],\n",
    "                             [0, 6,7, 8,9, 14,15]]\n",
    "\n",
    "# All 24 key indices:\n",
    "#     0  1  2  3       12 13 14 15\n",
    "#     4  5  6  7       16 17 18 19\n",
    "#     8  9 10 11       20 21 22 23\n",
    "# Open indices:\n",
    "#     0  -  -  3       12  -  - 15\n",
    "#     -  -  -  -        -  -  -  -\n",
    "#     -  9 10  -        - 21 22  -\n",
    "fixed_letter_indices2 = [1,2, 4,5,6,7, 8,11, 13,14, 16,17,18,19, 20,23]\n",
    "open_letter_indices2  = [0,3, 9,10, 12,15, 21,22]\n",
    "fixed_letter_index_lists3 = [[2, 4,5,6,7, 16,17,18,19],\n",
    "                             [2, 4,5,6,7, 16,17,18,19],\n",
    "                             [2, 4,5,6,7, 16,17,18,19],\n",
    "                             [2, 4,5,6,7, 16,17,18,19],\n",
    "                             [2, 4,5,6,7, 16,17,18,19],\n",
    "                             [2, 4,5,6,7, 16,17,18,19],\n",
    "                             [2, 4,5,6,7, 16,17,18,19],\n",
    "                             [2, 4,5,6,7, 16,17,18,19],\n",
    "                             [2,   5,6,7, 16,17,18,19, 20],\n",
    "                             [2,   5,6,7, 16,17,18,19, 20],\n",
    "                             [2,   5,6,7, 16,17,18,19, 20],\n",
    "                             [2, 4,  6,7, 16,17,18,19, 20],\n",
    "                             [2, 4,  6,7, 16,17,18,19, 20],\n",
    "                             [2, 4,  6,7, 16,17,18,19, 20],\n",
    "                             [   4,5,6,7, 16,17,18,19, 20],\n",
    "                             [   4,5,6,7, 16,17,18,19, 20],\n",
    "                             [   4,5,6,7, 16,17,18,19, 20],\n",
    "                             [2, 4,5,6,7, 16,17,18,19],\n",
    "                             [2, 4,5,6,7, 16,17,18,19]]\n",
    "\n",
    "# Loop through initialized layouts with assigned vowels and consonants \n",
    "top_layouts = []\n",
    "nlists = len(fixed_letter_lists1)\n",
    "for ilist, fixed_letters1 in enumerate(fixed_letter_lists1):\n",
    "    #if ilist in [17]:\n",
    "    fixed_letter_indices1 = fixed_letter_index_lists1[ilist]\n",
    "    fixed_letter_indices3 = fixed_letter_index_lists3[ilist]\n",
    "    open_letter_indices1 = open_letter_index_lists1[ilist]\n",
    "\n",
    "    print('Layout {0}'.format(nlists))\n",
    "    print(*fixed_letters1)\n",
    "\n",
    "    # Most frequent letters\n",
    "    top_permutation1, letter_permutations1, scores1 = permute_optimize_keys(fixed_letters1, fixed_letter_indices1, \n",
    "                                                        open_letter_indices1, letters24, keys1, Factors24x24, \n",
    "                                                        bigrams, bigram_frequencies, verbose=False, ntop=0)\n",
    "\n",
    "    fixed_letters2 = top_permutation1\n",
    "\n",
    "    # Least frequent letters\n",
    "    top_permutation2, letter_permutations2, scores2 = permute_optimize_keys(fixed_letters2, fixed_letter_indices2, \n",
    "                                                        open_letter_indices2, letters24, keys24, Factors24x24, \n",
    "                                                        bigrams, bigram_frequencies, verbose=False, ntop=0)\n",
    "\n",
    "    # Further optimize layouts by exchanging more letters\n",
    "    top_permutation3 = exchange_letters(top_permutation2, fixed_letter_indices3, letters24, keys24, \n",
    "                                        Factors24x24, bigrams, bigram_frequencies, verbose=True, ntop=0)\n",
    "\n",
    "    top_layouts.append(top_permutation3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Load optimized layouts (outcome of above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_top_layouts = True\n",
    "print_layouts = False\n",
    "if load_top_layouts:\n",
    "    top_layouts = [\n",
    "    ['B','Y','O','U','H','I','E','A','V','K','J','X','L','D','G','F','R','T','S','N','C','M','W','P'],\n",
    "    ['W','Y','O','U','R','I','E','A','G','X','J','K','L','D','C','B','H','T','S','N','M','F','V','P'],\n",
    "    ['J','P','O','U','N','I','E','A','B','K','Y','X','M','C','G','V','H','T','S','R','L','D','F','W'],\n",
    "    ['J','P','O','U','S','I','E','A','G','K','Y','X','M','C','W','V','H','T','N','R','D','L','F','B'],\n",
    "    ['J','P','O','U','I','H','E','A','B','K','Y','X','L','D','G','F','R','T','S','N','C','M','V','W'],\n",
    "    ['J','W','O','U','I','R','E','A','G','X','K','Y','L','D','C','B','H','T','S','N','M','F','V','P'],\n",
    "    ['J','P','O','U','I','N','E','A','B','X','K','Y','M','C','G','V','H','T','S','R','L','D','F','W'],\n",
    "    ['J','G','O','U','I','S','E','A','P','X','K','Y','M','C','W','V','H','T','N','R','D','L','F','B'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','K','J','X','L','D','F','B','R','T','S','N','H','M','V','W'],\n",
    "    ['B','Y','O','U','C','I','E','A','G','X','J','K','L','D','W','V','H','T','S','N','R','M','F','P'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','K','J','X','M','L','F','B','H','T','S','R','N','D','V','W'],\n",
    "    ['J','G','O','U','I','C','E','A','B','X','Y','K','L','D','F','V','R','T','S','N','H','M','W','P'],\n",
    "    ['J','G','O','U','I','C','E','A','B','X','Y','K','L','D','W','V','H','T','S','N','R','M','F','P'],\n",
    "    ['P','G','O','U','I','C','E','A','K','X','J','Y','M','L','F','B','H','T','S','R','N','D','V','W'],\n",
    "    ['J','G','U','K','I','O','E','A','P','X','Y','F','L','D','V','B','R','T','S','N','H','M','C','W'],\n",
    "    ['J','G','U','X','I','O','E','A','W','K','Y','F','L','D','C','B','H','T','S','N','R','M','V','P'],\n",
    "    ['J','G','U','K','I','O','E','A','P','X','Y','F','M','L','B','W','H','T','S','R','N','D','V','C'],\n",
    "    ['J','P','O','U','H','I','E','A','G','K','Y','X','M','C','F','V','T','S','N','R','D','L','B','W'],\n",
    "    ['J','P','O','U','I','H','E','A','G','K','Y','X','M','C','F','V','T','S','N','R','D','L','B','W']]\n",
    "if print_layouts:\n",
    "    print('Layouts:\\n')\n",
    "    for layout in top_layouts:\n",
    "        print(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank optimized layouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load code/rank_layouts.py\n",
    "layout_strings = []\n",
    "scores = []\n",
    "for layout in top_layouts:\n",
    "    layout_string = ' '.join(layout)\n",
    "    score = score_layout(Factors24x24, layout, bigrams, bigram_frequencies, verbose=False)\n",
    "    #print('    {0}    {1}'.format(layout_string, score))\n",
    "    layout_strings.append(layout_string)\n",
    "    scores.append(score)\n",
    "\n",
    "# Establish which layouts are within a small difference of the top-scoring layout \n",
    "scores_sorted, ranks_sorted, Isort = rank_within_epsilon(scores, factor24, factor=True, verbose=False)\n",
    "layouts_sorted = []\n",
    "layout_strings_sorted = []\n",
    "for i in Isort:\n",
    "    layouts_sorted.append(top_layouts[i])\n",
    "    layout_strings_sorted.append(layout_strings[i])\n",
    "print('\\n    (#) Rank                                                Score')\n",
    "for i, rank in enumerate(ranks_sorted):\n",
    "    print('    ({0}) {1}:  {2}    {3}'.format(i+1, rank, layout_strings_sorted[i], scores_sorted[i]))\n",
    "\n",
    "print('\\nLayouts tied for first place, with letter frequencies:\\n')\n",
    "#print('    Rank                                                   Score')\n",
    "first_ranks = []\n",
    "first_layouts = []\n",
    "first_layout_strings = []\n",
    "first_scores = []\n",
    "for i, rank in enumerate(ranks_sorted):\n",
    "    if rank == 1:\n",
    "        first_ranks.append(rank)\n",
    "        first_layouts.append(layout_strings_sorted[i])\n",
    "        first_layout_strings.append(layouts_sorted[i])\n",
    "        first_scores.append(scores_sorted[i])    \n",
    "Isort2 = np.argsort([-x for x in first_scores])\n",
    "first_ranks_sorted = []\n",
    "first_layouts_sorted = []\n",
    "first_layout_strings_sorted = []\n",
    "first_scores_sorted = []\n",
    "for i in Isort2:\n",
    "    first_ranks_sorted.append(first_ranks[i])\n",
    "    first_layouts_sorted.append(first_layouts[i])\n",
    "    first_layout_strings_sorted.append(first_layout_strings[i])\n",
    "    first_scores_sorted.append(first_scores[i])\n",
    "#for i, first_layout in enumerate(first_layouts):\n",
    "#    print('    {0}:  {1}    {2}'.format(first_ranks_sorted[i], \n",
    "#                                        first_layout,  # first_layout_strings_sorted[i], \n",
    "#                                        first_scores_sorted[i]))\n",
    "\n",
    "# Print layouts:\n",
    "for i, layout_string in enumerate(first_layout_strings_sorted):\n",
    "    layout = first_layouts_sorted[i]\n",
    "    print('    Layout {0}:\\n'.format(Isort2[i] + 1))\n",
    "    print_layout24(layout_string)\n",
    "    print('')\n",
    "    print_layout24_instances(layout_string, letters24, instances24, bigrams, bigram_frequencies)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized layouts after further exchange of letters, and candidate winner\n",
    "\n",
    "We will select the second layout tied for first place as our candidate winner, so that the most frequent bigram (TH, over 100 billion) is on the home row and easier to type.\n",
    "\n",
    "    Rank                                                   Score\n",
    "    1:  P Y O U C I E A G K J X L D F B R T S N H M V W    0.7079134589554652\n",
    "    1:  B Y O U C I E A G X J K L D W V H T S N R M F P    0.7078676989043136\n",
    "    2:  J G O U I C E A B X Y K L D F V R T S N H M W P    0.7078208372363046\n",
    "    2:  B Y O U H I E A V K J X L D G F R T S N C M W P    0.7078164910125013\n",
    "    2:  J P O U H I E A G K Y X M C F V T S N R D L B W    0.707806617890607\n",
    "    2:  J G O U I C E A B X Y K L D W V H T S N R M F P    0.7077802597858632\n",
    "    3:  P Y O U C I E A G K J X M L F B H T S R N D V W    0.707765513186795\n",
    "    3:  J P O U I H E A G K Y X M C F V T S N R D L B W    0.7077455939244159\n",
    "    3:  J P O U I H E A B K Y X L D G F R T S N C M V W    0.7077426951024633\n",
    "    4:  P G O U I C E A K X J Y M L F B H T S R N D V W    0.7076779754232723\n",
    "    5:  J P O U S I E A G K Y X M C W V H T N R D L F B    0.707608035505442\n",
    "    5:  J G U K I O E A P X Y F L D V B R T S N H M C W    0.707560090465515\n",
    "    5:  W Y O U R I E A G X J K L D C B H T S N M F V P    0.7075589351593826\n",
    "    6:  J G O U I S E A P X K Y M C W V H T N R D L F B    0.707549787929756\n",
    "    6:  J G U X I O E A W K Y F L D C B H T S N R M V P    0.7075212659110061\n",
    "    7:  J W O U I R E A G X K Y L D C B H T S N M F V P    0.7074562433695609\n",
    "    7:  J P O U I N E A B X K Y M C G V H T S R L D F W    0.7074435243752765\n",
    "    7:  J P O U N I E A B K Y X M C G V H T S R L D F W    0.707432984110794\n",
    "    7:  J G U K I O E A P X Y F M L B W H T S R N D V C    0.7074108195944783\n",
    "\n",
    "Above layouts that tied for first place, with letter frequencies (2nd layout identical to Engram v2.0):\n",
    "\n",
    "    P Y O U  L D F B     76  59 272  97  145 136  86  53\n",
    "    C I E A  R T S N    119 270 445 287  224 331 232 258\n",
    "    G K J X  H M V W     67  19   6   8  180  90  38  60\n",
    "\n",
    "    left: 1.725T  right: 1.831T (6.09%)\n",
    "    Total same-finger bigram frequencies:     31002467582\n",
    "    Total bigram inward roll frequencies:   4595272424809\n",
    "\n",
    "\n",
    "    B Y O U  L D W V     53  59 272  97  145 136  60  38\n",
    "    C I E A  H T S N    119 270 445 287  180 331 232 258\n",
    "    G X J K  R M F P     67   8   6  19  224  90  86  76\n",
    "\n",
    "    left: 1.702T  right: 1.854T (8.90%)\n",
    "    Total same-finger bigram frequencies:     31422990907\n",
    "    Total bigram inward roll frequencies:   4595756397870"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: rank variations of top-scoring layouts\n",
    "\n",
    "As an alternative to simply choosing the candidate winner layout, we can generate variations of this layout and find those variants within a small difference of one another and select from among these variants. For this, we select keys to vary, compute scores for every combination of the letters assigned to these keys, and select among those that are tied for first place. Below we vary those keys with different letters in the two layouts tied for first place, except we fix H above R (as in the second layout, our candidate winner) so that the most frequent bigram (TH, over 100 billion) is easy to type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_variants = True\n",
    "if not load_variants:\n",
    "\n",
    "    # Candidate winner above:\n",
    "    #\n",
    "    #  B Y O U  L D W V\n",
    "    #  C I E A  H T S N\n",
    "    #  G X J K  R M F P\n",
    "\n",
    "    #  - Y O U  L D - -\n",
    "    #  C I E A  H T S N\n",
    "    #  G - J -  R M - -\n",
    "\n",
    "    fixed_letters = ['Y','O','U', 'C','I','E','A', 'G','J', 'L','D', 'H','T','S','N', 'R','M']\n",
    "    fixed_letter_indices = [1,2,3, 4,5,6,7, 8,10, 12,13, 16,17,18,19, 20,21]\n",
    "    open_letter_indices  = [0, 9,11, 14,15, 22,23]\n",
    "\n",
    "    top_permutation, letter_permutations, variant_scores = permute_optimize_keys(fixed_letters, \n",
    "        fixed_letter_indices, open_letter_indices, letters24, keys24, Factors24x24, \n",
    "        bigrams, bigram_frequencies, verbose=False, ntop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not load_variants:\n",
    "\n",
    "    nletters = len(fixed_letter_indices) + len(open_letter_indices)\n",
    "    layout_variant_strings = []\n",
    "    for ipermutation, letter_permutation in enumerate(letter_permutations):\n",
    "        letters = np.array(['E' for x in range(nletters)])  # KEEP to initialize!\n",
    "        for imove, open_letter_index in enumerate(open_letter_indices):\n",
    "            letters[open_letter_index] = letter_permutation[imove]\n",
    "        for ifixed, fixed_letter_index in enumerate(fixed_letter_indices):\n",
    "            letters[fixed_letter_index] = fixed_letters[ifixed]\n",
    "        layout_variant_strings.append(letters)\n",
    "\n",
    "    layout_variants = []\n",
    "    for layout_string in layout_variant_strings:\n",
    "        layout = ' '.join(layout_string)\n",
    "        layout_variants.append(layout)\n",
    "\n",
    "    variant_scores_sorted, variant_ranks_sorted, Isort_variants = rank_within_epsilon(variant_scores, \n",
    "            factor24, factor=True, verbose=False)\n",
    "    layout_variants_sorted = []\n",
    "    layout_variant_strings_sorted = []\n",
    "    for i in Isort_variants:\n",
    "        layout_variants_sorted.append(layout_variants[i])\n",
    "        layout_variant_strings_sorted.append(layout_variant_strings[i])\n",
    "\n",
    "    print('    (#) Rank: Layout                                           Score')\n",
    "    for i, rank in enumerate(variant_ranks_sorted):\n",
    "        if rank == 1:\n",
    "            print('    ({0}) {1}:  {2}    {3}'.format(i + 1, rank, \n",
    "                                                      layout_variants_sorted[i], \n",
    "                                                      variant_scores_sorted[i]))\n",
    "    # Print layouts:\n",
    "    Ifirst_place = []\n",
    "    layout_variants_first_place = []\n",
    "    layout_variant_strings_first_place = []\n",
    "    for i, rank in enumerate(variant_ranks_sorted):\n",
    "        if rank == 1:\n",
    "            layout_string = layout_variant_strings_sorted[i]\n",
    "            layout = layout_variants_sorted[i]\n",
    "            print('\\n    Layout {0}:\\n'.format(i + 1))\n",
    "            print_layout24(layout_string)\n",
    "            print('')\n",
    "            print_layout24_instances(layout_string, letters24, instances24, \n",
    "                                     bigrams, bigram_frequencies)\n",
    "\n",
    "            Ifirst_place.append(i)\n",
    "            layout_variants_first_place.append(layout)\n",
    "            layout_variant_strings_first_place.append(layout_string)\n",
    "            \n",
    "    print('')\n",
    "    for i, rank in enumerate(variant_ranks_sorted):\n",
    "        if rank == 1:\n",
    "            print('{0},'.format(layout_variant_strings_sorted[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our candidate winner scored highest among its (7! = 5,040) variants. The 42 variants tied for first place are listed below:\n",
    "\n",
    "    (#) Rank: Layout                                           Score\n",
    "    (1) 1:  B Y O U C I E A G X J K L D W V H T S N R M F P    0.7078676989043137\n",
    "    (2) 1:  B Y O U C I E A G K J X L D W V H T S N R M F P    0.7078625576908392\n",
    "    (3) 1:  W Y O U C I E A G X J K L D V B H T S N R M F P    0.7078577061845288\n",
    "    (4) 1:  P Y O U C I E A G K J X L D W V H T S N R M F B    0.7078565092277237\n",
    "    (5) 1:  W Y O U C I E A G K J X L D V B H T S N R M F P    0.7078522283063508\n",
    "    (6) 1:  B Y O U C I E A G X J K L D V W H T S N R M F P    0.7078519616931854\n",
    "    (7) 1:  P Y O U C I E A G X J K L D W V H T S N R M F B    0.7078517296463457\n",
    "    (8) 1:  B Y O U C I E A G X J K L D W F H T S N R M V P    0.7078490260211918\n",
    "    (9) 1:  B Y O U C I E A G K J X L D V W H T S N R M F P    0.707846820479711\n",
    "    (10) 1:  P Y O U C I E A G K J X L D W B H T S N R M V F    0.7078454560742882\n",
    "    (11) 1:  B Y O U C I E A G K J X L D W F H T S N R M V P    0.7078438848077173\n",
    "    (12) 1:  P Y O U C I E A G K J X L D W B H T S N R M F V    0.7078431094974508\n",
    "    (13) 1:  P Y O U C I E A G K J X L D V B H T S N R M F W    0.7078419742548276\n",
    "    (14) 1:  P Y O U C I E A G K J X L D V W H T S N R M F B    0.7078411358167733\n",
    "    (15) 1:  P Y O U C I E A G X J K L D W B H T S N R M V F    0.70784067649291\n",
    "    (16) 1:  W Y O U C I E A G X J K L D F B H T S N R M V P    0.7078403744444377\n",
    "    (17) 1:  P Y O U C I E A G K J X L D W F H T S N R M V B    0.7078391282354274\n",
    "    (18) 1:  P Y O U C I E A G X J K L D W B H T S N R M F V    0.7078383299160728\n",
    "    (19) 1:  P Y O U C I E A G X J K L D V B H T S N R M F W    0.7078371946734496\n",
    "    (20) 1:  W Y O U C I E A G X J K L D B V H T S N R M F P    0.7078371584583636\n",
    "    (21) 1:  P Y O U C I E A G X J K L D V W H T S N R M F B    0.7078363562353953\n",
    "    (22) 1:  B Y O U C I E A G X J K L D F W H T S N R M V P    0.7078359835497579\n",
    "    (23) 1:  W Y O U C I E A G K J X L D F B H T S N R M V P    0.7078348965662598\n",
    "    (24) 1:  P Y O U C I E A G X J K L D W F H T S N R M V B    0.7078343486540493\n",
    "    (25) 1:  W Y O U C I E A G K J X L D B V H T S N R M F P    0.7078316805801855\n",
    "    (26) 1:  B Y O U C I E A G K J X L D F W H T S N R M V P    0.7078308423362834\n",
    "    (27) 1:  P Y O U C I E A G K J X L D W V H T S N R M B F    0.7078260494151115\n",
    "    (28) 1:  P Y O U C I E A G K J X L D F W H T S N R M V B    0.7078260359767987\n",
    "    (29) 1:  P Y O U C I E A G K J X L D F B H T S N R M V W    0.7078245475443425\n",
    "    (30) 1:  W Y O U C I E A G X J K L D F V H T S N R M B P    0.7078214911264225\n",
    "    (31) 1:  P Y O U C I E A G K J X L D B V H T S N R M F W    0.7078214181411706\n",
    "    (32) 1:  P Y O U C I E A G X J K L D W V H T S N R M B F    0.7078212698337334\n",
    "    (33) 1:  P Y O U C I E A G X J K L D F W H T S N R M V B    0.7078212563954208\n",
    "    (34) 1:  B Y O U C I E A G X J K L D F V H T S N R M W P    0.7078210837714037\n",
    "    (35) 1:  P Y O U C I E A G X J K L D F B H T S N R M V W    0.7078197679629645\n",
    "    (36) 1:  W Y O U C I E A G X J K L D V F H T S N R M B P    0.70781880339861\n",
    "    (37) 1:  B Y O U C I E A G X J K L D V F H T S N R M W P    0.7078184238466051\n",
    "    (38) 1:  W Y O U C I E A G X J K L D B F H T S N R M V P    0.7078172387197521\n",
    "    (39) 1:  P Y O U C I E A G X J K L D B V H T S N R M F W    0.7078166385597925\n",
    "    (40) 1:  W Y O U C I E A G K J X L D F V H T S N R M B P    0.7078160132482443\n",
    "    (41) 1:  P Y O U C I E A G K J X L D V B H T S N R M W F    0.7078159646633373\n",
    "    (42) 1:  B Y O U C I E A G K J X L D F V H T S N R M W P    0.7078159425579292\n",
    "\n",
    "Letters shared across all layout variants tied for first place:\n",
    "\n",
    "    - Y O U  L D - -\n",
    "    C I E A  H T S N\n",
    "    G - J -  R M - -\n",
    "\n",
    "If we list only those layouts in descending order by score that have progressively lower same-finger bigram counts, then we end up with the candidate winner (Variant 1) and Variant 3:\n",
    "        \n",
    "    Variant 1 = Layout 2 above:\n",
    "\n",
    "    B Y O U  L D W V\n",
    "    C I E A  H T S N\n",
    "    G X J K  R M F P\n",
    "\n",
    "     53  59 272  97  145 136  60  38\n",
    "    119 270 445 287  180 331 232 258\n",
    "     67   8   6  19  224  90  86  76\n",
    "\n",
    "    left: 1.702T  right: 1.854T (8.90%)\n",
    "    Total same-finger bigram frequencies:     31422990907\n",
    "    Total bigram inward roll frequencies:   4595756397870\n",
    "\n",
    "    Variant 3:\n",
    "\n",
    "    W Y O U  L D V B\n",
    "    C I E A  H T S N\n",
    "    G X J K  R M F P\n",
    "\n",
    "     60  59 272  97  145 136  38  53\n",
    "    119 270 445 287  180 331 232 258\n",
    "     67   8   6  19  224  90  86  76\n",
    "\n",
    "    left: 1.709T  right: 1.847T (8.07%)\n",
    "    Total same-finger bigram frequencies:     28475089052\n",
    "    Total bigram inward roll frequencies:   4605502028148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_variants:\n",
    "    layout_variant_strings_first_place = [\n",
    "    ['B','Y','O','U','C','I','E','A','G','X','J','K','L','D','W','V','H','T','S','N','R','M','F','P'],\n",
    "    ['B','Y','O','U','C','I','E','A','G','K','J','X','L','D','W','V','H','T','S','N','R','M','F','P'],\n",
    "    ['W','Y','O','U','C','I','E','A','G','X','J','K','L','D','V','B','H','T','S','N','R','M','F','P'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','K','J','X','L','D','W','V','H','T','S','N','R','M','F','B'],\n",
    "    ['W','Y','O','U','C','I','E','A','G','K','J','X','L','D','V','B','H','T','S','N','R','M','F','P'],\n",
    "    ['B','Y','O','U','C','I','E','A','G','X','J','K','L','D','V','W','H','T','S','N','R','M','F','P'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','X','J','K','L','D','W','V','H','T','S','N','R','M','F','B'],\n",
    "    ['B','Y','O','U','C','I','E','A','G','X','J','K','L','D','W','F','H','T','S','N','R','M','V','P'],\n",
    "    ['B','Y','O','U','C','I','E','A','G','K','J','X','L','D','V','W','H','T','S','N','R','M','F','P'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','K','J','X','L','D','W','B','H','T','S','N','R','M','V','F'],\n",
    "    ['B','Y','O','U','C','I','E','A','G','K','J','X','L','D','W','F','H','T','S','N','R','M','V','P'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','K','J','X','L','D','W','B','H','T','S','N','R','M','F','V'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','K','J','X','L','D','V','B','H','T','S','N','R','M','F','W'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','K','J','X','L','D','V','W','H','T','S','N','R','M','F','B'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','X','J','K','L','D','W','B','H','T','S','N','R','M','V','F'],\n",
    "    ['W','Y','O','U','C','I','E','A','G','X','J','K','L','D','F','B','H','T','S','N','R','M','V','P'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','K','J','X','L','D','W','F','H','T','S','N','R','M','V','B'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','X','J','K','L','D','W','B','H','T','S','N','R','M','F','V'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','X','J','K','L','D','V','B','H','T','S','N','R','M','F','W'],\n",
    "    ['W','Y','O','U','C','I','E','A','G','X','J','K','L','D','B','V','H','T','S','N','R','M','F','P'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','X','J','K','L','D','V','W','H','T','S','N','R','M','F','B'],\n",
    "    ['B','Y','O','U','C','I','E','A','G','X','J','K','L','D','F','W','H','T','S','N','R','M','V','P'],\n",
    "    ['W','Y','O','U','C','I','E','A','G','K','J','X','L','D','F','B','H','T','S','N','R','M','V','P'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','X','J','K','L','D','W','F','H','T','S','N','R','M','V','B'],\n",
    "    ['W','Y','O','U','C','I','E','A','G','K','J','X','L','D','B','V','H','T','S','N','R','M','F','P'],\n",
    "    ['B','Y','O','U','C','I','E','A','G','K','J','X','L','D','F','W','H','T','S','N','R','M','V','P'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','K','J','X','L','D','W','V','H','T','S','N','R','M','B','F'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','K','J','X','L','D','F','W','H','T','S','N','R','M','V','B'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','K','J','X','L','D','F','B','H','T','S','N','R','M','V','W'],\n",
    "    ['W','Y','O','U','C','I','E','A','G','X','J','K','L','D','F','V','H','T','S','N','R','M','B','P'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','K','J','X','L','D','B','V','H','T','S','N','R','M','F','W'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','X','J','K','L','D','W','V','H','T','S','N','R','M','B','F'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','X','J','K','L','D','F','W','H','T','S','N','R','M','V','B'],\n",
    "    ['B','Y','O','U','C','I','E','A','G','X','J','K','L','D','F','V','H','T','S','N','R','M','W','P'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','X','J','K','L','D','F','B','H','T','S','N','R','M','V','W'],\n",
    "    ['W','Y','O','U','C','I','E','A','G','X','J','K','L','D','V','F','H','T','S','N','R','M','B','P'],\n",
    "    ['B','Y','O','U','C','I','E','A','G','X','J','K','L','D','V','F','H','T','S','N','R','M','W','P'],\n",
    "    ['W','Y','O','U','C','I','E','A','G','X','J','K','L','D','B','F','H','T','S','N','R','M','V','P'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','X','J','K','L','D','B','V','H','T','S','N','R','M','F','W'],\n",
    "    ['W','Y','O','U','C','I','E','A','G','K','J','X','L','D','F','V','H','T','S','N','R','M','B','P'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','K','J','X','L','D','V','B','H','T','S','N','R','M','W','F'],\n",
    "    ['B','Y','O','U','C','I','E','A','G','K','J','X','L','D','F','V','H','T','S','N','R','M','W','P']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate winning layout <a name=\"step4\">\n",
    "    \n",
    "We evaluate the candidate winner with tests:\n",
    "    \n",
    "    1. Evaluate optimized layouts using interkey speed estimates\n",
    "    2. Evaluate variants of the candidate winner using interkey speed estimates\n",
    "    3. Evaluate sensitivity of the candidate winner to the scoring parameters\n",
    "    4. Search for higher-scoring layouts by rearranging letters\n",
    "    5. Compare with alternate layout based solely on interkey speed estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1. Evaluate optimized layouts using interkey speed estimates   \n",
    "Below we rescore all of the 20 top-scoring layouts optimized from the 20 initialized layouts, and replace the factor matrix with the inter-key speed matrix. The same two layouts that tied for first place do so again.\n",
    "\n",
    "*Note:*\n",
    "    \n",
    "The speed matrix contains normalized interkey stroke times derived from a published study (\"Estimation of digraph costs for keyboard layout optimization\", A Iseri, Ma Eksioglu, International Journal of Industrial Ergonomics, 48, 127-138, 2015). To establish which layouts are within a small difference of each other when using the speed matrix, we define an epsilon equal to 131.58 ms for a single bigram (of the 32^2 possible bigrams), where 131.58 ms is the fastest measured digraph tapping speed (30,000/228 = 131.58 ms) recorded in the above study.\n",
    "    \n",
    "\"Digraph-tapping rate changes dramatically across the digraph types. The range is between 82 and 228 taps per 30 s. The difference is nearly three times between the slowest and the fastest digraphs. From this result it can be concluded that the assignment of letter pairs on the correct digraph keys on the keyboard can have a high impact on the typing speed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_layout_strings = first_layout_strings_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load code/test/score_speed_of_layouts.py\n",
    "data_matrix_speed = Speed24x24  # SpeedSymmetric24x24\n",
    "speed_scores = []\n",
    "for letters in test_layout_strings:\n",
    "    score = score_layout(data_matrix_speed, letters, bigrams, bigram_frequencies, verbose = False) \n",
    "    speed_scores.append(score)\n",
    "\n",
    "speed_scores_sorted, speed_ranks_sorted, Isort_speed = rank_within_epsilon(speed_scores, \n",
    "                                                                    epsilon, factor=False, verbose=False)\n",
    "speed_layouts_sorted = []\n",
    "speed_layout_strings_sorted = []\n",
    "for i in Isort_speed:\n",
    "    speed_layouts_sorted.append(' '.join(test_layout_strings[i]))\n",
    "    speed_layout_strings_sorted.append(test_layout_strings[i])\n",
    "\n",
    "count = 0\n",
    "print('    (#)   Layout                                             Speed score')\n",
    "for i, isort_speed in enumerate(Isort_speed):\n",
    "    if speed_ranks_sorted[isort_speed] == 1:\n",
    "        count += 1\n",
    "        if isort_speed < 9:\n",
    "            s = '  '\n",
    "        else:\n",
    "            s = ' '\n",
    "        print('    ({0}) {1}{2}    {3}'.format(isort_speed+1, s, \n",
    "                                               speed_layouts_sorted[i], \n",
    "                                               speed_scores_sorted[i]))\n",
    "print('\\n    {0} of {1} layouts tied for first place'.format(count, len(test_layout_strings)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2. Evaluate variants of the candidate winner using interkey speed estimates   \n",
    "Below we rescore all of the 5,040 variants of the candidate winner that are tied for first place, replacing the factor matrix with the inter-key speed matrix. The candidate winner scores highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_layout_strings = layout_variant_strings_first_place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load code/test/score_speed_of_layouts.py\n",
    "data_matrix_speed = Speed24x24  # SpeedSymmetric24x24\n",
    "speed_scores = []\n",
    "for letters in test_layout_strings:\n",
    "    score = score_layout(data_matrix_speed, letters,  bigrams, bigram_frequencies, verbose = False) \n",
    "    speed_scores.append(score)\n",
    "\n",
    "speed_scores_sorted, speed_ranks_sorted, Isort_speed = rank_within_epsilon(speed_scores, \n",
    "                                                                    epsilon, factor=False, verbose=False)\n",
    "speed_layouts_sorted = []\n",
    "speed_layout_strings_sorted = []\n",
    "for i in Isort_speed:\n",
    "    speed_layouts_sorted.append(' '.join(test_layout_strings[i]))\n",
    "    speed_layout_strings_sorted.append(test_layout_strings[i])\n",
    "\n",
    "count = 0\n",
    "print('    Layout                                                  Speed score')\n",
    "for i, isort_speed in enumerate(Isort_speed):\n",
    "    if speed_ranks_sorted[isort_speed] == 1:\n",
    "        count += 1\n",
    "        if isort_speed < 9:\n",
    "            s = '  '\n",
    "        else:\n",
    "            s = ' '\n",
    "        print('    ({0}){1}{2}    {3}'.format(isort_speed+1, s, \n",
    "                                              speed_layouts_sorted[i], \n",
    "                                              speed_scores_sorted[i]))\n",
    "print('    {0} of {1} layouts tied for first place'.format(count, len(test_layout_strings)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variant 1 (the candidate winner above) scores highest:\n",
    "\n",
    "    Layout                                                  Speed score\n",
    "    (1)  B Y O U C I E A G X J K L D W V H T S N R M F P    0.7023756439425117\n",
    "    (30) W Y O U C I E A G X J K L D F V H T S N R M B P    0.7023734892525684\n",
    "    (20) W Y O U C I E A G X J K L D B V H T S N R M F P    0.7023700909720256\n",
    "    (6)  B Y O U C I E A G X J K L D V W H T S N R M F P    0.7023688377122477\n",
    "    (22) B Y O U C I E A G X J K L D F W H T S N R M V P    0.702367226885074\n",
    "    (3)  W Y O U C I E A G X J K L D V B H T S N R M F P    0.7023627643568422\n",
    "    (7)  P Y O U C I E A G X J K L D W V H T S N R M F B    0.7023607516204574\n",
    "    (16) W Y O U C I E A G X J K L D F B H T S N R M V P    0.7023603659811735\n",
    "    (8)  B Y O U C I E A G X J K L D W F H T S N R M V P    0.7023583852103916\n",
    "    (21) P Y O U C I E A G X J K L D V W H T S N R M F B    0.7023538733148424\n",
    "    (2)  B Y O U C I E A G K J X L D W V H T S N R M F P    0.7023520610893563\n",
    "    (4)  P Y O U C I E A G K J X L D W V H T S N R M F B    0.7023484279427685\n",
    "    (18) P Y O U C I E A G X J K L D W B H T S N R M F V    0.7023464351081202\n",
    "    (25) W Y O U C I E A G K J X L D B V H T S N R M F P    0.7023461467370498\n",
    "    (9)  B Y O U C I E A G K J X L D V W H T S N R M F P    0.7023452548590922\n",
    "    (19) P Y O U C I E A G X J K L D V B H T S N R M F W    0.7023449431149574\n",
    "    (24) P Y O U C I E A G X J K L D W F H T S N R M V B    0.7023436988861739\n",
    "    (26) B Y O U C I E A G K J X L D F W H T S N R M V P    0.7023436440319186\n",
    "    (14) P Y O U C I E A G K J X L D V W H T S N R M F B    0.7023415496371536\n",
    "    (28) P Y O U C I E A G K J X L D F W H T S N R M V B    0.7023402284944377\n",
    "    (5)  W Y O U C I E A G K J X L D V B H T S N R M F P    0.7023388201218663\n",
    "    (23) W Y O U C I E A G K J X L D F B H T S N R M V P    0.7023364217461976\n",
    "    (11) B Y O U C I E A G K J X L D W F H T S N R M V P    0.7023348023572361\n",
    "    (12) P Y O U C I E A G K J X L D W B H T S N R M F V    0.7023341114304313\n",
    "    (13) P Y O U C I E A G K J X L D V B H T S N R M F W    0.7023326194372687\n",
    "    (17) P Y O U C I E A G K J X L D W F H T S N R M V B    0.7023313752084851\n",
    "    (27) P Y O U C I E A G K J X L D W V H T S N R M B F    0.7023309175507675\n",
    "    (29) P Y O U C I E A G K J X L D F B H T S N R M V W    0.7023301885671278\n",
    "    (15) P Y O U C I E A G X J K L D W B H T S N R M V F    0.7023301589694194\n",
    "    (10) P Y O U C I E A G K J X L D W B H T S N R M V F    0.7023178352917306\n",
    "    \n",
    "    30 of 42 layouts tied for first place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3. Evaluate sensitivity of the candidate winner to the scoring parameters\n",
    "\n",
    "We run a test below on the variants of the candidate winner layout to see how robust they are to removal of scoring parameters. We removed each of the 11 scoring parameters one by one and ranked the new scores for the variants above. Variant 1 (the candidate winner) scores highest for 8 of the 11 cases, and second highest for two other cases, demonstrating that this layout is not sensitive to individual parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load code/test/remove_parameters_rescore.py\n",
    "params0 = [side_above_3away, side_above_2away, side_above_1away, middle_above_ring, ring_above_middle, \n",
    "           outward, skip_row_3away, skip_row_2away, skip_row_1away, skip_row_0away, same_finger]\n",
    "param_names = ['side_above_3away', 'side_above_2away', 'side_above_1away', \n",
    "               'middle_above_ring', 'ring_above_middle', 'outward', 'skip_row_3away', \n",
    "               'skip_row_2away', 'skip_row_1away', 'skip_row_0away', 'same_finger']\n",
    "params_lists = []\n",
    "for i in range(len(params0)):\n",
    "    params_list = params0.copy()\n",
    "    params_list[i] = 1.0\n",
    "    params_lists.append(params_list)\n",
    "\n",
    "for iparam, P in enumerate(params_lists):\n",
    "\n",
    "    print('    Remove parameter {0}:'.format(param_names[iparam]))\n",
    "\n",
    "    data_matrix_param = create_24x24_flow_matrix(not_home_row, side_top,\n",
    "                                                 P[0],P[1],P[2],P[3],P[4],P[5],P[6],P[7],P[8],P[9],P[10],\n",
    "                                                 1,1,1,1,1,1)\n",
    "    if apply_strength:\n",
    "        data_matrix_param = Strength24x24 * data_matrix_param\n",
    "\n",
    "    param_scores = []\n",
    "    for letters in test_layout_strings:\n",
    "        score = score_layout(data_matrix_param, letters, bigrams, bigram_frequencies, verbose=False);\n",
    "        param_scores.append(score)\n",
    "            \n",
    "    param_scores_sorted, param_ranks_sorted, Isort_param = rank_within_epsilon(param_scores, factor24, factor=True, verbose=False)\n",
    "    param_layouts_sorted = []\n",
    "    param_layout_strings_sorted = []\n",
    "    for i in Isort_param:\n",
    "        param_layouts_sorted.append(' '.join(test_layout_strings[i]))\n",
    "        param_layout_strings_sorted.append(test_layout_strings[i])\n",
    "\n",
    "    print('    Variant                                                 Score')\n",
    "    count = 0\n",
    "    for i, isort_param in enumerate(Isort_param):\n",
    "        count += 1\n",
    "        if param_ranks_sorted[isort_param] == 1:\n",
    "            if isort_param < 9:\n",
    "                s = '  '\n",
    "            else:\n",
    "                s = ' '\n",
    "            print('    ({0}){1}{2}    {3}'.format(isort_param+1, s, \n",
    "                                                  param_layouts_sorted[i], \n",
    "                                                  param_scores_sorted[i]))\n",
    "    print('    {0} of {1} layouts tied for first place'.format(count, len(test_layout_strings)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    Remove parameter side_above_3away:\n",
    "    (6)  B Y O U C I E A G X J K L D V W H T S N R M F P    0.7107633027019034\n",
    "    (1)  B Y O U C I E A G X J K L D W V H T S N R M F P    0.7107623334764219\n",
    "    Remove parameter side_above_2away:\n",
    "    (2)  B Y O U C I E A G K J X L D W V H T S N R M F P    0.7130518654000207\n",
    "    (1)  B Y O U C I E A G X J K L D W V H T S N R M F P    0.7130513395263505\n",
    "    Remove parameter side_above_1away:\n",
    "    (5)  W Y O U C I E A G K J X L D V B H T S N R M F P    0.7148772594313253\n",
    "    (3)  W Y O U C I E A G X J K L D V B H T S N R M F P    0.7148711293283665\n",
    "    (2)  B Y O U C I E A G K J X L D W V H T S N R M F P    0.7148593915832421\n",
    "    (23) W Y O U C I E A G K J X L D F B H T S N R M V P    0.7148583101988224\n",
    "    (4)  P Y O U C I E A G K J X L D W V H T S N R M F B    0.7148543601588774\n",
    "    (1)  B Y O U C I E A G X J K L D W V H T S N R M F P    0.7148530691183211\n",
    "    Remove parameter middle_above_ring:\n",
    "    (1)  B Y O U C I E A G X J K L D W V H T S N R M F P    0.7092201999241033\n",
    "    Remove parameter ring_above_middle:\n",
    "    (1)  B Y O U C I E A G X J K L D W V H T S N R M F P    0.7114189279608791\n",
    "    Remove parameter outward:\n",
    "    (1)  B Y O U C I E A G X J K L D W V H T S N R M F P    0.7201947803218552\n",
    "    Remove parameter skip_row_3away:\n",
    "    (1)  B Y O U C I E A G X J K L D W V H T S N R M F P    0.7087608738602452\n",
    "    Remove parameter skip_row_2away:\n",
    "    (1)  B Y O U C I E A G X J K L D W V H T S N R M F P    0.7127292945043059\n",
    "    Remove parameter skip_row_1away:\n",
    "    (1)  B Y O U C I E A G X J K L D W V H T S N R M F P    0.7182207100993533\n",
    "    Remove parameter skip_row_0away:\n",
    "    (1)  B Y O U C I E A G X J K L D W V H T S N R M F P    0.712081162928148\n",
    "    Remove parameter same_finger:\n",
    "    (1)  B Y O U C I E A G X J K L D W V H T S N R M F P    0.7305410820225844"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4. Search for higher-scoring layouts by rearranging letters\n",
    "\n",
    "The following test is to see if allowing random sets of eight letters to rearrange in every possible combination improves the score of the winning layout. After randomly selecting eight letters from the top-scoring layout, creating layouts from every permutation of these letters, and computing their scores, we get identical results as the original layout. We repeated this test hundreds of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner24 = ['B','Y','O','U','C','I','E','A','G','X','J','K','L','D','W','V','H','T','S','N','R','M','F','P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_stability_test = True\n",
    "if run_stability_test:\n",
    "    original_score = score_layout(Factors24x24, winner24, bigrams, bigram_frequencies, verbose=False) \n",
    "    nunber_of_tests = 1000\n",
    "    size_random_set = 8\n",
    "    indices = [0,1, 8,9,10,11, 12,13,14,15, 21,22,23]\n",
    "\n",
    "    #  B Y O U  L D W V\n",
    "    #  C I E A  H T S N\n",
    "    #  G X J K  R M F P\n",
    "\n",
    "    #  0  1  -  -       12 13 14 15\n",
    "    #  -  -  -  -        -  -  -  -\n",
    "    #  8  9 10 11        - 21 22 23\n",
    "\n",
    "    print(original_score)\n",
    "\n",
    "    for i in range(nunber_of_tests):\n",
    "        letters_copy = winner24.copy()    \n",
    "        random_indices = []\n",
    "        while np.size(random_indices) < size_random_set:\n",
    "            random_index = indices[np.int( np.round( (np.size(indices) - 1) * np.random.random(1) )[0])]\n",
    "            if random_index not in random_indices:\n",
    "                random_indices.append(random_index)   \n",
    "        for irand in random_indices:\n",
    "            letters_copy[np.int(irand)] = ''\n",
    "\n",
    "        top_permutation_test1, letter_permutations_test1, scores_test1 = permute_optimize(letters_copy, \n",
    "                            letters24, keys24, Factors24x24, bigrams, bigram_frequencies, verbose=False, ntop=0)\n",
    "\n",
    "        print(i)\n",
    "        if ''.join(top_permutation_test1) != ''.join(winner24) and max(scores_test1) > original_score:\n",
    "            print(max(scores_test1))\n",
    "            print(*top_permutation_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 5. Compare with alternate layout based solely on interkey speed estimates\n",
    "\n",
    "Since we use interkey speed estimates to independently corroborate the practical utility of our top-scoring initialized layouts and variants generated from our candidate winner, the question arises whether a better layout could be generated using the above procedure and based solely on interkey speed estimates. To do this, we simply set apply_strength=False and Factors24x24=Speed24x24 and ran Steps 1 through 3 above. The resulting layouts have two to three times higher same-finger bigram frequencies, which is not a good sign of the ease with which they can be typed. This indirectly demonstrates that fast-to-type layouts do not necessarily translate to less strenuous layouts.\n",
    "\n",
    "    (#) Rank                                                Score\n",
    "    (0) 1:  J Y U G I O E A X K W D L C F V R T S N H M P B    0.7028248210994403\n",
    "    (1) 1:  J Y O F U I E A X K G D L C B V R T S N H M P W    0.7028092866027337\n",
    "    (2) 1:  J B U P I O E A X K Y F L D C V H T S R N M W G    0.7027885065002167\n",
    "    (3) 1:  J P O F U I E A X Y K G L D C V H T S R N M W B    0.7027774348054611\n",
    "    (4) 1:  J Y U G I O E A X K W D L C F V H T S N R M P B    0.7027766978615982\n",
    "    (5) 2:  J Y O F U I E A X K G D L C W V H T S N R M P B    0.7027604410329258\n",
    "    (6) 3:  J Y O F I U E A X K G D L C B V R T S N H M P W    0.7027015337086406\n",
    "    (7) 3:  J P O F I U E A X Y K G L D C V H T S R N M W B    0.7026779438898121\n",
    "    (8) 3:  J Y O F I U E A X K G D L C W V H T S N R M P B    0.7026531181501796\n",
    "    (9) 4:  J U O F I H E A X Y K G D L C V T S N R P M W B    0.7026052409973239\n",
    "    (10) 4:  J U O F H I E A X Y K G D L C V T S N R P M W B    0.7025798551167619\n",
    "    (11) 5:  J U O G I H E A X Y K D C F W V R T S N L M P B    0.7025168489505383\n",
    "    (12) 5:  J U O G H I E A X Y K D C F W V R T S N L M P B    0.7025072606193864\n",
    "    (13) 6:  J G O F I S E A X Y K U D L C V H T N R P M W B    0.7024132916102113\n",
    "    (14) 6:  J Y O F S I E A X K G U D L C V H T N R P M W B    0.7023840624087121\n",
    "    (15) 7:  J W O U I R E A X K Y G L C F V H T S N D M P B    0.7021673985385113\n",
    "    (16) 7:  J P O F I N E A X Y K U M G C V H T S R L D W B    0.7021345744708818\n",
    "    (17) 8:  J Y O F R I E A X K G U L C W V H T S N D M P B    0.7020921733913089\n",
    "    (18) 8:  J P O F N I E A X Y K U M G C V H T S R L D W B    0.7020744010726611\n",
    "\n",
    "Layouts tied for first place, with letter frequencies:\n",
    "\n",
    "    Layout 1:\n",
    "\n",
    "    J Y U G  L C F V\n",
    "    I O E A  R T S N\n",
    "    X K W D  H M P B\n",
    "\n",
    "      6  59  97  67  145 119  86  38\n",
    "    270 272 445 287  224 331 232 258\n",
    "      8  19  60 136  180  90  76  53\n",
    "\n",
    "    left: 1.726T  right: 1.830T (6.03%)\n",
    "    Total same-finger bigram frequencies:     83350937269\n",
    "    Total bigram inward roll frequencies:   4619080035315\n",
    "\n",
    "    Layout 2:\n",
    "\n",
    "    J Y O F  L C B V\n",
    "    U I E A  R T S N\n",
    "    X K G D  H M P W\n",
    "\n",
    "      6  59 272  86  145 119  53  38\n",
    "     97 270 445 287  224 331 232 258\n",
    "      8  19  67 136  180  90  76  60\n",
    "\n",
    "    left: 1.752T  right: 1.804T (2.99%)\n",
    "    Total same-finger bigram frequencies:     85067873377\n",
    "    Total bigram inward roll frequencies:   4595756638318\n",
    "\n",
    "    Layout 3:\n",
    "\n",
    "    J B U P  L D C V\n",
    "    I O E A  H T S R\n",
    "    X K Y F  N M W G\n",
    "\n",
    "      6  53  97  76  145 136 119  38\n",
    "    270 272 445 287  180 331 232 224\n",
    "      8  19  59  86  258  90  60  67\n",
    "\n",
    "    left: 1.678T  right: 1.878T (11.89%)\n",
    "    Total same-finger bigram frequencies:     67426732036\n",
    "    Total bigram inward roll frequencies:   4698191302186\n",
    "\n",
    "    Layout 4:\n",
    "\n",
    "    J P O F  L D C V\n",
    "    U I E A  H T S R\n",
    "    X Y K G  N M W B\n",
    "\n",
    "      6  76 272  86  145 136 119  38\n",
    "     97 270 445 287  180 331 232 224\n",
    "      8  59  19  67  258  90  60  53\n",
    "\n",
    "    left: 1.692T  right: 1.864T (10.17%)\n",
    "    Total same-finger bigram frequencies:     55581492895\n",
    "    Total bigram inward roll frequencies:   4538464009444\n",
    "\n",
    "    Layout 5:\n",
    "\n",
    "    J Y U G  L C F V\n",
    "    I O E A  H T S N\n",
    "    X K W D  R M P B\n",
    "\n",
    "      6  59  97  67  145 119  86  38\n",
    "    270 272 445 287  180 331 232 258\n",
    "      8  19  60 136  224  90  76  53\n",
    "\n",
    "    left: 1.726T  right: 1.830T (6.03%)\n",
    "    Total same-finger bigram frequencies:     83350937269\n",
    "    Total bigram inward roll frequencies:   4619080035315"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign letters Z and Q and test left/right swap\n",
    "\n",
    "Test to see if equal or higher scores are obtained for the following:\n",
    "\n",
    "    1. Assign Z and either Q or J to keys 112 and 113\n",
    "    2. Swap left and right sides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layouts_26letters = [\n",
    "    ['B','Y','O','U','C','I','E','A','G','X','J','K','L','D','W','V','H','T','S','N','R','M','F','P', \"'\",',','-', '\"','.','?', 'Z','Q'],\n",
    "    ['B','Y','O','U','C','I','E','A','G','X','J','K','L','D','W','V','H','T','S','N','R','M','F','P', \"'\",',','-', '\"','.','?', 'Q','Z'],\n",
    "    ['V','W','D','L','N','S','T','H','P','F','M','R','U','O','Y','B','A','E','I','C','K','J','X','G', \"'\",',','-', '\"','.','?', 'Z','Q'],\n",
    "    ['V','W','D','L','N','S','T','H','P','F','M','R','U','O','Y','B','A','E','I','C','K','J','X','G', \"'\",',','-', '\"','.','?', 'Q','Z']]\n",
    "data_matrix = Factors32x32\n",
    "scores_26letters = []\n",
    "for layout_26letters in layouts_26letters:\n",
    "    scores_26letters.append(score_layout(data_matrix, layout_26letters, bigrams, bigram_frequencies, verbose=False))\n",
    "\n",
    "scores_26letters_sorted, ranks_26letters_sorted, Isort_26letters = rank_within_epsilon(scores_26letters, \n",
    "                                                                        factor32, factor=True, verbose=False)\n",
    "print('\\n    Rank                                                                   Score')\n",
    "for i, rank in enumerate(ranks_26letters_sorted):\n",
    "    layout_string = layouts_26letters[Isort_26letters[i]]\n",
    "    layout = ' '.join(layout_string)\n",
    "    print('    {0}:  {1}    {2}'.format(rank, layout, scores_26letters_sorted[i]))\n",
    "    \n",
    "print('')\n",
    "print_layout24(layouts_26letters[0])\n",
    "\n",
    "#bigram_strings = [['f','l'],['f','r'],['p','l'],['p','r'],['w','r'],['w','l']]\n",
    "#for bigram_string in bigram_strings:\n",
    "#    print_bigram_frequency(bigram_string, bigrams, bigram_frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z above Q received the highest score:\n",
    "\n",
    "    Rank                                                                   Score\n",
    "    1:  B Y O U C I E A G X J K L D W V H T S N R M F P ' , - \" . ? Z Q    0.621987268013091\n",
    "    1:  B Y O U C I E A G X J K L D W V H T S N R M F P ' , - \" . ? Q Z    0.6219870422703005\n",
    "    1:  V W D L N S T H P F M R U O Y B A E I C K J X G ' , - \" . ? Q Z    0.6219847143830128\n",
    "    1:  V W D L N S T H P F M R U O Y B A E I C K J X G ' , - \" . ? Z Q    0.6219774708803041\n",
    "    \n",
    "The letters of the Engram layout:\n",
    "\n",
    "    B Y O U  L D W V Z\n",
    "    C I E A  H T S N Q\n",
    "    G X J K  R M F P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner24 = ['B','Y','O','U','C','I','E','A','G','X','J','K','L','D','W','V','H','T','S','N','R','M','F','P']\n",
    "winner32 = ['B','Y','O','U','C','I','E','A','G','X','J','K','L','D','W','V','H','T','S','N','R','M','F','P', \"'\",',','-', '\"','.','?', 'Z','Q']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional stability test\n",
    "\n",
    "The following test is used to compare the score of the winning layout after rearranging random letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_stability_test = True\n",
    "if run_stability_test:\n",
    "    original_score = score_layout(Factors24x24, winner24, bigrams, bigram_frequencies, verbose=False) \n",
    "    nunber_of_tests = 1000\n",
    "    size_random_set = 8\n",
    "    indices = [0,1, 8,9,10,11, 12,13,14,15, 21,22,23]\n",
    "\n",
    "    #  B Y O U  L D W V\n",
    "    #  C I E A  H T S N\n",
    "    #  G X J K  R M F P\n",
    "\n",
    "    #  0  1  -  -       12 13 14 15\n",
    "    #  -  -  -  -        -  -  -  -\n",
    "    #  8  9 10 11        - 21 22 23\n",
    "\n",
    "    print(original_score)\n",
    "\n",
    "    for i in range(nunber_of_tests):\n",
    "        letters_copy = winner24.copy()    \n",
    "        random_indices = []\n",
    "        while np.size(random_indices) < size_random_set:\n",
    "            random_index = indices[np.int( np.round( (np.size(indices) - 1) * np.random.random(1) )[0])]\n",
    "            if random_index not in random_indices:\n",
    "                random_indices.append(random_index)   \n",
    "        for irand in random_indices:\n",
    "            letters_copy[np.int(irand)] = ''\n",
    "\n",
    "        top_permutation_test1, letter_permutations_test1, scores_test1 = permute_optimize(letters_copy, \n",
    "                            letters24, keys24, Factors24x24, bigrams, bigram_frequencies, verbose=False, ntop=0)\n",
    "\n",
    "        print(i)\n",
    "        if ''.join(top_permutation_test1) != ''.join(winner24) and max(scores_test1) > original_score:\n",
    "            print(max(scores_test1))\n",
    "            print(*top_permutation_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TPW3wZw2DzT7"
   },
   "source": [
    "## Step 5: Arrange non-letter characters in easy-to-remember places <a name=\"step5\">\n",
    "    \n",
    "Now that we have all 26 letters accounted for, we turn our attention to non-letter characters, taking into account frequency of punctuation and ease of recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "ul_j8VsZDzT7"
   },
   "source": [
    "### Frequency of punctuation marks\n",
    "\n",
    "  - Statistical values of punctuation frequency in 20 English-speaking countries (Table 1): <br>\n",
    "Sun, Kun & Wang, Rong. (2018). Frequency Distributions of Punctuation Marks in English: Evidence from Large-scale Corpora. English Today. 10.1017/S0266078418000512. <br> \n",
    "https://www.researchgate.net/publication/328512136_Frequency_Distributions_of_Punctuation_Marks_in_English_Evidence_from_Large-scale_Corpora\n",
    "  <br>\"frequency of punctuation marks attested for twenty English-speaking countries and regions... The data were acquired through GloWbE.\"\n",
    "  \"The corpus of GloWbE (2013) is a large English corpus collecting international English from the internet, containing about 1.9 billion words of text from twenty different countries. For further information on the corpora used, see https://corpus.byu.edu/.\"\n",
    "  \n",
    "  - Google N-grams and Twitter analysis: <br>\n",
    "\"Punctuation Input on Touchscreen Keyboards: Analyzing Frequency of Use and Costs\" <br>\n",
    "S Malik, L Findlater - College Park: The Human-Computer Interaction Lab. 2013 <br>\n",
    "https://www.cs.umd.edu/sites/default/files/scholarly_papers/Malik.pdf <br>\n",
    " \"the Twitter corpora included substantially higher punctuation use than the Google corpus,  <br>\n",
    " comprising 7.5% of characters in the mobile tweets and 7.6% in desktop versus only 4.4%...  <br>\n",
    "With the Google corpus,only 6 punctuation symbols (. - ( ) ) appeared more frequently than [q]\"\n",
    "\n",
    "  - \"Frequencies for English Punctuation Marks\" by Vivian Cook <br>\n",
    "http://www.viviancook.uk/Punctuation/PunctFigs.htm  <br>\n",
    " \"Based on a writing system corpus some 459 thousand words long.  <br> \n",
    " This includes three novels of different types (276 thousand words),  <br>\n",
    " selections of articles from two newspapers (55 thousand), <br> \n",
    "one bureaucratic report (94 thousand), and assorted academic papers <br>\n",
    "on language topics (34 thousand). More information is in <br>\n",
    "Cook, V.J. (2013) Standard punctuation and the punctuation of the street <br>\n",
    "in M. Pawlak and L. Aronin (eds.), Essential Topics in Applied Linguistics and Multilingualism,  <br>\n",
    " Springer International Publishing Switzerland (2013), 267-290\"\n",
    "\n",
    "  - \"A Statistical Study of Current Usage in Punctuation\": <br>\n",
    "Ruhlen, H., & Pressey, S. (1924). A Statistical Study of Current Usage in Punctuation. The English Journal, 13(5), 325-331. doi:10.2307/802253\n",
    "\n",
    "  - \"Computer Languages Character Frequency\"\n",
    "by Xah Lee.  <br>\n",
    "Date: 2013-05-23. Last updated: 2020-06-29. <br>\n",
    "http://xahlee.info/comp/computer_language_char_distribution.html <br>\n",
    "NOTE: biased toward C (19.8%) and Py (18.5%), which have high use of \"_\".\n",
    "\n",
    "Frequency: \n",
    "\n",
    "             Sun:     Malik:   Ruhlen:    Cook:            Xah:\n",
    "              /1M   N-gram %   /10,000   /1,000       All%  JS%   Py%\n",
    "\n",
    "    .    42840.02      1.151       535     65.3       6.6   9.4  10.3\n",
    "    ,    44189.96                  556     61.6       5.8   8.9   7.5\n",
    "    \"                  2.284        44     26.7       3.9   1.6   6.2\n",
    "    '     2980.35      0.200        40     24.3       4.4   4.0   8.6\n",
    "    -     9529.78      0.217        21     15.3       4.1   1.9   3.0\n",
    "    ()    4500.81      0.140         7                7.4   9.8   8.1\n",
    "    ;     1355.22      0.096        22      3.2       3.8   8.6\n",
    "    z                  0.09                   -         -\n",
    "    :     3221.82      0.087        11      3.4       3.5   2.8   4.7\n",
    "    ?     4154.78      0.032        14      5.6       0.3\n",
    "    /                  0.019                          4.0   4.9   1.1\n",
    "    !     2057.22      0.013         3      3.3       0.4\n",
    "    _                  0.001                         11.0   2.9  10.5\n",
    "    =                                                 4.4  10.7   5.4\n",
    "    *                                                 3.6   2.1\n",
    "    >                                                 3.0         1.4\n",
    "    $                                                 2.7   1.6\n",
    "    #                                                 2.2         3.2\n",
    "    {}                                                1.9   4.2\n",
    "    <                                                 1.3\n",
    "    &                                                 1.3\n",
    "    \\                                                 1.2         1.1\n",
    "    []                                                0.9   1.9   1.2\n",
    "    @                                                 0.8\n",
    "    |                                                 0.6\n",
    "    +                                                 0.6   1.9\n",
    "    %                                                 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sdl3lLOfDzT8"
   },
   "source": [
    "### Add punctuation keys and number keys\n",
    "\n",
    "We will assign the most frequent punctuation according to Sun, et al (2018) to the six keys in the middle two columns:  . , \" ' - ? ; : () ! _\n",
    "\n",
    "            B Y O U  '   \"   L D W V Z\n",
    "            C I E A  ,   .   H T S N Q\n",
    "            G X J K  -   ?   R M F P\n",
    "\n",
    "We will use the Shift key to group similar punctuation marks (separating and joining marks in the left middle column and closing marks in the right middle column):\n",
    "\n",
    "            B Y O U  '(  \")  L D W V Z\n",
    "            C I E A  ,;  .:  H T S N Q\n",
    "            G X J K  -_  ?!  R M F P\n",
    " \n",
    "**Separating marks (left)**: The comma separates text in lists; the semicolon can be used in place of the comma to separate items in a list (especially if these items contain commas); open parenthesis sets off an explanatory word, phrase, or sentence. \n",
    "\n",
    "**Joining marks (left)**: The apostrophe joins words as contractions; the hyphen joins words as compounds; the underscore joins words in cases where whitespace characters are not permitted (such as in variables or file names). \n",
    "\n",
    "**Closing marks (right)**: A sentence usually ends with a period, question mark, or exclamation mark. The colon ends one statement but precedes the following: an explanation, quotation, list, etc. Double quotes and close parenthesis closes a word, clause, or sentence separated by an open parenthesis.\n",
    "\n",
    "**Number keys**: \n",
    "The numbers are flanked to the left and right by [square brackets], and {curly brackets} accessed by the Shift key. Each of the numbers is paired with a mathematical or logic symbol accessed by the Shift key:\n",
    "    \n",
    "    { | = ~ +   <  >   ^ & % * } \\\n",
    "    [ 1 2 3 4   5  6   7 8 9 0 ] /\n",
    "\n",
    "    1: | (vertical bar or \"pipe\" represents the logical OR operator: 1 stroke, looks like the number one)\n",
    "    2: = (equal: 2 strokes, like the Chinese character for \"2\")\n",
    "    3: ~ (tilde: \"almost equal\", often written with 3 strokes, like the Chinese character for \"3\")\n",
    "    4: + (plus: has four quadrants; resembles \"4\")\n",
    "    5 & 6: < > (\"less/greater than\"; these angle brackets are directly above the other bracket keys)\n",
    "    7: ^ (caret for logical XOR operator as well as exponentiation; resembles \"7\")\n",
    "    8: & (ampersand: logical AND operator; resembles \"8\")\n",
    "    9: % (percent: related to division; resembles \"9\")\n",
    "    0: * (asterisk: for multiplication; resembles \"0\") \n",
    "\n",
    "The three remaining keys in many common keyboards (flanking the upper right hand corner Backspace key) are displaced in special keyboards, such as the Kinesis Advantage and Ergodox. For the top right key, we will assign the forward slash and backslash: / \\\\. For the remaining two keys, we will assign two symbols that in modern usage have significance in social media: the hash/pound sign and the \"at sign\". The hash or hashtag identifies digital content on a specific topic (the Shift key accesses the dollar sign). The \"at sign\" identifies a location or affiliation (such as in email addresses) and acts as a \"handle\" to identify users in popular social media platforms and online forums.\n",
    "\n",
    "The resulting Engram layout:\n",
    "\n",
    "          { | = ~ +   <  >   ^ & % * } \\\n",
    "          [ 1 2 3 4   5  6   7 8 9 0 ] /\n",
    "\n",
    "            B Y O U  '(  \")  L D W V Z\n",
    "            C I E A  ,;  .:  H T S N Q\n",
    "            G X J K  -_  ?!  R M F P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "engram-layout.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

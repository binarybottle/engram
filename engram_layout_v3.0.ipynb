{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J1wRG8laa8Pm"
   },
   "source": [
    "## Arno's Engram keyboard layout\n",
    "\n",
    "##### NOTE: README and evaluation tables NOT UPDATED\n",
    "\n",
    "Engram is a key layout optimized for comfortable and efficient touch typing in English \n",
    "created by [Arno Klein](https://binarybottle.com), \n",
    "with [open source code](https://github.com/binarybottle/engram) to create other optimized key layouts.\n",
    "You can install the Engram layout on [Windows, macOS, and Linux](https://keyman.com/keyboards/engram)\n",
    "or [try it out online](https://keymanweb.com/#en,Keyboard_engram).\n",
    "An article is under review (see the [preprint](https://www.preprints.org/manuscript/202103.0287/v1) for an earlier description and preliminary layout).\n",
    "\n",
    "Letters are optimally arranged according to ergonomics factors that promote reduction of lateral finger movements and more efficient typing of high-frequency letter pairs. The most common punctuation marks are logically grouped together in the middle columns and numbers are paired with mathematical and logic symbols (shown as pairs of default and Shift-key-accessed characters):\n",
    "\n",
    "         [{ 1| 2= 3~ 4+  5<  6>  7^ 8& 9% 0* ]} /\\\n",
    "            pP yY oO uU  '(  \")  lL dD bB VV qQ #$ @`\n",
    "            cC iI eE aA  ,;  .:  rR tT nN sS zZ\n",
    "            gG kK jJ xX  -_  ?!  hH MM wW fF\n",
    "            \n",
    "Letter frequencies (Norvig, 2012), showing that the Engram layout emphasizes keys in the home row and typed above the home row by the middle and ring fingers, and below by the index finger:\n",
    "\n",
    "          P   Y   O   U          L   D   B   V   Q\n",
    "          C   I   E   A          R   T   N   S   Z\n",
    "          G   K   J   X          H   M   W   F\n",
    "\n",
    "         76  59 272  97        145 136  53  38   4\n",
    "        119 270 445 287        224 331 258 232   3\n",
    "         67  19   6   8        180  90  60  86\n",
    "            \n",
    "See below for a full description and comparisons with other key layouts.\n",
    "\n",
    "<!--### Standard diagonal keyboard (default and Shift-key layers)\n",
    "![Standard keyboard](https://github.com/binarybottle/engram/blob/master/assets/engram-800px.png?raw=true)\n",
    "\n",
    "### \"Ergonomic\" orthonormal keyboard (default and Shift-key layers)\n",
    "![Orthonormal keyboard](https://github.com/binarybottle/engram/blob/master/assets/engram-ergo-squeezed-800px.png?raw=true)\n",
    "-->\n",
    "\n",
    "(c) 2021 Arno Klein, MIT license\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "awscg4wBa8Po"
   },
   "source": [
    "# Contents\n",
    "1. [Why a new keyboard layout?](#why)\n",
    "2. [How does Engram compare with other key layouts?](#scores)\n",
    "3. [Guiding criteria](#criteria)\n",
    "4. Setup:\n",
    "    - [Dependencies and functions](#import)\n",
    "    - [Speed matrix](#speed)\n",
    "    - [Strength matrix](#strength)\n",
    "    - [Flow matrix and Engram scoring model](#flow)\n",
    "5. Steps:\n",
    "    - [Step 1: Define the shape of the key layout to minimize lateral finger movements](#step1)\n",
    "    - [Step 2: Arrange the most frequent letters based on comfort and bigram frequencies](#step2)\n",
    "    - [Step 3: Optimize assignment of the remaining letters](#step3)\n",
    "    - [Step 4: Stability tests](#step4)\n",
    "    - [Step 5: Arrange non-letter characters in easy-to-remember places](#step5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SSdE4O9Wa8Pp"
   },
   "source": [
    "## Why a new keyboard layout? <a name=\"why\">\n",
    "\n",
    "**Personal history** <br>\n",
    "In the future, I hope to include an engaging rationale for why I took on this challenge.\n",
    "Suffice to say I love solving problems, and I have battled repetitive strain injury \n",
    "ever since I worked on an old DEC workstation at the MIT Media Lab while composing \n",
    "my thesis back in the 1990s.\n",
    "I have experimented with a wide variety of human interface technologies over the years --\n",
    "voice dictation, one-handed keyboard, keyless keyboard, foot mouse, and ergonomic keyboards \n",
    "like the Kinesis Advantage and [Ergodox](https://configure.ergodox-ez.com/ergodox-ez/layouts/APXBR/latest/0) keyboards with different key switches.\n",
    "While these technologies can significantly improve comfort and reduce strain, \n",
    "if you have to type on a keyboard, it can only help to use a key layout optimized according to sound ergonomics principles. \n",
    "\n",
    "I have used different key layouts (Qwerty, Dvorak, Colemak, etc.)\n",
    "for communications and for writing and programming projects,\n",
    "and have primarily relied on Colemak for the last 10 years. \n",
    "**I find that most to all of these key layouts:**\n",
    "\n",
    "- Demand too much strain on tendons\n",
    "    - *strenuous lateral extension of the index and little fingers*\n",
    "- Ignore the ergonomics of the human hand\n",
    "    - *different finger strengths*\n",
    "    - *different finger lengths*\n",
    "    - *natural roundedness of the hand*\n",
    "    - *easier for shorter fingers to reach below than above longer fingers*\n",
    "    - *easier for longer fingers to reach above than below shorter fingers*\n",
    "    - *ease of little-to-index finger rolls vs. reverse*\n",
    "- Over-emphasize alternation between hands and under-emphasize same-hand, different-finger transitions\n",
    "    - *same-row, adjacent finger transitions are easy and comfortable*\n",
    "    - *little-to-index finger rolls are easy and comfortable*\n",
    "\n",
    "While I used ergonomics principles outlined below and the accompanying code to help generate the Engram layout,\n",
    "I also relied on massive bigram frequency data for the English language. \n",
    "if one were to follow the procedure below and use a different set of bigram frequencies for another language or text corpus,\n",
    "they could create a variant of the Engram layout, say \"Engram-French\", better suited to the French language.\n",
    "    \n",
    "**Why \"Engram\"?** <br>\n",
    "The name is a pun, referring both to \"n-gram\", letter permutations and their frequencies that are used to compute the Engram layout, and \"engram\", or memory trace, the postulated change in neural tissue to account for the persistence of memory, as a nod to my attempt to make this layout easy to remember."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vkv2v3gla8Pt"
   },
   "source": [
    "## How does Engram compare with other key layouts? <a name=\"scores\">\n",
    "\n",
    "Despite the fact that the Engram layout was designed to reduce strain and discomfort, not specifically to increase speed or reduce finger travel from the home row, it scores higher than all other key layouts (Colemak, Dvorak, QWERTY, etc.) for some large, representative, publicly available data (all text sources are listed below and available on [GitHub](https://github.com/binarybottle/text_data)). Below are tables of different prominent key layouts scored using the Engram Scoring Model (detailed below).\n",
    " \n",
    "#### Engram Scoring Model scores (x100) for layouts, based on publicly available text data\n",
    " \n",
    "| Layout | Google bigrams | Alice | Memento | Tweets_100K | Tweets_20K | Tweets_MASC | Spoken_MASC | COCA_blogs | iweb | Monkey | Coder | Rosetta |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| Engram v2 | 61.69 | 61.16 | 61.79 | 62.52 | 59.77 | 61.98 | 61.06 | 61.68 | 61.88 | 61.72 | 62.00 | 61.97 |\n",
    "| Engram v3 | 61.69 | 61.16 | 61.80 | 62.52 | 59.77 | 61.99 | 61.06 | 61.68 | 61.88 | 61.72 | 62.01 | 61.95 |\n",
    "| Exgram | 61.68 | 61.15 | 61.79 | 62.51 | 59.78 | 61.98 | 61.05 | 61.68 | 61.87 | 61.71 | 61.99 | 61.95 |\n",
    "| Halmak | 61.62 | 61.09 | 61.72 | 62.42 | 59.75 | 61.92 | 61.00 | 61.62 | 61.80 | 61.65 | 61.95 | 61.89 |\n",
    "| Hieamtsrn | 61.66 | 61.13 | 61.76 | 62.48 | 59.76 | 61.96 | 61.02 | 61.65 | 61.84 | 61.69 | 61.98 | 61.88 |\n",
    "| Colemak Mod-DH | 61.61 | 61.09 | 61.70 | 62.38 | 59.75 | 61.89 | 60.98 | 61.60 | 61.79 | 61.64 | 61.93 | 61.83 |\n",
    "| Norman | 61.58 | 61.06 | 61.68 | 62.34 | 59.70 | 61.87 | 60.96 | 61.57 | 61.75 | 61.60 | 61.88 | 61.83 |\n",
    "| Workman | 61.60 | 61.08 | 61.71 | 62.39 | 59.72 | 61.89 | 60.98 | 61.59 | 61.77 | 61.63 | 61.92 | 61.86 |\n",
    "| MTGap 2.0 | 61.59 | 61.07 | 61.70 | 62.36 | 59.71 | 61.87 | 60.97 | 61.58 | 61.76 | 61.62 | 61.91 | 61.81 |\n",
    "| QGMLWB | 61.59 | 61.07 | 61.69 | 62.38 | 59.75 | 61.88 | 60.97 | 61.58 | 61.77 | 61.62 | 61.91 | 61.80 |\n",
    "| Colemak | 61.59 | 61.06 | 61.67 | 62.36 | 59.74 | 61.88 | 60.96 | 61.58 | 61.77 | 61.62 | 61.91 | 61.84 |\n",
    "| Asset | 61.56 | 61.04 | 61.67 | 62.33 | 59.74 | 61.85 | 60.95 | 61.55 | 61.73 | 61.58 | 61.87 | 61.83 |\n",
    "| Capewell-Dvorak | 61.56 | 61.05 | 61.65 | 62.34 | 59.69 | 61.85 | 60.95 | 61.55 | 61.73 | 61.59 | 61.86 | 61.78 |\n",
    "| Klausler | 61.58 | 61.06 | 61.68 | 62.37 | 59.74 | 61.87 | 60.97 | 61.57 | 61.75 | 61.60 | 61.89 | 61.81 |\n",
    "| Dvorak | 61.55 | 61.05 | 61.65 | 62.33 | 59.71 | 61.83 | 60.95 | 61.54 | 61.72 | 61.58 | 61.83 | 61.80 |\n",
    "| QWERTY | 61.44 | 60.97 | 61.55 | 62.19 | 59.66 | 61.72 | 60.87 | 61.44 | 61.61 | 61.47 | 61.73 | 61.67 |\n",
    "    \n",
    "---\n",
    "    \n",
    "[Keyboard Layout Analyzer](http://patorjk.com/keyboard-layout-analyzer/) measures for the same text sources:\n",
    "\n",
    "Total finger distances\n",
    "\n",
    "| Layout | Alice | Memento | Tweets_100K | Tweets_20K | Tweets_MASC | Spoken_MASC | COCA_blogs | iweb | Monkey | Coder | Rosetta |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| Engram v3 | 387 | 10524 | 294193 | 94699 | 6460 | 6482 | 247995 | 1400516 | 44689 | 89902 | 4412 |\n",
    "| Engram v2 | 373 | 10533 | 293851 | 94577 | 6640 | 6298 | 252031 | 1446803 | 45540 | 92919 | 4517 |\n",
    "| Exgram | 387 | 10526 | 294303 | 94752 | 6471 | 6482 | 247992 | 1400848 | 44698 | 89909 | 4411 |\n",
    "| Halmak | 334 | 10130 | 276352 | 93504 | 6409 | 5780 | 232454 | 1339767 | 42207 | 88533 | 4288 |\n",
    "| Hieamtsrn | 354 | 10249 | 289816 | 94756 | 6491 | 6045 | 235033 | 1345849 | 42209 | 83748 | 4123 |\n",
    "| Colemak Mod-DH | 352 | 9652 | 277910 | 92954 | 6226 | 6047 | 232765 | 1324663 | 42247 | 84616 | 4122 |\n",
    "| Norman | 335 | 9886 | 277031 | 92311 | 6386 | 5844 | 234322 | 1354524 | 42694 | 86844 | 4139 |\n",
    "| Workman | 336 | 9670 | 276958 | 92393 | 6368 | 5851 | 235125 | 1359975 | 42833 | 87018 | 4240 |\n",
    "| MTGap 2.0 | 343 | 9517 | 270990 | 90102 | 6069 | 5907 | 224465 | 1275631 | 40695 | 83454 | 4014 |\n",
    "| QGMLWB | 349 | 10422 | 292502 | 94899 | 6684 | 6054 | 248758 | 1435245 | 45096 | 89509 | 4300 |\n",
    "| Colemak | 350 | 9638 | 279364 | 92810 | 6268 | 6016 | 232360 | 1321219 | 42072 | 84815 | 4094 |\n",
    "| Asset | 351 | 9976 | 282385 | 93278 | 6314 | 6086 | 234823 | 1334773 | 42404 | 84398 | 4039 |\n",
    "| Capewell-Dvorak | 333 | 9944 | 275841 | 91100 | 6246 | 5712 | 230413 | 1328042 | 41928 | 87307 | 4193 |\n",
    "| Klausler | 344 | 9948 | 278427 | 92104 | 6341 | 5794 | 232489 | 1336667 | 42176 | 88519 | 4277 |\n",
    "| Dvorak | 363 | 10332 | 297153 | 95786 | 6714 | 5978 | 251920 | 1444416 | 45939 | 90828 | 4435 |\n",
    "\n",
    "Same finger different key taps\n",
    "\n",
    "| Layout | Alice | Memento | Tweets_100K | Tweets_20K | Tweets_MASC | Spoken_MASC | COCA_blogs | iweb | Monkey | Coder | Rosetta |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| Engram v3 | 272 | 11878 | 331356 | 117336 | 8786 | 3344 | 139794 | 1050952 | 35944 | 122144 | 5284 |\n",
    "| Engram v2 | 216 | 11476 | 320406 | 120286 | 7728 | 3514 | 137290 | 1064640 | 37534 | 125798 | 5822 |\n",
    "| Exgram | 216 | 11358 | 322336 | 113270 | 7856 | 3196 | 132534 | 993030 | 34044 | 122278 | 5314 |\n",
    "| Halmak | 498 | 13640 | 484702 | 170064 | 11456 | 5742 | 268246 | 2029634 | 68858 | 144790 | 5392 |\n",
    "| Hieamtsrn | 244 | 12096 | 311000 | 119490 | 8316 | 3192 | 155674 | 1100116 | 40882 | 158698 | 7324 |\n",
    "| Colemak Mod-DH | 362 | 10960 | 352578 | 151736 | 9298 | 4644 | 153984 | 1233770 | 47438 | 117842 | 5328 |\n",
    "| Norman | 938 | 20012 | 721602 | 213890 | 16014 | 9022 | 595168 | 3885282 | 135844 | 179752 | 7402 |\n",
    "| Workman | 550 | 13086 | 451280 | 136692 | 10698 | 6156 | 287622 | 1975564 | 71150 | 132526 | 5550 |\n",
    "| MTGap 2.0 | 226 | 14550 | 397690 | 139130 | 10386 | 6252 | 176724 | 1532844 | 58144 | 138484 | 7272 |\n",
    "| QGMLWB | 812 | 17820 | 637788 | 189700 | 14364 | 7838 | 456442 | 3027530 | 100750 | 149366 | 8062 |\n",
    "| Colemak | 362 | 10960 | 352578 | 151736 | 9298 | 4644 | 153984 | 1233770 | 47438 | 117842 | 5328 |\n",
    "| Asset | 520 | 12519 | 519018 | 155246 | 11802 | 5664 | 332860 | 2269342 | 77406 | 140886 | 6020 |\n",
    "| Capewell-Dvorak | 556 | 14226 | 501178 | 163878 | 12214 | 6816 | 335056 | 2391416 | 78152 | 151194 | 9008 |\n",
    "| Klausler | 408 | 14734 | 455658 | 174998 | 11410 | 5212 | 257878 | 1794604 | 59566 | 135782 | 7444 |\n",
    "| Dvorak | 516 | 13970 | 492604 | 171488 | 12208 | 5912 | 263018 | 1993346 | 64994 | 142084 | 6484 |\n",
    "\n",
    "Hand balances\n",
    "\n",
    "| Layout | Alice | Memento | Tweets_100K | Tweets_20K | Tweets_MASC | Spoken_MASC | COCA_blogs | iweb | Monkey | Coder | Rosetta |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| Engram v3 | 3.70 | -0.21 | 4.27 | 5.62 | 4.41 | 6.46 | 1.67 | 1.35 | 3.89 | 4.94 | 2.29 |\n",
    "| Engram v2 | 3.48 | 0.09 | 4.43 | 7.12 | 5.64 | 6.39 | 2.44 | 2.64 | 4.86 | 6.36 | 4.00 |\n",
    "| Exgram | 3.70 | -0.21 | 4.27 | 5.62 | 4.41 | 6.46 | 1.67 | 1.35 | 3.89 | 4.94 | 2.29 |\n",
    "| Halmak | -0.67 | 1.66 | 5.31 | 0.55 | 2.95 | 7.68 | 0.46 | 1.07 | 0.83 | 6.93 | 4.35 |\n",
    "| Hieamtsrn | 0.10 | -2.87 | 1.70 | 2.38 | 3.61 | 0.92 | 1.18 | 3.11 | 3.67 | 10.70 | 10.05 |\n",
    "| Colemak Mod-DH | 10.18 | 7.45 | 10.97 | 6.79 | 9.19 | 18.50 | 7.14 | 6.35 | 7.74 | 12.02 | 14.79 |\n",
    "| Norman | -2.42 | -1.04 | 2.21 | -0.36 | 3.86 | 6.17 | -2.26 | -2.08 | -0.90 | 10.39 | 12.52 |\n",
    "| Workman | 1.38 | 1.46 | 3.34 | 1.50 | 4.96 | 8.25 | 1.02 | 1.54 | 1.80 | 12.56 | 14.27 |\n",
    "| MTGap 2.0 | -4.33 | -3.31 | 1.05 | 0.53 | 3.56 | 4.33 | 0.17 | 1.73 | 2.12 | 10.82 | 5.52 |\n",
    "| QGMLWB | 7.26 | 3.85 | 7.27 | 5.95 | 6.14 | 15.33 | 5.15 | 4.51 | 5.57 | 8.29 | 12.35 |\n",
    "| Colemak | 10.18 | 7.45 | 10.97 | 6.79 | 9.19 | 18.50 | 7.14 | 6.35 | 7.74 | 12.02 | 14.79 |\n",
    "| Asset | -0.53 | 0.71 | 4.36 | 1.08 | 5.60 | 7.77 | -1.00 | -0.81 | 0.07 | 10.81 | 13.88 |\n",
    "| Capewell-Dvorak | 8.25 | -0.04 | 4.32 | 5.24 | 5.14 | 9.45 | 2.77 | 2.65 | 5.01 | 8.94 | 4.93 |\n",
    "| Klausler | 3.01 | -3.93 | 1.37 | 4.41 | 4.46 | 7.06 | 2.24 | 2.53 | 4.39 | 8.27 | 4.86 |\n",
    "| Dvorak | 10.70 | 2.03 | 6.95 | 9.21 | 8.85 | 12.17 | 8.14 | 8.59 | 10.85 | 10.63 | 7.98 |\n",
    "    \n",
    "---\n",
    "\n",
    "| Layout | Year | Website |\n",
    "| --- | --- | --- |\n",
    "| Engram | 2021 | https://engram.dev |\n",
    "| [Halmak 2.2](https://keyboard-design.com/letterlayout.html?layout=halmak-2-2.en.ansi) | 2016 | https://github.com/MadRabbit/halmak |\n",
    "| [Hieamtsrn](https://www.keyboard-design.com/letterlayout.html?layout=hieamtsrn.en.ansi) | 2014 | https://mathematicalmulticore.wordpress.com/the-keyboard-layout-project/#comment-4976 |\n",
    "| [Colemak Mod-DH](https://keyboard-design.com/letterlayout.html?layout=colemak-mod-DH-full.en.ansi) | 2014 | https://colemakmods.github.io/mod-dh/ | \n",
    "| [Norman](https://keyboard-design.com/letterlayout.html?layout=norman.en.ansi) | 2013 | https://normanlayout.info/ |\n",
    "| [Workman](https://keyboard-design.com/letterlayout.html?layout=workman.en.ansi) | 2010 | https://workmanlayout.org/ | \n",
    "| [MTGAP 2.0](https://www.keyboard-design.com/letterlayout.html?layout=mtgap-2-0.en.ansi) | 2010 | https://mathematicalmulticore.wordpress.com/2010/06/21/mtgaps-keyboard-layout-2-0/ |\n",
    "| [QGMLWB](https://keyboard-design.com/letterlayout.html?layout=qgmlwb.en.ansi) | 2009 | http://mkweb.bcgsc.ca/carpalx/?full_optimization | \n",
    "| [Colemak](https://keyboard-design.com/letterlayout.html?layout=colemak.en.ansi) | 2006 | https://colemak.com/ | \n",
    "| [Asset](https://keyboard-design.com/letterlayout.html?layout=asset.en.ansi) | 2006 | http://millikeys.sourceforge.net/asset/ | \n",
    "| Capewell-Dvorak | 2004 | http://michaelcapewell.com/projects/keyboard/layout_capewell-dvorak.htm |\n",
    "| [Klausler](https://www.keyboard-design.com/letterlayout.html?layout=klausler.en.ansi) | 2002 | https://web.archive.org/web/20031001163722/http://klausler.com/evolved.html |\n",
    "| [Dvorak](https://keyboard-design.com/letterlayout.html?layout=dvorak.en.ansi) | 1936 | https://en.wikipedia.org/wiki/Dvorak_keyboard_layout | \n",
    "| [QWERTY](https://keyboard-design.com/letterlayout.html?layout=qwerty.en.ansi) | 1873 | https://en.wikipedia.org/wiki/QWERTY |\n",
    "\n",
    "---\n",
    "\n",
    "| Text source | Information |\n",
    "| --- | --- |\n",
    "| \"Alice in Wonderland\" | Alice in Wonderland (Ch.1) |\n",
    "| \"Memento screenplay\" | [Memento screenplay](https://www.dailyscript.com/scripts/memento.html) |\n",
    "| \"100K tweets\" | 100,000 tweets from: [Sentiment140 dataset](https://data.world/data-society/twitter-user-data) training data |\n",
    "| \"20K tweets\" | 20,000 tweets from [Gender Classifier Data](https://www.kaggle.com/crowdflower/twitter-user-gender-classification) |\n",
    "| \"MASC tweets\" | [MASC](http://www.anc.org/data/masc/corpus/) tweets (cleaned of html markup) |\n",
    "| \"MASC spoken\" | [MASC](http://www.anc.org/data/masc/corpus/) spoken transcripts (phone and face-to-face: 25,783 words) |\n",
    "| \"COCA blogs\" | [Corpus of Contemporary American English](https://www.english-corpora.org/coca/) [blog samples](https://www.corpusdata.org/) |\n",
    "| \"Rosetta\" | \"Tower of Hanoi\" (programming languages A-Z from [Rosetta Code](https://rosettacode.org/wiki/Towers_of_Hanoi)) |\n",
    "| \"Monkey text\" | Ian Douglas's English-generated [monkey0-7.txt corpus](https://zenodo.org/record/4642460) |\n",
    "| \"Coder text\" | Ian Douglas's software-generated [coder0-7.txt corpus](https://zenodo.org/record/4642460) |\n",
    "| \"iweb cleaned corpus\" | First 150,000 lines of Shai Coleman's [iweb-corpus-samples-cleaned.txt](https://colemak.com/pub/corpus/iweb-corpus-samples-cleaned.txt.xz) |\n",
    "\n",
    "Reference for Monkey and Coder texts:\n",
    "Douglas, Ian. (2021, March 28). Keyboard Layout Analysis: Creating the Corpus, Bigram Chains, and Shakespeare's Monkeys (Version 1.0.0). Zenodo. http://doi.org/10.5281/zenodo.4642460"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wm3T-hmja8Ps"
   },
   "source": [
    "## Guiding criteria   <a name=\"criteria\">\n",
    "\n",
    "    1.  Assign letters to keys that don't require lateral finger movements.\n",
    "    2.  Promote alternating between hands over uncomfortable same-hand transitions.\n",
    "    3.  Assign the most common letters to the most comfortable keys.\n",
    "    4.  Arrange letters so that more frequent bigrams are easier to type.\n",
    "    5.  Promote little-to-index-finger roll-ins over index-to-little-finger roll-outs.\n",
    "    6.  Balance finger loads according to their relative strength.\n",
    "    7.  Avoid stretching shorter fingers up and longer fingers down.\n",
    "    8.  Avoid using the same finger.\n",
    "    9.  Avoid skipping over the home row.\n",
    "    10. Assign the most common punctuation to keys in the middle of the keyboard.\n",
    "    11. Assign easy-to-remember symbols to the Shift-number keys.\n",
    "    \n",
    "### Factors used to compute the Engram layout <a name=\"factors\">\n",
    "  - **N-gram letter frequencies** <br>\n",
    "    \n",
    "    [Peter Norvig's analysis](http://www.norvig.com/mayzner.html) of data from Google's book scanning project\n",
    "  - **Flow factors** (transitions between ordered key pairs) <br>\n",
    "    These factors are influenced by Dvorak's 11 criteria (1936)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2eTQ4jxPa8Pv"
   },
   "source": [
    "### Import dependencies and functions  <a name=\"import\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load code/engram_variables.py\n",
    "# Print .png figures and .txt text files\n",
    "print_output = False # True\n",
    "\n",
    "# Apply strength data\n",
    "apply_strength = True\n",
    "min_strength_factor = 0.9\n",
    "\n",
    "letters24 = ['E','T','A','O','I','N','S','R','H','L','D','C','U','M','F','P','G','W','Y','B','V','K','X','J']\n",
    "keys24 = [1,2,3,4, 5,6,7,8, 9,10,11,12, 13,14,15,16, 17,18,19,20, 21,22,23,24]\n",
    "instances24 = [4.45155E+11,3.30535E+11,2.86527E+11,2.72277E+11,2.69732E+11,2.57771E+11,\n",
    "               2.32083E+11,2.23768E+11,1.80075E+11,1.44999E+11,1.36018E+11,1.19156E+11,\n",
    "               97273082907,89506734085,85635440629,76112599849,66615316232,59712390260,\n",
    "               59331661972,52905544693,37532682260,19261229433,8369138754,5657910830]                        \n",
    "\n",
    "\n",
    "# Establish which layouts are within a small difference of the top-scoring layout \n",
    "# (the smallest difference between two penalties, 0.9^8 - 0.9^9, in one of 24^2 key pairs):\n",
    "#delta = 0.9**8 - 0.9**9 #delta = 0.03874204889999999\n",
    "#factor = ((24**2 - 1) + (1-delta)) / (24**2)\n",
    "factor = 0.9999327394984375\n",
    "\n",
    "# Establish which layouts are within a small difference of each other when using the speed matrix. \n",
    "# We define an epsilon of 24.3 ms for a single bigram (of the 24^2 possible bigrams), \n",
    "# one tenth of the range of times recorded in the study above, which is less than a quarter \n",
    "# of the fastest measured digraph tapping speed (30,000/228 = 131.58 ms) recorded in that study:\n",
    "# \"Estimation of digraph costs for keyboard layout optimization\", \n",
    "# A Iseri, Ma Eksioglu, International Journal of Industrial Ergonomics, 48, 127-138, 2015.\n",
    "#data_matrix_speed = Speed32x32\n",
    "#time_range = 243  # milliseconds\n",
    "#norm_range = np.max(data_matrix_speed) - np.min(data_matrix_speed)  #norm_range = 0.6535662299854439\n",
    "#ms_norm = norm_range / time_range  #ms_norm = 0.0026895729629030614\n",
    "#epsilon = time_range/10 * ms_norm / (24**2)\n",
    "epsilon    = 0.0001134663593724729\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "q1wNgX_FDzRH",
    "outputId": "7c14cebc-a4b7-4a77-d14f-26cbc7690c28"
   },
   "outputs": [],
   "source": [
    "# %load code/engram_functions.py\n",
    "# Import dependencies\n",
    "import xlrd\n",
    "import numpy as np\n",
    "from sympy.utilities.iterables import multiset_permutations\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt    \n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def permute_optimize_keys(fixed_letters, fixed_letter_indices, open_letter_indices, \n",
    "                          all_letters, keys, data_matrix, bigrams, bigram_frequencies, \n",
    "                          verbose=False, ntop=0):\n",
    "    \"\"\"\n",
    "    Find all permutations of letters, optimize layout, and generate output.\n",
    "    \"\"\"\n",
    "    matrix_selected = select_keys(data_matrix, keys, verbose=False) \n",
    "    \n",
    "    unassigned_letters = []\n",
    "    for all_letter in all_letters:\n",
    "        if all_letter not in fixed_letters:\n",
    "            unassigned_letters.append(all_letter)\n",
    "            if len(unassigned_letters) == len(open_letter_indices):\n",
    "                break\n",
    "\n",
    "    letter_permutations = permute_letters(unassigned_letters, verbose)\n",
    "    top_permutation, scores = optimize_layout(matrix_selected, bigrams, bigram_frequencies, letter_permutations, open_letter_indices, fixed_letters, fixed_letter_indices, verbose)\n",
    "\n",
    "    if ntop > 0:\n",
    "        print_top_scores(letter_permutations, scores, ntop)\n",
    "    \n",
    "    return top_permutation, letter_permutations, scores\n",
    "\n",
    "\n",
    "def permute_optimize(letters, all_letters, all_keys, data_matrix, bigrams, bigram_frequencies, verbose=False, ntop=0):\n",
    "    \"\"\"\n",
    "    Find all permutations of letters, optimize layout, and generate output.\n",
    "    \"\"\"\n",
    "    matrix_selected = select_keys(data_matrix, all_keys, verbose=False)\n",
    "    open_positions = []\n",
    "    fixed_positions = [] \n",
    "    open_letters = []\n",
    "    fixed_letters = []\n",
    "    assigned_letters = []\n",
    "    for iletter, letter in enumerate(letters):\n",
    "        if letter.strip() == \"\":\n",
    "            open_positions.append(iletter)\n",
    "            for all_letter in all_letters:\n",
    "                if all_letter not in letters and all_letter not in assigned_letters:\n",
    "                    open_letters.append(all_letter)\n",
    "                    assigned_letters.append(all_letter)\n",
    "                    break\n",
    "        else:\n",
    "            fixed_positions.append(iletter)\n",
    "            fixed_letters.append(letter)\n",
    "    #print(open_positions, fixed_positions, open_letters, fixed_letters)\n",
    "    letter_permutations = permute_letters(open_letters, verbose)\n",
    "    top_permutation, scores = optimize_layout(matrix_selected, bigrams, bigram_frequencies, letter_permutations, open_positions, fixed_letters, fixed_positions, verbose)\n",
    "    if ntop > 0:\n",
    "        print_top_scores(letter_permutations, scores, ntop)\n",
    "    \n",
    "    return top_permutation, letter_permutations, scores\n",
    "\n",
    "\n",
    "def select_keys(data_matrix, keys, verbose=False):\n",
    "    \"\"\"\n",
    "    Select keys to quantify pairwise relationships.\n",
    "    \"\"\"\n",
    "    # Extract pairwise entries for the keys:\n",
    "    nkeys = len(keys)\n",
    "    Select = np.zeros((nkeys, nkeys))\n",
    "    u = 0\n",
    "    for i in keys:\n",
    "        u += 1\n",
    "        v = 0\n",
    "        for j in keys:\n",
    "            v += 1\n",
    "            Select[u-1,v-1] = data_matrix[i-1,j-1]\n",
    "\n",
    "    # Normalize matrix with min-max scaling to a range with max 1:\n",
    "    newMin = np.min(Select) / np.max(Select)\n",
    "    newMax = 1.0\n",
    "    Select = newMin + (Select - np.min(Select)) * (newMax - newMin) / (np.max(Select) - np.min(Select))\n",
    "    \n",
    "    if verbose:\n",
    "        #print(\"Matrix:\")\n",
    "        #np.set_printoptions(precision=2); print(Select)\n",
    "\n",
    "        # Heatmap of array\n",
    "        heatmap(data=Select, title=\"Matrix heatmap\", xlabel=\"Key 1\", ylabel=\"Key 2\", print_output=False); plt.show()\n",
    "    \n",
    "    return Select\n",
    "\n",
    "\n",
    "def permute_letters(letters, verbose=False):\n",
    "    \"\"\"\n",
    "    Find all permutations of a given set of letters (max: 8-10 letters).\n",
    "    \"\"\"\n",
    "    letter_permutations = []\n",
    "    for p in multiset_permutations(letters):\n",
    "        letter_permutations.append(p)\n",
    "    letter_permutations = np.array(letter_permutations)\n",
    "    #if verbose:\n",
    "    #    print(\"First permutation: {0}\".format(letter_permutations[0])) \n",
    "    \n",
    "    return letter_permutations\n",
    "\n",
    "\n",
    "def score_layout(data_matrix, letters, bigrams, bigram_frequencies, verbose=False):\n",
    "    \"\"\"\n",
    "    Compute the score for a given letter-key layout (NOTE normalization step).\n",
    "    \"\"\"\n",
    "    # Create a matrix of bigram frequencies:\n",
    "    nletters = len(letters)\n",
    "    F2 = np.zeros((nletters, nletters))\n",
    "\n",
    "    # Find the bigram frequency for each ordered pair of letters in the permutation:\n",
    "    for i1 in range(nletters):\n",
    "        for i2 in range(nletters):\n",
    "            bigram = letters[i1] + letters[i2]\n",
    "            i2gram = np.where(bigrams == bigram)\n",
    "            if np.size(i2gram) > 0:\n",
    "                F2[i1, i2] = bigram_frequencies[i2gram][0]\n",
    "\n",
    "    # Normalize matrices with min-max scaling to a range with max 1:\n",
    "    newMax = 1\n",
    "    minF2 = np.min(F2)\n",
    "    maxF2 = np.max(F2)\n",
    "    newMin2 = minF2 / maxF2\n",
    "    F2 = newMin + (F2 - minF2) * (newMax - newMin2) / (maxF2 - minF2)\n",
    "\n",
    "    # Compute the score for this permutation:\n",
    "    score  = np.average(data_matrix * F2) \n",
    "    if verbose:\n",
    "        print(\"Score for letter permutation {0}: {1}\".format(letters, score))\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def tally_bigrams(input_text, bigrams, normalize=True, verbose=False):\n",
    "    \"\"\"\n",
    "    Compute the score for a given letter-key layout (NOTE normalization step).\n",
    "    \"\"\"   \n",
    "    # Find the bigram frequency for each ordered pair of letters in the input text\n",
    "    #input_text = [str.upper(str(x)) for x in input_text]\n",
    "    input_text = [str.upper(x) for x in input_text]\n",
    "    nchars = len(input_text)\n",
    "    F = np.zeros(len(bigrams))\n",
    "\n",
    "    for ichar in range(0, nchars-1):\n",
    "        bigram = input_text[ichar] + input_text[ichar + 1]\n",
    "        i2gram = np.where(bigrams == bigram)\n",
    "        if np.size(i2gram) > 0:\n",
    "            F[i2gram] += 1\n",
    "\n",
    "    # Normalize matrix with min-max scaling to a range with max 1:\n",
    "    if normalize:\n",
    "        newMax = 1\n",
    "        newMin = np.min(F) / np.max(F)\n",
    "        F = newMin + (F - np.min(F)) * (newMax - newMin) / (np.max(F) - np.min(F))\n",
    "\n",
    "    bigram_frequencies_for_input = F\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Bigram frequencies for input: {0}\".format(bigram_frequencies_for_input))\n",
    "\n",
    "    return bigram_frequencies_for_input\n",
    "\n",
    "\n",
    "def tally_layout_samefinger_bigrams(layout, bigrams, bigram_frequencies, nkeys=32, verbose=False):\n",
    "    \"\"\"\n",
    "    Tally the number of same-finger bigrams within (a list of 24 letters representing) a layout:\n",
    "    ['P','Y','O','U','C','I','E','A','G','K','J','X','M','D','L','B','R','T','N','S','H','V','W','F']\n",
    "    \"\"\"  \n",
    "    if nkeys == 32:\n",
    "        #        Left:            Right:\n",
    "        #    1  2  3  4 25   28 13 14 15 16 31 \n",
    "        #    5  6  7  8 26   29 17 18 19 20 32\n",
    "        #    9 10 11 12 27   30 21 22 23 24\n",
    "        same_finger_keys = [[1,5],[5,9],[1,9], [2,6],[6,10],[2,10], \n",
    "                            [3,7],[7,11],[3,11], [4,8],[8,12],[4,12],\n",
    "                            [25,26],[26,27],[25,27], [28,29],[29,30],[28,30], [31,32],\n",
    "                            [4,25],[4,26],[4,27], [8,25],[8,26],[8,27], [12,25],[12,26],[12,27],\n",
    "                            [13,28],[13,29],[13,30], [17,28],[17,29],[17,30], [21,28],[21,29],[21,30],\n",
    "                            [31,16],[31,20],[31,24], [32,16],[32,20],[32,24],\n",
    "                            [13,17],[17,21],[13,21], [14,18],[18,22],[14,22], \n",
    "                            [15,19],[19,23],[15,23], [16,20],[20,24],[16,24]] \n",
    "    elif nkeys == 24:\n",
    "        #    1  2  3  4         13 14 15 16  \n",
    "        #    5  6  7  8         17 18 19 20 \n",
    "        #    9 10 11 12         21 22 23 24\n",
    "        same_finger_keys = [[1,5],[5,9],[1,9], [2,6],[6,10],[2,10], \n",
    "                            [3,7],[7,11],[3,11], [4,8],[8,12],[4,12],\n",
    "                            [13,17],[17,21],[13,21], [14,18],[18,22],[14,22], \n",
    "                            [15,19],[19,23],[15,23], [16,20],[20,24],[16,24]] \n",
    "\n",
    "    layout = [str.upper(x) for x in layout]\n",
    "    max_frequency = 1.00273E+11\n",
    "\n",
    "    samefinger_bigrams = []\n",
    "    samefinger_bigram_counts = []\n",
    "    for bigram_keys in same_finger_keys:\n",
    "        bigram1 = layout[bigram_keys[0]-1] + layout[bigram_keys[1]-1]\n",
    "        bigram2 = layout[bigram_keys[1]-1] + layout[bigram_keys[0]-1]\n",
    "        i2gram1 = np.where(bigrams == bigram1)\n",
    "        i2gram2 = np.where(bigrams == bigram2)\n",
    "        if np.size(i2gram1) > 0:\n",
    "            samefinger_bigrams.append(bigram1)\n",
    "            samefinger_bigram_counts.append(max_frequency * bigram_frequencies[i2gram1] / np.max(bigram_frequencies))\n",
    "        if np.size(i2gram2) > 0:\n",
    "            samefinger_bigrams.append(bigram2)\n",
    "            samefinger_bigram_counts.append(max_frequency * bigram_frequencies[i2gram2] / np.max(bigram_frequencies))\n",
    "\n",
    "    samefinger_bigrams_total = np.sum(samefinger_bigram_counts)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"    Total same-finger bigram frequencies: {0:15.0f}\".format(samefinger_bigrams_total))\n",
    "\n",
    "    return samefinger_bigrams, samefinger_bigram_counts, samefinger_bigrams_total \n",
    "\n",
    "\n",
    "def tally_layout_bigram_rolls(layout, bigrams, bigram_frequencies, nkeys=32, verbose=False):\n",
    "    \"\"\"\n",
    "    Tally the number of bigrams that engage little-to-index finger inward rolls\n",
    "    within (a list of 24 letters representing) a layout:\n",
    "    layout = ['P','Y','O','U','C','I','E','A','G','K','J','X','L','D','B','V','N','T','R','S','H','M','W','F']\n",
    "    bigram_rolls, bigram_roll_counts, bigram_rolls_total = tally_layout_bigram_rolls(layout, bigrams, bigram_frequencies, nkeys=24, verbose=True)\n",
    "    \"\"\"   \n",
    "    if nkeys == 32:\n",
    "        #        Left:            Right:\n",
    "        #    1  2  3  4 25   28 13 14 15 16 31 \n",
    "        #    5  6  7  8 26   29 17 18 19 20 32\n",
    "        #    9 10 11 12 27   30 21 22 23 24\n",
    "\n",
    "        roll_keys = [[1,2],[2,3],[3,4], [5,6],[6,7],[7,8], [9,10],[10,11],[11,12],\n",
    "                    [4,25],[8,26],[12,27],\n",
    "                    [16,15],[15,14],[14,13], [20,19],[19,18],[18,17], [24,23],[23,22],[22,21],\n",
    "                    [13,28],[17,29],[21,30], [31,16],[32,20],\n",
    "                    [1,3],[2,4],[1,4], [5,7],[6,8],[5,8], [9,11],[10,12],[9,12],\n",
    "                    [1,25],[2,25],[3,25],\n",
    "                    [5,26],[6,26],[7,26],\n",
    "                    [9,27],[10,27],[11,27],\n",
    "                    [16,14],[15,13],[16,13], [20,18],[19,17],[20,17], [24,22],[23,21],[24,21],\n",
    "                    [16,28],[15,28],[14,28],\n",
    "                    [20,29],[19,29],[18,29],\n",
    "                    [24,30],[23,30],[22,30],\n",
    "                    [31,15],[31,14],[31,13],[31,28],\n",
    "                    [32,19],[32,18],[32,17],[32,29],\n",
    "                    [1,6],[1,7],[1,8],[2,7],[2,8],[3,8], \n",
    "                    [5,2],[5,3],[5,4],[6,3],[6,4],[7,4],\n",
    "                    [5,10],[5,11],[5,12],[6,11],[6,12],[7,12], \n",
    "                    [9,6],[9,7],[9,8],[10,7],[10,8],[11,8],\n",
    "                    [5,25],[6,25],[7,25],[8,25],\n",
    "                    [5,27],[6,27],[7,27],[8,27],\n",
    "                    [1,26],[2,26],[3,26],[4,26],\n",
    "                    [9,26],[10,26],[11,26],[12,26],\n",
    "                    [16,19],[16,18],[16,17],[15,18],[15,17],[14,17], \n",
    "                    [20,15],[20,14],[20,13],[19,14],[19,13],[18,13],\n",
    "                    [20,23],[20,22],[20,21],[19,22],[19,21],[18,21], \n",
    "                    [24,19],[24,18],[24,17],[23,18],[23,17],[22,17],\n",
    "                    [16,29],[15,29],[14,29],[13,29],\n",
    "                    [24,29],[23,29],[22,29],[21,29],\n",
    "                    [20,28],[19,28],[18,28],[17,28],\n",
    "                    [20,30],[19,30],[18,30],[17,30],\n",
    "                    [31,20],[31,19],[31,18],[31,17],[31,29],\n",
    "                    [32,16],[32,15],[32,14],[32,13],[32,28],\n",
    "                    [32,24],[32,23],[32,22],[32,21],[32,30],\n",
    "                    [1,10],[1,11],[1,12],[1,27],[2,11],[2,12],[2,27],[3,12],[3,27],[4,27], \n",
    "                    [9,2],[9,3],[9,4],[9,25],[10,3],[10,4],[10,25],[11,4],[11,25],[12,25],\n",
    "                    [16,23],[16,22],[16,21],[16,30],[15,22],[15,21],[15,30],[14,21],[14,30],[13,30],\n",
    "                    [24,15],[24,14],[24,13],[24,28],[23,14],[23,13],[23,28],[22,13],[22,28],[21,28],\n",
    "                    [31,24],[31,23],[31,22],[31,21],[31,30]]\n",
    "    elif nkeys == 24:\n",
    "        #    1  2  3  4         13 14 15 16  \n",
    "        #    5  6  7  8         17 18 19 20 \n",
    "        #    9 10 11 12         21 22 23 24\n",
    "        roll_keys = [[1,2],[2,3],[3,4], [5,6],[6,7],[7,8], [9,10],[10,11],[11,12],\n",
    "                    [16,15],[15,14],[14,13], [20,19],[19,18],[18,17], [24,23],[23,22],[22,21],\n",
    "                    [1,3],[2,4],[1,4], [5,7],[6,8],[5,8], [9,11],[10,12],[9,12],\n",
    "                    [16,14],[15,13],[16,13], [20,18],[19,17],[20,17], [24,22],[23,21],[24,21],\n",
    "                    [1,6],[1,7],[1,8],[2,7],[2,8],[3,8], [5,2],[5,3],[5,4],[6,3],[6,4],[7,4],\n",
    "                    [5,10],[5,11],[5,12],[6,11],[6,12],[7,12], [9,6],[9,7],[9,8],[10,7],[10,8],[11,8],\n",
    "                    [16,19],[16,18],[16,17],[15,18],[15,17],[14,17], [20,15],[20,14],[20,13],[19,14],[19,13],[18,13],\n",
    "                    [20,23],[20,22],[20,21],[19,22],[19,21],[18,21], [24,19],[24,18],[24,17],[23,18],[23,17],[22,17],\n",
    "                    [1,10],[1,11],[1,12],[2,11],[2,12],[3,12], [9,2],[9,3],[9,4],[10,3],[10,4],[11,4],\n",
    "                    [16,23],[16,22],[16,21],[15,22],[15,21],[14,21], [24,15],[24,14],[24,13],[23,14],[23,13],[22,13]]\n",
    "\n",
    "    layout = [str.upper(x) for x in layout]\n",
    "    max_frequency = 1.00273E+11\n",
    "\n",
    "    bigram_rolls = []\n",
    "    bigram_roll_counts = []\n",
    "    for bigram_keys in roll_keys:\n",
    "        bigram1 = layout[bigram_keys[0]-1] + layout[bigram_keys[1]-1]\n",
    "        bigram2 = layout[bigram_keys[1]-1] + layout[bigram_keys[0]-1]\n",
    "        i2gram1 = np.where(bigrams == bigram1)\n",
    "        i2gram2 = np.where(bigrams == bigram2)\n",
    "        if np.size(i2gram1) > 0:\n",
    "            bigram_rolls.append(bigram1)\n",
    "            bigram_roll_counts.append(max_frequency * bigram_frequencies[i2gram1] / np.max(bigram_frequencies))\n",
    "        if np.size(i2gram2) > 0:\n",
    "            bigram_rolls.append(bigram2)\n",
    "            bigram_roll_counts.append(max_frequency * bigram_frequencies[i2gram2] / np.max(bigram_frequencies))\n",
    "\n",
    "    bigram_rolls_total = np.sum(bigram_roll_counts)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"    Total bigram inward roll frequencies: {0:15.0f}\".format(bigram_rolls_total))\n",
    "\n",
    "    return bigram_rolls, bigram_roll_counts, bigram_rolls_total \n",
    "\n",
    "\n",
    "def optimize_layout(data_matrix, bigrams, bigram_frequencies, letter_permutations, open_positions, fixed_letters, fixed_positions=[], verbose=False):\n",
    "    \"\"\"\n",
    "    Compute scores for all letter-key layouts.\n",
    "    \"\"\"\n",
    "    iter = 0\n",
    "    top_score = 0\n",
    "    scores = []\n",
    "    use_score_function = False\n",
    "\n",
    "    nletters = len(open_positions) + len(fixed_positions)\n",
    "    top_permutation = np.array(['E' for x in range(nletters)])\n",
    "    F2 = np.zeros((nletters, nletters))\n",
    "\n",
    "    # Loop through the permutations of the selected letters:\n",
    "    for p in letter_permutations:\n",
    "        letters = np.array(['E' for x in range(nletters)])  # KEEP to initialize!\n",
    "        for imove, open_position in enumerate(open_positions):\n",
    "            letters[open_position] = p[imove]\n",
    "        for ifixed, fixed_position in enumerate(fixed_positions):\n",
    "            letters[fixed_position] = fixed_letters[ifixed]\n",
    "\n",
    "        # Compute the score for this permutation:\n",
    "        if use_score_function:\n",
    "            score = score_layout(data_matrix, letters, bigrams, bigram_frequencies, verbose=False)\n",
    "        else:\n",
    "            # Find the bigram frequency for each ordered pair of letters in the permutation:\n",
    "            for i1 in range(nletters):\n",
    "                for i2 in range(nletters):\n",
    "                    bigram = letters[i1] + letters[i2]\n",
    "                    i2gram = np.where(bigrams == bigram)\n",
    "                    if np.size(i2gram) > 0:\n",
    "                        F2[i1, i2] = bigram_frequencies[i2gram][0]\n",
    "\n",
    "            # Normalize matrices with min-max scaling to a range with max 1:\n",
    "            newMax = 1\n",
    "            minF2 = np.min(F2)\n",
    "            maxF2 = np.max(F2)\n",
    "            newMin2 = minF2 / maxF2\n",
    "            F = newMin + (F2 - minF2) * (newMax - newMin2) / (maxF2 - minF2)\n",
    "\n",
    "            # Compute the score for this permutation:\n",
    "            score  = np.average(data_matrix * F) \n",
    "\n",
    "        # Store all scores and the top score and permutation:\n",
    "        scores.append(score)\n",
    "        if score > top_score:\n",
    "            top_score = score\n",
    "            top_permutation = letters\n",
    "            \n",
    "    #print(\"Topmost of {0} permutations: {1}\".format(len(letter_permutations), top_score))\n",
    "    if verbose:\n",
    "        print(\"{0:0.8f}\".format(top_score))\n",
    "        print(*top_permutation)\n",
    "        \n",
    "    return top_permutation, scores\n",
    "\n",
    "\n",
    "def exchange_letters(letters, fixed_letter_indices, all_letters, all_keys, data_matrix, \n",
    "                     bigrams, bigram_frequencies, verbose=True, ntop=0):\n",
    "    \"\"\"\n",
    "    Exchange letters, 8 keys at a time (8! = 40,320) selected twice in 32 different ways:\n",
    "\n",
    "    Indices:\n",
    "         0  1  2  3     12 13 14 15\n",
    "         4  5  6  7     16 17 18 19\n",
    "         8  9 10 11     20 21 22 23 \n",
    "\n",
    "    1. Top rows\n",
    "         0  1  2  3     12 13 14 15\n",
    "    2. Bottom rows\n",
    "         8  9 10 11     20 21 22 23 \n",
    "    3. Top and bottom rows on the right side\n",
    "                        12 13 14 15\n",
    "                        20 21 22 23 \n",
    "    4. Top and bottom rows on the left side \n",
    "         0  1  2  3\n",
    "         8  9 10 11 \n",
    "    5. Top right and bottom left rows\n",
    "                        12 13 14 15\n",
    "         8  9 10 11 \n",
    "    6. Top left and bottom right rows \n",
    "         0  1  2  3\n",
    "                        20 21 22 23 \n",
    "    7. Center of the top and bottom rows on both sides\n",
    "            1  2          13 14\n",
    "            9 10          21 22\n",
    "    8. The eight corners\n",
    "         0        3    12       15\n",
    "         8       11    20       23 \n",
    "    9. Left half of the top and bottom rows on both sides \n",
    "         0  1          12 13\n",
    "         8  9          20 21\n",
    "    10. Right half of the top and bottom rows on both sides\n",
    "               2  3          14 15\n",
    "              10 11          22 23 \n",
    "    11. Left half of non-home rows on the left and right half of the same rows on the right \n",
    "         0  1                14 15\n",
    "         8  9                22 23 \n",
    "    12. Right half of non-home rows on the left and left half of the same rows on the right\n",
    "               2  3    12 13\n",
    "              10 11    20 21 \n",
    "    13. Top center and lower sides\n",
    "            1  2           13 14\n",
    "         8       11     20       23 \n",
    "    14. Top sides and lower center\n",
    "         0        3     12       15\n",
    "            9 10           21 22   \n",
    "    15. Repeat 1-14\n",
    "         \n",
    "    \"\"\"\n",
    "    score = score_layout(data_matrix, letters, bigrams, bigram_frequencies, verbose=False)\n",
    "    print('Initial score: {0}'.format(score)) \n",
    "    print(*letters) \n",
    "    top_permutation = letters\n",
    "\n",
    "    lists_of_open_indices = [\n",
    "        [0,1,2,3,12,13,14,15],\n",
    "        [8,9,10,11,20,21,22,23],\n",
    "        [12,13,14,15,20,21,22,23],\n",
    "        [0,1,2,3,8,9,10,11],\n",
    "        [12,13,14,15,8,9,10,11],\n",
    "        [0,1,2,3,20,21,22,23],\n",
    "        [1,2,13,14,9,10,21,22],\n",
    "        [0,3,12,15,8,11,20,23],\n",
    "        [0,1,12,13,8,9,20,21],\n",
    "        [2,3,14,15,10,11,22,23],\n",
    "        [0,1,14,15,8,9,22,23],\n",
    "        [2,3,12,13,10,11,20,21],\n",
    "        [1,2,8,11,13,14,20,23],\n",
    "        [0,3,9,10,12,15,21,22]  \n",
    "    ]\n",
    "    lists_of_print_statements = [\n",
    "        '1. Top rows',\n",
    "        '2. Bottom rows',\n",
    "        '3. Top and bottom rows on the right side',\n",
    "        '4. Top and bottom rows on the left side',\n",
    "        '5. Top right and bottom left rows',\n",
    "        '6. Top left and bottom right rows',\n",
    "        '7. Center of the top and bottom rows on both sides',\n",
    "        '8. The eight corners',\n",
    "        '9. Left half of the top and bottom rows on both sides',\n",
    "        '10. Right half of the top and bottom rows on both sides',\n",
    "        '11. Left half of non-home rows on the left and right half of the same rows on the right',\n",
    "        '12. Right half of non-home rows on the left and left half of the same rows on the right',\n",
    "        '13. Top center and lower sides',\n",
    "        '14. Top sides and lower center'\n",
    "    ]\n",
    "                         \n",
    "    for istep in [1,2]:\n",
    "        if istep == 1:\n",
    "            s = \"First set of 14 letter exchanges: \"\n",
    "        elif istep == 2:\n",
    "            s = \"Second set of 14 letter exchanges: \"\n",
    "\n",
    "        for ilist, open_indices in enumerate(lists_of_open_indices):\n",
    "            print_statement = lists_of_print_statements[ilist]     \n",
    "\n",
    "            if verbose:\n",
    "                print('{0} {1}'.format(s, print_statement))\n",
    "                             \n",
    "            for open_index in open_indices:\n",
    "                if open_index not in fixed_letter_indices:\n",
    "                    top_permutation[open_index] = ''\n",
    "                    \n",
    "            top_permutation, letter_permutations, scores = permute_optimize(top_permutation, letters24, keys24, data_matrix, bigrams, bigram_frequencies, verbose=True, ntop=0)            \n",
    "            top_permutation = top_permutation.tolist()\n",
    "        \n",
    "    if verbose:\n",
    "        print('')\n",
    "        print('    -------- DONE --------') \n",
    "        print('')\n",
    "\n",
    "    return top_permutation\n",
    "                             \n",
    "\n",
    "def rank_within_epsilon(numbers, epsilon, factor=False, verbose=True):\n",
    "    \"\"\"\n",
    "    numbers = np.array([10,9,8,7,6])\n",
    "    epsilon = 1\n",
    "    rank_within_epsilon(numbers, epsilon, factor=False, verbose=True) \n",
    "    >>> array([1., 1., 2., 2., 3.])\n",
    "    numbers = np.array([0.798900824, 0.79899900824, 0.79900824])\n",
    "    epsilon = 0.9**8 - 0.9**9\n",
    "    factor = ((24**2 - 1) + (1-epsilon)) / (24**2) # 0.999925266109375\n",
    "    rank_within_epsilon(numbers, factor, factor=True, verbose=True) \n",
    "    >>> array([2., 1., 1.])\n",
    "    \"\"\"\n",
    "    numbers = np.array(numbers)\n",
    "    Isort = np.argsort(-numbers)\n",
    "    numbers_sorted = numbers[Isort]\n",
    "    count = 1\n",
    "    ranks = np.zeros(np.size(numbers))\n",
    "    for i, num in enumerate(numbers_sorted):\n",
    "        if ranks[i] == 0:\n",
    "            if factor:\n",
    "                lower_bound = num * epsilon\n",
    "            else:\n",
    "                lower_bound = num - epsilon\n",
    "            bounded_nums1 = num >= numbers_sorted\n",
    "            bounded_nums2 = numbers_sorted >= lower_bound\n",
    "            bounded_nums = bounded_nums1 * bounded_nums2\n",
    "            count += 1\n",
    "            for ibounded, bounded_num in enumerate(bounded_nums):\n",
    "                if bounded_num == True:\n",
    "                    ranks[ibounded] = count\n",
    "\n",
    "    uranks = np.unique(ranks)\n",
    "    nranks = np.size(uranks)\n",
    "    new_ranks = ranks.copy()\n",
    "    new_count = 0\n",
    "    for rank in uranks:\n",
    "        new_count += 1\n",
    "        same_ranks = ranks == rank\n",
    "        for isame, same_rank in enumerate(same_ranks):\n",
    "            if same_rank == True:\n",
    "                new_ranks[isame] = new_count\n",
    "\n",
    "    #ranks_sorted = new_ranks[Isort]\n",
    "    ranks_sorted = [np.int(x) for x in new_ranks]\n",
    "    \n",
    "    if verbose:\n",
    "        for i, num in enumerate(numbers_sorted):\n",
    "            print(\"    ({0})    {1}\".format(np.int(ranks_sorted[i]), num))\n",
    "        \n",
    "    return numbers_sorted, ranks_sorted, Isort\n",
    "\n",
    "\n",
    "def print_top_scores(letter_permutations, scores, ntop):\n",
    "    \"\"\"\n",
    "    Print top-scored letter permutations.\n",
    "    \"\"\"\n",
    "    scores_negative = -np.array(scores)\n",
    "    isort = np.argsort(scores_negative)[:ntop]\n",
    "    sorted_scores = [scores[isort[x]] for x in range(len(isort))]\n",
    "    sorted_letter_permutations = [letter_permutations[isort[x]].tolist() for x in range(len(isort))]\n",
    "    for ix, x in enumerate(sorted_letter_permutations):\n",
    "        print(\"{0:0.8f}\".format(sorted_scores[ix]))\n",
    "        print(*x)\n",
    "    \n",
    "def print_matrix_info(matrix_data, matrix_label, nkeys, nlines=10):\n",
    "    \"\"\"\n",
    "    Print matrix output.\n",
    "    \"\"\"\n",
    "    print(\"{0} min = {1}, max = {2}\".format(matrix_label, np.min(matrix_data), np.max(matrix_data)))\n",
    "    matrix_flat = matrix_data.flatten()\n",
    "    argsort = np.argsort(matrix_flat)\n",
    "    print(\"{0} key number pairs with minimum values:\".format(matrix_label))\n",
    "    for x in argsort[0:nlines]:\n",
    "        if x % nkeys == 0:\n",
    "            min_row = np.int(np.ceil(x / nkeys)) + 1\n",
    "            min_col = 1\n",
    "        else:\n",
    "            min_row = np.int(np.ceil(x / nkeys))\n",
    "            min_col = x - nkeys * (min_row-1) + 1                \n",
    "        print(\"        {0} -> {1}        ({2})\".format(min_row, min_col, matrix_flat[x]))\n",
    "    print(\"{0} key number pairs with maximum values:\".format(matrix_label))\n",
    "    max_sort = argsort[-nlines::]\n",
    "    for x in max_sort[::-1]:\n",
    "        if x % nkeys == 0:\n",
    "            max_row = np.int(np.ceil(x / nkeys)) + 1\n",
    "            max_col = 1\n",
    "        else:\n",
    "            max_row = np.int(np.ceil(x / nkeys))\n",
    "            max_col = x - nkeys * (max_row-1) + 1                \n",
    "        print(\"        {0} -> {1}        ({2})\".format(max_row, max_col, matrix_flat[x]))\n",
    "\n",
    "\n",
    "def heatmap(data, title=\"\", xlabel=\"\", ylabel=\"\", x_axis_labels=[], y_axis_labels=[], print_output=True):\n",
    "    \"\"\"\n",
    "    Plot heatmap of matrix.\n",
    "    \"\"\"\n",
    "    # use heatmap function, set the color as viridis and\n",
    "    # make each cell seperate using linewidth parameter\n",
    "    plt.figure()\n",
    "    sns_plot = sns.heatmap(data, xticklabels=x_axis_labels, yticklabels=y_axis_labels, linewidths=1, \n",
    "                           cmap=\"viridis\", square=True, vmin=np.min(data), vmax=np.max(data))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    sns_plot.set_xticklabels(x_axis_labels)  #, rotation=75) \n",
    "    sns_plot.set_yticklabels(y_axis_labels) \n",
    "    if print_output:\n",
    "        sns_plot.figure.savefig(\"{0}_heatmap.png\".format(title))\n",
    "        \n",
    "    \n",
    "def histmap(data, title=\"\", print_output=True):\n",
    "    \"\"\"\n",
    "    Plot histogram.\n",
    "    \"\"\"\n",
    "    sns.distplot(data)\n",
    "    plt.title(title)\n",
    "    if print_output:\n",
    "        sns_plot.figure.savefig(\"{0}_histogram.png\".format(title))\n",
    "        \n",
    "        \n",
    "def print_layout24(layout):\n",
    "    \"\"\"\n",
    "    Print layout.\n",
    "    \"\"\"   \n",
    "    print('    {0}  {1}'.format(' '.join(layout[0:4]),\n",
    "                                ' '.join(layout[12:16])))\n",
    "    print('    {0}  {1}'.format(' '.join(layout[4:8]),\n",
    "                                ' '.join(layout[16:20])))\n",
    "    print('    {0}  {1}'.format(' '.join(layout[8:12]),\n",
    "                                ' '.join(layout[20:24])))\n",
    "\n",
    "\n",
    "def print_layout24_instances(layout, letters24, instances24, bigrams, bigram_frequencies):\n",
    "    \"\"\"\n",
    "    Print billions of instances per letter (not Z or Q) in layout form.\n",
    "    layout = ['P','Y','O','U','C','I','E','A','G','K','J','X','M','D','L','B','R','T','N','S','H','V','W','F']\n",
    "    print_layout24_instances(layout, letters24, instances24, bigrams, bigram_frequencies)\n",
    "    \"\"\"\n",
    "    layout_instances = []\n",
    "    layout_instances_strings = []\n",
    "    for letter in layout:\n",
    "        index = letters24.index(letter)\n",
    "        layout_instances.append(instances24[index])\n",
    "        layout_instances_strings.append('{0:3.0f}'.format(instances24[index]/1000000000))\n",
    " \n",
    "    print('    {0}  {1}'.format(' '.join(layout_instances_strings[0:4]),\n",
    "                                ' '.join(layout_instances_strings[12:16])))\n",
    "    print('    {0}  {1}'.format(' '.join(layout_instances_strings[4:8]),\n",
    "                                ' '.join(layout_instances_strings[16:20])))\n",
    "    print('    {0}  {1}'.format(' '.join(layout_instances_strings[8:12]),\n",
    "                                ' '.join(layout_instances_strings[20:24])))\n",
    "    left_sum = np.sum(layout_instances[0:12])/1000000000000\n",
    "    right_sum = np.sum(layout_instances[12:24])/1000000000000\n",
    "    pL = ''\n",
    "    pR = ''\n",
    "    if left_sum > right_sum:\n",
    "        pL = ' ({0:3.2f}%)'.format(100 * (left_sum - right_sum) / right_sum)\n",
    "    elif right_sum > left_sum:\n",
    "        pR = ' ({0:3.2f}%)'.format(100 * (right_sum - left_sum) / left_sum)\n",
    "    \n",
    "    print('\\n    left: {0:3.3f}T{1}  right: {2:3.3f}T{3}'.format(left_sum, pL, \n",
    "                                                                 right_sum, pR))\n",
    "    \n",
    "    tally_layout_samefinger_bigrams(layout, bigrams, bigram_frequencies, nkeys=24, verbose=True)\n",
    "    tally_layout_bigram_rolls(layout, bigrams, bigram_frequencies, nkeys=24, verbose=True)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rFiySi8rDzRN"
   },
   "source": [
    "### Bigram frequencies <a name=\"ngrams\">\n",
    "\n",
    "[Peter Norvig's ngrams table](http://www.norvig.com/mayzner.html](http://www.norvig.com/mayzner.html)\n",
    "    \n",
    "[NOTE: If you want to compute an optimized layout for another language, or based on another corpus, you can run the tally_bigrams() function above and replace bigram_frequencies below before running the rest of the code.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K68F0fkqDzRO"
   },
   "outputs": [],
   "source": [
    "# %load code/load_bigram_frequencies.py\n",
    "load_original_ngram_files = False\n",
    "if load_original_ngram_files:\n",
    "    ngrams_table = \"data/bigrams-trigrams-frequencies.xlsx\"\n",
    "    wb = xlrd.open_workbook(ngrams_table) \n",
    "    ngrams_sheet = wb.sheet_by_index(0)\n",
    "    # 1-grams and frequencies\n",
    "    onegrams = np.array(())\n",
    "    onegram_frequencies = np.array(())\n",
    "    i = 0\n",
    "    start1 = 0\n",
    "    stop1 = 0\n",
    "    while stop1 == 0:\n",
    "        if ngrams_sheet.cell_value(i, 0) == \"2-gram\":\n",
    "            stop1 = 1\n",
    "        elif ngrams_sheet.cell_value(i, 0) == \"1-gram\":\n",
    "            start1 = 1\n",
    "        elif start1 == 1:\n",
    "            onegrams = np.append(onegrams, ngrams_sheet.cell_value(i, 0))\n",
    "            onegram_frequencies = np.append(onegram_frequencies, ngrams_sheet.cell_value(i, 1))\n",
    "        i += 1\n",
    "    onegram_frequencies = onegram_frequencies / np.sum(onegram_frequencies)\n",
    "\n",
    "    # 2-grams and frequencies\n",
    "    bigrams = np.array(())\n",
    "    bigram_frequencies = np.array(())\n",
    "    i = 0\n",
    "    start1 = 0\n",
    "    stop1 = 0\n",
    "    while stop1 == 0:\n",
    "        if ngrams_sheet.cell_value(i, 0) == \"3-gram\":\n",
    "            stop1 = 1\n",
    "        elif ngrams_sheet.cell_value(i, 0) == \"2-gram\":\n",
    "            start1 = 1\n",
    "        elif start1 == 1:\n",
    "            bigrams = np.append(bigrams, ngrams_sheet.cell_value(i, 0))\n",
    "            bigram_frequencies = np.append(bigram_frequencies, ngrams_sheet.cell_value(i, 1))\n",
    "        i += 1\n",
    "    bigram_frequencies = bigram_frequencies / np.sum(bigram_frequencies)\n",
    "\n",
    "    # Save:\n",
    "    if print_output:\n",
    "        file = open(\"onegrams.txt\", \"w+\")\n",
    "        file.write(str(onegrams))\n",
    "        file.close()\n",
    "        file = open(\"onegram_frequencies.txt\", \"w+\")\n",
    "        file.write(str(onegram_frequencies))\n",
    "        file.close()\n",
    "        file = open(\"bigrams.txt\", \"w+\")\n",
    "        file.write(str(bigrams))\n",
    "        file.close()\n",
    "        file = open(\"bigram_frequencies.txt\", \"w+\")\n",
    "        file.write(str(bigram_frequencies))\n",
    "        file.close()\n",
    "\n",
    "    # Print:\n",
    "    print(repr(onegrams))\n",
    "    print(repr(onegram_frequencies))\n",
    "    print(repr(bigrams))\n",
    "    print(repr(bigram_frequencies))\n",
    "\n",
    "else:\n",
    "    onegrams = np.array(['E', 'T', 'A', 'O', 'I', 'N', 'S', 'R', 'H', 'L', 'D', 'C', 'U',\n",
    "       'M', 'F', 'P', 'G', 'W', 'Y', 'B', 'V', 'K', 'X', 'J', 'Q', 'Z'],\n",
    "      dtype='<U32')\n",
    "    onegram_frequencies = np.array([0.12492063, 0.09275565, 0.08040605, 0.07640693, 0.07569278,\n",
    "       0.07233629, 0.06512767, 0.06279421, 0.05053301, 0.04068986,\n",
    "       0.03816958, 0.03343774, 0.02729702, 0.02511761, 0.02403123,\n",
    "       0.02135891, 0.01869376, 0.01675664, 0.0166498 , 0.01484649,\n",
    "       0.01053252, 0.00540513, 0.00234857, 0.00158774, 0.00120469,\n",
    "       0.00089951])\n",
    "    bigrams = np.array(['TH', 'HE', 'IN', 'ER', 'AN', 'RE', 'ON', 'AT', 'EN', 'ND', 'TI',\n",
    "       'ES', 'OR', 'TE', 'OF', 'ED', 'IS', 'IT', 'AL', 'AR', 'ST', 'TO',\n",
    "       'NT', 'NG', 'SE', 'HA', 'AS', 'OU', 'IO', 'LE', 'VE', 'CO', 'ME',\n",
    "       'DE', 'HI', 'RI', 'RO', 'IC', 'NE', 'EA', 'RA', 'CE', 'LI', 'CH',\n",
    "       'LL', 'BE', 'MA', 'SI', 'OM', 'UR', 'CA', 'EL', 'TA', 'LA', 'NS',\n",
    "       'DI', 'FO', 'HO', 'PE', 'EC', 'PR', 'NO', 'CT', 'US', 'AC', 'OT',\n",
    "       'IL', 'TR', 'LY', 'NC', 'ET', 'UT', 'SS', 'SO', 'RS', 'UN', 'LO',\n",
    "       'WA', 'GE', 'IE', 'WH', 'EE', 'WI', 'EM', 'AD', 'OL', 'RT', 'PO',\n",
    "       'WE', 'NA', 'UL', 'NI', 'TS', 'MO', 'OW', 'PA', 'IM', 'MI', 'AI',\n",
    "       'SH', 'IR', 'SU', 'ID', 'OS', 'IV', 'IA', 'AM', 'FI', 'CI', 'VI',\n",
    "       'PL', 'IG', 'TU', 'EV', 'LD', 'RY', 'MP', 'FE', 'BL', 'AB', 'GH',\n",
    "       'TY', 'OP', 'WO', 'SA', 'AY', 'EX', 'KE', 'FR', 'OO', 'AV', 'AG',\n",
    "       'IF', 'AP', 'GR', 'OD', 'BO', 'SP', 'RD', 'DO', 'UC', 'BU', 'EI',\n",
    "       'OV', 'BY', 'RM', 'EP', 'TT', 'OC', 'FA', 'EF', 'CU', 'RN', 'SC',\n",
    "       'GI', 'DA', 'YO', 'CR', 'CL', 'DU', 'GA', 'QU', 'UE', 'FF', 'BA',\n",
    "       'EY', 'LS', 'VA', 'UM', 'PP', 'UA', 'UP', 'LU', 'GO', 'HT', 'RU',\n",
    "       'UG', 'DS', 'LT', 'PI', 'RC', 'RR', 'EG', 'AU', 'CK', 'EW', 'MU',\n",
    "       'BR', 'BI', 'PT', 'AK', 'PU', 'UI', 'RG', 'IB', 'TL', 'NY', 'KI',\n",
    "       'RK', 'YS', 'OB', 'MM', 'FU', 'PH', 'OG', 'MS', 'YE', 'UD', 'MB',\n",
    "       'IP', 'UB', 'OI', 'RL', 'GU', 'DR', 'HR', 'CC', 'TW', 'FT', 'WN',\n",
    "       'NU', 'AF', 'HU', 'NN', 'EO', 'VO', 'RV', 'NF', 'XP', 'GN', 'SM',\n",
    "       'FL', 'IZ', 'OK', 'NL', 'MY', 'GL', 'AW', 'JU', 'OA', 'EQ', 'SY',\n",
    "       'SL', 'PS', 'JO', 'LF', 'NV', 'JE', 'NK', 'KN', 'GS', 'DY', 'HY',\n",
    "       'ZE', 'KS', 'XT', 'BS', 'IK', 'DD', 'CY', 'RP', 'SK', 'XI', 'OE',\n",
    "       'OY', 'WS', 'LV', 'DL', 'RF', 'EU', 'DG', 'WR', 'XA', 'YI', 'NM',\n",
    "       'EB', 'RB', 'TM', 'XC', 'EH', 'TC', 'GY', 'JA', 'HN', 'YP', 'ZA',\n",
    "       'GG', 'YM', 'SW', 'BJ', 'LM', 'CS', 'II', 'IX', 'XE', 'OH', 'LK',\n",
    "       'DV', 'LP', 'AX', 'OX', 'UF', 'DM', 'IU', 'SF', 'BT', 'KA', 'YT',\n",
    "       'EK', 'PM', 'YA', 'GT', 'WL', 'RH', 'YL', 'HS', 'AH', 'YC', 'YN',\n",
    "       'RW', 'HM', 'LW', 'HL', 'AE', 'ZI', 'AZ', 'LC', 'PY', 'AJ', 'IQ',\n",
    "       'NJ', 'BB', 'NH', 'UO', 'KL', 'LR', 'TN', 'GM', 'SN', 'NR', 'FY',\n",
    "       'MN', 'DW', 'SB', 'YR', 'DN', 'SQ', 'ZO', 'OJ', 'YD', 'LB', 'WT',\n",
    "       'LG', 'KO', 'NP', 'SR', 'NQ', 'KY', 'LN', 'NW', 'TF', 'FS', 'CQ',\n",
    "       'DH', 'SD', 'VY', 'DJ', 'HW', 'XU', 'AO', 'ML', 'UK', 'UY', 'EJ',\n",
    "       'EZ', 'HB', 'NZ', 'NB', 'MC', 'YB', 'TP', 'XH', 'UX', 'TZ', 'BV',\n",
    "       'MF', 'WD', 'OZ', 'YW', 'KH', 'GD', 'BM', 'MR', 'KU', 'UV', 'DT',\n",
    "       'HD', 'AA', 'XX', 'DF', 'DB', 'JI', 'KR', 'XO', 'CM', 'ZZ', 'NX',\n",
    "       'YG', 'XY', 'KG', 'TB', 'DC', 'BD', 'SG', 'WY', 'ZY', 'AQ', 'HF',\n",
    "       'CD', 'VU', 'KW', 'ZU', 'BN', 'IH', 'TG', 'XV', 'UZ', 'BC', 'XF',\n",
    "       'YZ', 'KM', 'DP', 'LH', 'WF', 'KF', 'PF', 'CF', 'MT', 'YU', 'CP',\n",
    "       'PB', 'TD', 'ZL', 'SV', 'HC', 'MG', 'PW', 'GF', 'PD', 'PN', 'PC',\n",
    "       'RX', 'TV', 'IJ', 'WM', 'UH', 'WK', 'WB', 'BH', 'OQ', 'KT', 'RQ',\n",
    "       'KB', 'CG', 'VR', 'CN', 'PK', 'UU', 'YF', 'WP', 'CZ', 'KP', 'DQ',\n",
    "       'WU', 'FM', 'WC', 'MD', 'KD', 'ZH', 'GW', 'RZ', 'CB', 'IW', 'XL',\n",
    "       'HP', 'MW', 'VS', 'FC', 'RJ', 'BP', 'MH', 'HH', 'YH', 'UJ', 'FG',\n",
    "       'FD', 'GB', 'PG', 'TK', 'KK', 'HQ', 'FN', 'LZ', 'VL', 'GP', 'HZ',\n",
    "       'DK', 'YK', 'QI', 'LX', 'VD', 'ZS', 'BW', 'XQ', 'MV', 'UW', 'HG',\n",
    "       'FB', 'SJ', 'WW', 'GK', 'UQ', 'BG', 'SZ', 'JR', 'QL', 'ZT', 'HK',\n",
    "       'VC', 'XM', 'GC', 'FW', 'PZ', 'KC', 'HV', 'XW', 'ZW', 'FP', 'IY',\n",
    "       'PV', 'VT', 'JP', 'CV', 'ZB', 'VP', 'ZR', 'FH', 'YV', 'ZG', 'ZM',\n",
    "       'ZV', 'QS', 'KV', 'VN', 'ZN', 'QA', 'YX', 'JN', 'BF', 'MK', 'CW',\n",
    "       'JM', 'LQ', 'JH', 'KJ', 'JC', 'GZ', 'JS', 'TX', 'FK', 'JL', 'VM',\n",
    "       'LJ', 'TJ', 'JJ', 'CJ', 'VG', 'MJ', 'JT', 'PJ', 'WG', 'VH', 'BK',\n",
    "       'VV', 'JD', 'TQ', 'VB', 'JF', 'DZ', 'XB', 'JB', 'ZC', 'FJ', 'YY',\n",
    "       'QN', 'XS', 'QR', 'JK', 'JV', 'QQ', 'XN', 'VF', 'PX', 'ZD', 'QT',\n",
    "       'ZP', 'QO', 'DX', 'HJ', 'GV', 'JW', 'QC', 'JY', 'GJ', 'QB', 'PQ',\n",
    "       'JG', 'BZ', 'MX', 'QM', 'MZ', 'QF', 'WJ', 'ZQ', 'XR', 'ZK', 'CX',\n",
    "       'FX', 'FV', 'BX', 'VW', 'VJ', 'MQ', 'QV', 'ZF', 'QE', 'YJ', 'GX',\n",
    "       'KX', 'XG', 'QD', 'XJ', 'SX', 'VZ', 'VX', 'WV', 'YQ', 'BQ', 'GQ',\n",
    "       'VK', 'ZJ', 'XK', 'QP', 'HX', 'FZ', 'QH', 'QJ', 'JZ', 'VQ', 'KQ',\n",
    "       'XD', 'QW', 'JX', 'QX', 'KZ', 'WX', 'FQ', 'XZ', 'ZX'], dtype='<U32')\n",
    "    bigram_frequencies = np.array([3.55620339e-02, 3.07474124e-02, 2.43274529e-02, 2.04826481e-02,\n",
    "       1.98515108e-02, 1.85432319e-02, 1.75804642e-02, 1.48673230e-02,\n",
    "       1.45424846e-02, 1.35228145e-02, 1.34257882e-02, 1.33939375e-02,\n",
    "       1.27653906e-02, 1.20486963e-02, 1.17497528e-02, 1.16812337e-02,\n",
    "       1.12842988e-02, 1.12327374e-02, 1.08744953e-02, 1.07489847e-02,\n",
    "       1.05347566e-02, 1.04126653e-02, 1.04125115e-02, 9.53014842e-03,\n",
    "       9.32114579e-03, 9.25763559e-03, 8.71095073e-03, 8.70002319e-03,\n",
    "       8.34931851e-03, 8.29254235e-03, 8.25280566e-03, 7.93859725e-03,\n",
    "       7.93006486e-03, 7.64818391e-03, 7.63241814e-03, 7.27618866e-03,\n",
    "       7.26724441e-03, 6.98707488e-03, 6.91722265e-03, 6.88165290e-03,\n",
    "       6.85633031e-03, 6.51417363e-03, 6.24352184e-03, 5.97765978e-03,\n",
    "       5.76571076e-03, 5.76283716e-03, 5.65269345e-03, 5.50057242e-03,\n",
    "       5.46256885e-03, 5.42747781e-03, 5.38164098e-03, 5.30301559e-03,\n",
    "       5.29886071e-03, 5.27529444e-03, 5.08937452e-03, 4.92966405e-03,\n",
    "       4.87753568e-03, 4.84902069e-03, 4.77989185e-03, 4.77282719e-03,\n",
    "       4.74470916e-03, 4.64574958e-03, 4.60971757e-03, 4.54257059e-03,\n",
    "       4.47772200e-03, 4.42103298e-03, 4.31534618e-03, 4.25820178e-03,\n",
    "       4.25013516e-03, 4.15745843e-03, 4.12608242e-03, 4.05151268e-03,\n",
    "       4.05075209e-03, 3.97732158e-03, 3.96527277e-03, 3.94413046e-03,\n",
    "       3.86884200e-03, 3.85337077e-03, 3.85189513e-03, 3.84646388e-03,\n",
    "       3.78793431e-03, 3.77605408e-03, 3.74420703e-03, 3.73663638e-03,\n",
    "       3.67956418e-03, 3.65492648e-03, 3.61676413e-03, 3.61373182e-03,\n",
    "       3.60899233e-03, 3.47234973e-03, 3.45829494e-03, 3.39212478e-03,\n",
    "       3.37488213e-03, 3.36877623e-03, 3.30478042e-03, 3.23572471e-03,\n",
    "       3.17759946e-03, 3.17691369e-03, 3.16447752e-03, 3.15240004e-03,\n",
    "       3.15172398e-03, 3.11176534e-03, 2.95503911e-03, 2.89966768e-03,\n",
    "       2.87848219e-03, 2.86282435e-03, 2.84865969e-03, 2.84585627e-03,\n",
    "       2.81484803e-03, 2.69544349e-03, 2.62987083e-03, 2.54961380e-03,\n",
    "       2.54906719e-03, 2.54783715e-03, 2.52606379e-03, 2.47740122e-03,\n",
    "       2.39175226e-03, 2.36573195e-03, 2.33400171e-03, 2.29786417e-03,\n",
    "       2.27503360e-03, 2.27277101e-03, 2.23911052e-03, 2.21754315e-03,\n",
    "       2.18017446e-03, 2.17360835e-03, 2.14044590e-03, 2.13767970e-03,\n",
    "       2.13188615e-03, 2.10259217e-03, 2.04932647e-03, 2.04724906e-03,\n",
    "       2.03256516e-03, 2.02845908e-03, 1.96777866e-03, 1.95449429e-03,\n",
    "       1.95410531e-03, 1.91254221e-03, 1.89316385e-03, 1.88234971e-03,\n",
    "       1.87652262e-03, 1.84944194e-03, 1.83351654e-03, 1.78086545e-03,\n",
    "       1.76468430e-03, 1.75132925e-03, 1.71573739e-03, 1.70683303e-03,\n",
    "       1.66405086e-03, 1.63999785e-03, 1.62732115e-03, 1.62613977e-03,\n",
    "       1.60361051e-03, 1.54749379e-03, 1.51636562e-03, 1.51067364e-03,\n",
    "       1.49901610e-03, 1.49455831e-03, 1.49011351e-03, 1.48460771e-03,\n",
    "       1.48077067e-03, 1.47541326e-03, 1.47480347e-03, 1.46316579e-03,\n",
    "       1.46204465e-03, 1.43745726e-03, 1.41513491e-03, 1.39980075e-03,\n",
    "       1.38382616e-03, 1.36545598e-03, 1.36333253e-03, 1.36012483e-03,\n",
    "       1.35189358e-03, 1.32127808e-03, 1.30185876e-03, 1.28328757e-03,\n",
    "       1.27907576e-03, 1.26260675e-03, 1.23637099e-03, 1.23094105e-03,\n",
    "       1.21386641e-03, 1.20743055e-03, 1.19536134e-03, 1.19032774e-03,\n",
    "       1.17626124e-03, 1.16805780e-03, 1.14618533e-03, 1.11559852e-03,\n",
    "       1.06597119e-03, 1.05782134e-03, 1.04699320e-03, 1.04540205e-03,\n",
    "       1.01153313e-03, 9.97734501e-04, 9.86028683e-04, 9.84491816e-04,\n",
    "       9.79174450e-04, 9.78784303e-04, 9.70343472e-04, 9.68322624e-04,\n",
    "       9.66708177e-04, 9.60690121e-04, 9.59749105e-04, 9.43900197e-04,\n",
    "       9.40242103e-04, 9.28331656e-04, 9.26685761e-04, 9.14014864e-04,\n",
    "       9.02555222e-04, 8.92112065e-04, 8.85803335e-04, 8.77507468e-04,\n",
    "       8.62646840e-04, 8.57695087e-04, 8.54499050e-04, 8.43925356e-04,\n",
    "       8.31382851e-04, 8.23722323e-04, 8.16643644e-04, 7.89875969e-04,\n",
    "       7.86444549e-04, 7.42072946e-04, 7.36927617e-04, 7.27646949e-04,\n",
    "       7.25004577e-04, 7.11071849e-04, 6.92833068e-04, 6.71807283e-04,\n",
    "       6.68638321e-04, 6.56391013e-04, 6.51990243e-04, 6.49048818e-04,\n",
    "       6.43397537e-04, 6.43118050e-04, 6.37839069e-04, 6.21864133e-04,\n",
    "       6.06367626e-04, 5.99162639e-04, 5.87024289e-04, 5.74860663e-04,\n",
    "       5.72519573e-04, 5.68447140e-04, 5.58806800e-04, 5.45711864e-04,\n",
    "       5.37896691e-04, 5.34768852e-04, 5.20071483e-04, 5.18874875e-04,\n",
    "       5.16054649e-04, 5.14388309e-04, 5.11931727e-04, 5.04227393e-04,\n",
    "       5.00890900e-04, 4.97325634e-04, 4.75088970e-04, 4.66605249e-04,\n",
    "       4.58324041e-04, 4.29127437e-04, 4.27514542e-04, 4.17186146e-04,\n",
    "       4.16199437e-04, 3.94646924e-04, 3.94183167e-04, 3.86306652e-04,\n",
    "       3.61812839e-04, 3.50841120e-04, 3.49059129e-04, 3.23402665e-04,\n",
    "       3.22604151e-04, 3.11527347e-04, 3.10032877e-04, 3.07611603e-04,\n",
    "       2.96010489e-04, 2.88197255e-04, 2.77494857e-04, 2.70735751e-04,\n",
    "       2.67122244e-04, 2.64790886e-04, 2.64597695e-04, 2.63237166e-04,\n",
    "       2.61362824e-04, 2.59399816e-04, 2.58614910e-04, 2.57579773e-04,\n",
    "       2.49143242e-04, 2.49036616e-04, 2.47547306e-04, 2.36748821e-04,\n",
    "       2.35282013e-04, 2.32245156e-04, 2.30209194e-04, 2.28229670e-04,\n",
    "       2.27822992e-04, 2.20319919e-04, 2.17945603e-04, 2.13543715e-04,\n",
    "       1.97145202e-04, 1.90526970e-04, 1.90304866e-04, 1.88393786e-04,\n",
    "       1.85754127e-04, 1.85322815e-04, 1.81767370e-04, 1.74089940e-04,\n",
    "       1.71644610e-04, 1.71039222e-04, 1.69557657e-04, 1.66839046e-04,\n",
    "       1.64718022e-04, 1.59561636e-04, 1.57658164e-04, 1.54026397e-04,\n",
    "       1.52211752e-04, 1.51115808e-04, 1.47564559e-04, 1.46841709e-04,\n",
    "       1.36432949e-04, 1.35005671e-04, 1.32141796e-04, 1.27573620e-04,\n",
    "       1.27432415e-04, 1.26388914e-04, 1.25919175e-04, 1.23965197e-04,\n",
    "       1.21174483e-04, 1.18691292e-04, 1.18219114e-04, 1.17637524e-04,\n",
    "       1.17526303e-04, 1.13037594e-04, 1.10863960e-04, 1.09331046e-04,\n",
    "       1.08837112e-04, 1.06567401e-04, 1.05698197e-04, 1.00512685e-04,\n",
    "       1.00106518e-04, 9.85814937e-05, 9.17495595e-05, 9.15174736e-05,\n",
    "       9.09807382e-05, 8.79007001e-05, 8.16240791e-05, 7.91627682e-05,\n",
    "       7.79158645e-05, 7.56940333e-05, 7.44394656e-05, 7.18101849e-05,\n",
    "       6.97589276e-05, 6.81802488e-05, 6.69029567e-05, 6.54143249e-05,\n",
    "       6.08786925e-05, 6.07607969e-05, 6.03570614e-05, 5.98994801e-05,\n",
    "       5.95001291e-05, 5.94970869e-05, 5.86983574e-05, 5.79700512e-05,\n",
    "       5.66119466e-05, 5.50952209e-05, 5.47453912e-05, 5.43839597e-05,\n",
    "       5.25861529e-05, 4.89722417e-05, 4.78187439e-05, 4.77415865e-05,\n",
    "       4.77107257e-05, 4.62616737e-05, 4.60653783e-05, 4.60409299e-05,\n",
    "       4.56730211e-05, 4.54645078e-05, 4.52324283e-05, 4.38982745e-05,\n",
    "       4.36906610e-05, 4.33593810e-05, 4.31226640e-05, 4.29912118e-05,\n",
    "       4.29446346e-05, 4.17137339e-05, 3.93478837e-05, 3.84895449e-05,\n",
    "       3.84390172e-05, 3.81834469e-05, 3.53827628e-05, 3.47222349e-05,\n",
    "       3.37168917e-05, 3.18518637e-05, 3.15951703e-05, 3.12905207e-05,\n",
    "       3.10605585e-05, 3.02567524e-05, 2.91709879e-05, 2.89567711e-05,\n",
    "       2.85652293e-05, 2.82994071e-05, 2.80417376e-05, 2.77861205e-05,\n",
    "       2.77303518e-05, 2.76273746e-05, 2.72172235e-05, 2.69880432e-05,\n",
    "       2.66503046e-05, 2.66033916e-05, 2.62086568e-05, 2.59259584e-05,\n",
    "       2.57640153e-05, 2.56299050e-05, 2.54449453e-05, 2.51909823e-05,\n",
    "       2.47409597e-05, 2.46797892e-05, 2.42472084e-05, 2.35748710e-05,\n",
    "       2.24438116e-05, 2.24317329e-05, 2.23097275e-05, 2.21249597e-05,\n",
    "       2.17815183e-05, 2.15248592e-05, 2.09465192e-05, 2.09125513e-05,\n",
    "       1.96913177e-05, 1.95330853e-05, 1.91064697e-05, 1.88952009e-05,\n",
    "       1.85746459e-05, 1.81220081e-05, 1.78919334e-05, 1.73267658e-05,\n",
    "       1.61874055e-05, 1.60765855e-05, 1.58740992e-05, 1.45486411e-05,\n",
    "       1.40812264e-05, 1.36678429e-05, 1.32768479e-05, 1.31460479e-05,\n",
    "       1.30872012e-05, 1.29588223e-05, 1.25748548e-05, 1.24146066e-05,\n",
    "       1.22821602e-05, 1.22486357e-05, 1.20714645e-05, 1.20448925e-05,\n",
    "       1.19866728e-05, 1.18936663e-05, 1.17590888e-05, 1.17001978e-05,\n",
    "       1.16346360e-05, 1.11092945e-05, 1.08992577e-05, 1.06740258e-05,\n",
    "       1.06735218e-05, 1.06144296e-05, 1.05679067e-05, 1.03656570e-05,\n",
    "       1.03317955e-05, 9.98437559e-06, 9.01036943e-06, 8.85768061e-06,\n",
    "       8.76035160e-06, 8.60019167e-06, 8.19227801e-06, 7.80479658e-06,\n",
    "       7.53516931e-06, 7.44150882e-06, 7.30644125e-06, 7.26777599e-06,\n",
    "       7.06747616e-06, 6.95177332e-06, 6.85925126e-06, 6.74132156e-06,\n",
    "       6.71322068e-06, 6.70106994e-06, 6.66133186e-06, 6.47626505e-06,\n",
    "       6.38130476e-06, 6.29576510e-06, 6.24612583e-06, 5.93271496e-06,\n",
    "       5.92132104e-06, 5.83947722e-06, 5.76779879e-06, 5.76465728e-06,\n",
    "       5.53187023e-06, 5.47131015e-06, 5.33180695e-06, 5.22417954e-06,\n",
    "       5.20732008e-06, 5.15949060e-06, 5.11569104e-06, 4.95336950e-06,\n",
    "       4.94557425e-06, 4.73636484e-06, 4.63955858e-06, 4.53340156e-06,\n",
    "       4.22935422e-06, 4.19307790e-06, 4.17347414e-06, 4.12142146e-06,\n",
    "       4.11855764e-06, 3.80541311e-06, 3.36707879e-06, 3.29563656e-06,\n",
    "       3.17577578e-06, 3.05442971e-06, 2.98983688e-06, 2.97762691e-06,\n",
    "       2.95066092e-06, 2.91720550e-06, 2.89840858e-06, 2.77497857e-06,\n",
    "       2.76265227e-06, 2.74176112e-06, 2.70310579e-06, 2.61648976e-06,\n",
    "       2.60275585e-06, 2.56616744e-06, 2.55465117e-06, 2.49712549e-06,\n",
    "       2.42815484e-06, 2.37933375e-06, 2.35040476e-06, 2.33914845e-06,\n",
    "       2.33036549e-06, 2.32978989e-06, 2.28930419e-06, 2.28804340e-06,\n",
    "       2.26346210e-06, 2.24353844e-06, 2.23182640e-06, 2.23165865e-06,\n",
    "       2.22696341e-06, 2.22115030e-06, 2.21572164e-06, 2.20668084e-06,\n",
    "       2.19243658e-06, 2.17382266e-06, 2.08159887e-06, 2.07762818e-06,\n",
    "       1.95415065e-06, 1.88693410e-06, 1.83219245e-06, 1.81431726e-06,\n",
    "       1.67631850e-06, 1.67169206e-06, 1.63803449e-06, 1.57770706e-06,\n",
    "       1.56577585e-06, 1.53130790e-06, 1.52519015e-06, 1.52439998e-06,\n",
    "       1.49350905e-06, 1.47212210e-06, 1.45715861e-06, 1.40331777e-06,\n",
    "       1.38641504e-06, 1.29786439e-06, 1.27069447e-06, 1.25613209e-06,\n",
    "       1.23105569e-06, 1.22268909e-06, 1.21688094e-06, 1.18065108e-06,\n",
    "       1.18060143e-06, 1.16794389e-06, 1.13216621e-06, 1.12716419e-06,\n",
    "       1.12418866e-06, 1.12412659e-06, 1.05684621e-06, 1.05049722e-06,\n",
    "       1.04986594e-06, 1.03676402e-06, 1.03482230e-06, 9.96847192e-07,\n",
    "       9.75926251e-07, 9.54397081e-07, 9.36101632e-07, 9.30100914e-07,\n",
    "       9.27467975e-07, 8.92801774e-07, 8.85217179e-07, 8.58891337e-07,\n",
    "       7.80484800e-07, 7.67724409e-07, 7.54031637e-07, 7.45052550e-07,\n",
    "       7.32511689e-07, 7.06828122e-07, 6.59585949e-07, 6.40055245e-07,\n",
    "       6.18628925e-07, 6.17142222e-07, 6.09904832e-07, 6.07242457e-07,\n",
    "       5.72270900e-07, 5.49823535e-07, 5.22568859e-07, 5.01838721e-07,\n",
    "       4.91372576e-07, 4.82981856e-07, 4.69688423e-07, 4.59727658e-07,\n",
    "       4.54795508e-07, 4.22875379e-07, 4.13494116e-07, 3.99834682e-07,\n",
    "       3.97288987e-07, 3.87644926e-07, 3.84245584e-07, 3.81268632e-07,\n",
    "       3.67029696e-07, 3.57267536e-07, 3.52642869e-07, 3.51058992e-07,\n",
    "       3.44112772e-07, 3.36167495e-07, 3.24215712e-07, 3.23810344e-07,\n",
    "       3.21814716e-07, 3.21505459e-07, 3.10936465e-07, 2.88018831e-07,\n",
    "       2.86309762e-07, 2.76140106e-07, 2.63218703e-07, 2.56899508e-07,\n",
    "       2.51244222e-07, 2.25386521e-07, 2.15766576e-07, 2.03018243e-07,\n",
    "       1.99078411e-07, 1.97551987e-07, 1.96981706e-07, 1.92415912e-07,\n",
    "       1.84391194e-07, 1.81253585e-07, 1.78663913e-07, 1.77747846e-07,\n",
    "       1.59541769e-07, 1.38003378e-07, 1.36499298e-07, 1.22889160e-07,\n",
    "       1.22576357e-07, 1.19711121e-07, 1.09597855e-07, 9.97477409e-08,\n",
    "       9.65292710e-08, 9.36271510e-08, 9.35785637e-08, 9.34540807e-08,\n",
    "       8.40270671e-08, 7.82629028e-08, 7.54898762e-08, 6.64058115e-08,\n",
    "       5.96748649e-08, 5.79118882e-08, 5.73650143e-08, 5.65688198e-08,\n",
    "       5.34673852e-08, 5.34237630e-08, 5.29956976e-08, 4.84174907e-08,\n",
    "       3.83818937e-08])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "46wIL5xzDzRS"
   },
   "source": [
    "## Speed matrix  <a name=\"speed\">\n",
    "### 24x24 relative Speed matrix between key pair (averaged for left/right symmetry)\n",
    "\n",
    "  - does not take into account order of key pairs (see Flow24x24 matrix)\n",
    "  - the original version was constructed with data from right-handed people\n",
    "  - 24 keys that don't require extending index or little fingers (\"home block keys\")\n",
    "\n",
    "### Home block keys\n",
    "\n",
    "        Left:            Right:\n",
    "     1  2  3  4       13 14 15 16 \n",
    "     5  6  7  8       17 18 19 20\n",
    "     9 10 11 12       21 22 23 24\n",
    "\n",
    "Interkey stroke times in milliseconds from Table 3 of <br>\n",
    "\"Estimation of digraph costs for keyboard layout optimization\", <br>\n",
    "A Iseri, Ma Eksioglu, International Journal of Industrial Ergonomics, 48, 127-138, 2015. <br>\n",
    "Key numbering in article and in spreadsheet:\n",
    "\n",
    "         Left:           Right:\n",
    "     1 4 7 10 13   16 19 22 25 28 31\n",
    "     2 5 8 11 14   17 20 23 26 29 32\n",
    "     3 6 9 12 15   18 21 24 27 30\n",
    "     \n",
    "### Load table of interkey speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "095yG4iPDzRT"
   },
   "outputs": [],
   "source": [
    "# %load data/Time24x24.py\n",
    "Time24x24 = np.array([[196,225,204,164,266,258,231,166,357,325,263,186,169,176,178,186,156,156,158,163,171,175,177,185],\n",
    " [225,181,182,147,239,245,196,150,289,296,229,167,162,169,170,178,148,148,150,155,163,167,169,177],\n",
    " [204,182,170,149,196,194,232,155,237,214,263,166,157,164,165,173,143,143,145,150,158,163,164,172],\n",
    " [164,147,149,169,160,161,157,226,165,185,234,257,154,162,163,171,141,141,143,148,156,160,162,170],\n",
    " [266,239,196,160,196,240,208,166,271,267,208,169,143,150,151,160,129,129,132,137,145,149,151,159],\n",
    " [258,245,194,161,240,181,183,149,245,256,184,150,138,145,146,154,124,124,126,131,139,144,145,153],\n",
    " [231,196,232,157,208,183,170,149,201,215,239,151,134,141,142,150,120,120,122,127,135,140,141,149],\n",
    " [166,150,155,226,166,149,149,169,160,147,170,221,133,140,141,150,119,119,122,126,135,139,141,149],\n",
    " [357,289,237,165,271,245,201,160,196,236,194,161,171,178,179,188,157,157,160,164,173,177,179,187],\n",
    " [325,296,214,185,267,256,215,147,236,181,184,157,166,173,174,182,152,152,154,159,167,172,173,181],\n",
    " [263,229,263,234,208,184,239,170,194,184,170,150,159,166,167,176,145,145,148,153,161,165,167,175],\n",
    " [186,167,166,257,169,150,151,221,161,157,150,169,153,160,161,169,139,139,141,146,154,159,160,168],\n",
    " [169,162,157,154,143,138,134,133,171,166,159,153,151,147,141,145,188,151,142,164,213,204,162,145],\n",
    " [176,169,164,162,150,145,141,140,178,173,166,160,147,151,189,209,137,207,191,206,149,227,208,226],\n",
    " [178,170,165,163,151,146,142,141,179,174,167,161,141,189,157,253,136,188,210,231,155,226,239,225],\n",
    " [186,178,173,171,160,154,150,150,188,182,176,169,145,209,253,170,147,206,251,233,164,268,362,236],\n",
    " [156,148,143,141,129,124,120,119,157,152,145,139,188,137,136,147,151,133,138,152,192,149,139,143],\n",
    " [156,148,143,141,129,124,120,119,157,152,145,139,151,207,188,206,133,151,179,183,145,204,183,194],\n",
    " [158,150,145,143,132,126,122,122,160,154,148,141,142,191,210,251,138,179,157,240,145,185,208,235],\n",
    " [163,155,150,148,137,131,127,126,164,159,153,146,164,206,231,233,152,183,240,170,160,220,293,230],\n",
    " [171,163,158,156,145,139,135,135,173,167,161,154,213,149,155,164,192,145,145,160,151,140,142,175],\n",
    " [175,167,163,160,149,144,140,139,177,172,165,159,204,227,226,268,149,204,185,220,140,151,175,265],\n",
    " [177,169,164,162,151,145,141,141,179,173,167,160,162,208,239,362,139,183,208,293,142,175,157,265],\n",
    " [185,177,172,170,159,153,149,149,187,181,175,168,145,226,225,236,143,194,235,230,175,265,265,170]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load code/load_interkey_speeds24x24.py\n",
    "# Left/right symmetric version of the Time24x24 matrix\n",
    "# (The original version was constructed with data from right-handed people.)\n",
    "TimeSymmetric24x24 = np.ones((24,24))\n",
    "\n",
    "#        Left:            Right:\n",
    "#     1  2  3  4       13 14 15 16 \n",
    "#     5  6  7  8       17 18 19 20\n",
    "#     9 10 11 12       21 22 23 24\n",
    "\n",
    "I = [1,2,3,4, 5,6,7,8, 9,10,11,12,  16,15,14,13, 20,19,18,17, 24,23,22,21]\n",
    "J = [16,15,14,13, 20,19,18,17, 24,23,22,21,  1,2,3,4, 5,6,7,8, 9,10,11,12]\n",
    "\n",
    "for i1, I1 in enumerate(I):\n",
    "    for i2, I2 in enumerate(I):\n",
    "        J1 = J[i1] - 1\n",
    "        J2 = J[i2] - 1\n",
    "        #print(i1,i2,I1-1,I2-1,J1,J2)\n",
    "        avgvalue = (Time24x24[I1-1,I2-1] + Time24x24[J1,J2]) / 2 \n",
    "        TimeSymmetric24x24[I1-1,I2-1] = avgvalue\n",
    "        TimeSymmetric24x24[J1,J2] = avgvalue\n",
    "\n",
    "# Normalize matrix with min-max scaling to a range with maximum = 1:\n",
    "newMin = np.min(TimeSymmetric24x24) / np.max(TimeSymmetric24x24)\n",
    "newMax = 1.0\n",
    "TimeSymmetric24x24 = newMin + (TimeSymmetric24x24 - np.min(TimeSymmetric24x24)) * (newMax - newMin) / (np.max(TimeSymmetric24x24) - np.min(TimeSymmetric24x24))\n",
    "\n",
    "# Convert relative interkey stroke times to relative speeds by subtracting from 1:\n",
    "Speed24x24 = 1 - TimeSymmetric24x24 + np.min(TimeSymmetric24x24)\n",
    "\n",
    "# Print:\n",
    "print_matrix_info(matrix_data=Speed24x24, matrix_label=\"Speed24x24\", nkeys=24, nlines=50)\n",
    "heatmap(data=Speed24x24, title=\"Speed24x24\", xlabel=\"Key 1\", ylabel=\"Key 2\", print_output=print_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFfuA8zMDzRg"
   },
   "source": [
    "## Strength matrix  <a name=\"strength\">\n",
    "\n",
    "### 24x24 relative finger position STRENGTH matrix\n",
    "\n",
    "Finger strengths are based on peak keyboard reaction forces (in newtons) from Table 4 of <br>\n",
    "\"Keyboard Reaction Force and Finger Flexor Electromyograms during Computer Keyboard Work\" <br>\n",
    "BJ Martin, TJ Armstrong, JA Foulke, S Natarajan, Human Factors,1996,38(4),654-664:\n",
    "   \n",
    "    middle     2.36\n",
    "    index      2.26\n",
    "    ring       2.02\n",
    "    little     1.84\n",
    "    \n",
    "    index/middle:  0.9576271186440678\n",
    "    ring/middle:   0.8559322033898306\n",
    "    little/middle: 0.7796610169491526\n",
    "\n",
    "For reference, Table 1 of \"Ergonomic keyboard layout designed for the Filipino language\", 2016 (doi: 10.1007/978-3-319-41694-6_41) presents \"average finger strength of Filipinos [n=30, ages 16-36] measured in pounds\":\n",
    "   \n",
    "                L       R\n",
    "    little     3.77   4.27\n",
    "    ring       4.54   5.08\n",
    "    middle     5.65   6.37\n",
    "    index      6.09   6.57\n",
    "    \n",
    "    6.57/4.27 = 1.54\n",
    "    6.09/3.77 = 1.62\n",
    "    6.37/5.08 = 1.25\n",
    "    5.65/4.54 = 1.24\n",
    "    \n",
    "We won't use these results as I don't feel they represent relative strength relevant for typing: \"Respondents were asked to sit in upright position, with their wrists resting on a flat surface. A pinch gauge was placed within each finger's reach. The respondents were asked to exert maximum pressure on the device.\"\n",
    "    \n",
    "The following does not take into account order of key pairs (see Flow matrix).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load code/load_strength_data.py\n",
    "# Normalize by the highest peak force (middle finger):\n",
    "middle_force = 2.36\n",
    "index_force = 2.26\n",
    "ring_force = 2.02\n",
    "little_force = 1.84\n",
    "middle_norm = 1.0\n",
    "index_norm = index_force / middle_force\n",
    "ring_norm = ring_force / middle_force\n",
    "little_norm = little_force / middle_force\n",
    "print('index/middle: {0}'.format(index_norm))\n",
    "print('ring/middle: {0}'.format(ring_norm))\n",
    "print('little/middle: {0}'.format(little_norm))\n",
    "\n",
    "# Relative left/right hand strength (assume equal):\n",
    "lf = 1.0\n",
    "rf = 1.0\n",
    "\n",
    "strengths24 = np.array((\n",
    "                    lf * little_norm, lf * ring_norm, lf * middle_norm, lf * index_norm,\n",
    "                    lf * little_norm, lf * ring_norm, lf * middle_norm, lf * index_norm,\n",
    "                    lf * little_norm, lf * ring_norm, lf * middle_norm, lf * index_norm,\n",
    "                    rf * index_norm, rf * middle_norm, rf * ring_norm, rf * little_norm,\n",
    "                    rf * index_norm, rf * middle_norm, rf * ring_norm, rf * little_norm,\n",
    "                    rf * index_norm, rf * middle_norm, rf * ring_norm, rf * little_norm))\n",
    "\n",
    "# Create a finger-pair position strength matrix by adding pairs of strength values:\n",
    "Strength24x24 = np.zeros((24, 24))\n",
    "for i in range(24):\n",
    "    Strength24x24[i,:] = strengths24\n",
    "Strength24x24 = (Strength24x24 + Strength24x24.transpose())\n",
    "\n",
    "# Normalize matrix with min-max scaling to a range with maximum = 1:\n",
    "#newMin = strength_factor\n",
    "newMin = min_strength_factor  # np.min(Strength24x24) / np.max(Strength24x24)\n",
    "newMax = 1.0\n",
    "Strength24x24 = newMin + (Strength24x24 - np.min(Strength24x24)) * (newMax - newMin) / (np.max(Strength24x24) - np.min(Strength24x24))\n",
    "\n",
    "# Print:\n",
    "print_matrix_info(matrix_data=Strength24x24, matrix_label=\"Strength24x24\", nkeys=24, nlines=10)\n",
    "heatmap(data=Strength24x24, title=\"Strength24x24\", xlabel=\"Key 1\", ylabel=\"Key 2\", print_output=print_output)\n",
    "\n",
    "# Save:\n",
    "if print_output:\n",
    "    file = open(\"Strength24x24.txt\", \"w+\")\n",
    "    file.write(str(Strength24x24))\n",
    "    file.close()\n",
    "\n",
    "\n",
    "penalty = 1.0  # Penalty for lateral (index, little) finger placement (1 = no penalty)\n",
    "\n",
    "strengths32 = np.array((lf * little_norm, lf * ring_norm, lf * middle_norm, lf * index_norm,\n",
    "                        lf * little_norm, lf * ring_norm, lf * middle_norm, lf * index_norm,\n",
    "                        lf * little_norm, lf * ring_norm, lf * middle_norm, lf * index_norm,\n",
    "                        rf * index_norm, rf * middle_norm, rf * ring_norm, rf * little_norm,\n",
    "                        rf * index_norm, rf * middle_norm, rf * ring_norm, rf * little_norm,\n",
    "                        rf * index_norm, rf * middle_norm, rf * ring_norm, rf * little_norm,\n",
    "                        lf * index_norm * penalty, lf * index_norm * penalty, lf * index_norm * penalty,\n",
    "                        rf * index_norm * penalty, rf * index_norm * penalty, rf * index_norm * penalty,\n",
    "                        rf * little_norm * penalty, rf * little_norm * penalty))\n",
    "\n",
    "# Create a finger-pair position strength matrix by adding pairs of strength values:\n",
    "Strength32x32 = np.zeros((32, 32))\n",
    "for i in range(32):\n",
    "    Strength32x32[i,:] = strengths32\n",
    "Strength32x32 = (Strength32x32 + Strength32x32.transpose())\n",
    "\n",
    "# Normalize matrix with min-max scaling to a range with maximum = 1:\n",
    "newMin = np.min(Strength32x32) / np.max(Strength32x32)\n",
    "newMax = 1.0\n",
    "Strength32x32 = newMin + (Strength32x32 - np.min(Strength32x32)) * (newMax - newMin) / (np.max(Strength32x32) - np.min(Strength32x32))\n",
    "\n",
    "# Print:\n",
    "print_matrix_info(matrix_data=Strength32x32, matrix_label=\"Strength32x32\", nkeys=32, nlines=10)\n",
    "heatmap(data=Strength32x32, title=\"Strength32x32\", xlabel=\"Key 1\", ylabel=\"Key 2\", print_output=print_output)\n",
    "\n",
    "# Save:\n",
    "if print_output:\n",
    "    file = open(\"Strength32x32.txt\", \"w+\")\n",
    "    file.write(str(Strength32x32))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dnn5-8S5DzRy"
   },
   "source": [
    "## Flow matrix and Engram scoring model  <a name=\"flow\">\n",
    "\n",
    "The Flow24x24 matrix takes into account ease of transition between ordered pairs of keys.\n",
    "    \n",
    "Our optimization algorithm finds every permutation of a given set of letters, maps these letter permutations to a set of keys, and ranks these letter-key mappings according to a score reflecting ease of typing key pairs and frequency of letter pairs (bigrams). The score is the average of the scores for all possible bigrams in this arrangement. The score for each bigram is a product of the frequency of occurrence of that bigram, the frequency of each of the bigrams characters, and flow, strength (and optional speed) factors for the key pair.\n",
    "\n",
    "#### Dvorak et al. (1936) defined eleven criteria for the design and evaluation of keyboard layouts:\n",
    "1.  Deviation from the balance of hand and finger loads should be as low as possible.\n",
    "2.  Percentage of tapping with the same fingers should be as low as possible.\n",
    "3.  Percentage of tapping that includes top row should be as low as possible.\n",
    "4.  Percentage of tapping that includes bottom row should be as low as possible.\n",
    "5.  Percentage of tapping in the home row should be as high as possible.\n",
    "6.  Percentage of tapping by alternating hands should be as high as possible.\n",
    "7.  Percentage of hurdles with the same finger should be as low as possible.\n",
    "8.  Percentage of hurdles with adjacent offset fingers should be as low as possible.\n",
    "9.  Percentage of hurdles with remote fingers should be as low as possible.\n",
    "10. Percentage of reach with the same finger should be as low as possible.\n",
    "11. Percentage of reach with adjacent offset fingers should be as low as possible.\n",
    "\n",
    "#### Synopsis of above criteria for pairwise key presses when touch typing:\n",
    "1. Alternate between hands.\n",
    "2. Balance finger loads, and avoid using the same finger.\n",
    "3. Avoid the upper and lower rows, and avoid skipping over the home row.\n",
    "4. Avoid tapping adjacent offset rows with the same or adjacent offset fingers.\n",
    "    \n",
    "### Factors to penalize strenuous key transitions\n",
    "\n",
    "Direction:\n",
    "    \n",
    "    - outward = 0.9: outward roll of fingers from the index to little finger (same hand)\n",
    "\n",
    "Dexterity:\n",
    "    \n",
    "    - side_above_3away = 0.9\n",
    "        - index and little finger type two keys, one or more rows apart (same hand)\n",
    "    - side_above_2away = 0.9^2 = 0.81\n",
    "        - index finger types key a row or two above ring finger key, or\n",
    "        - little finger types key a row or two above middle finger key (same hand)\n",
    "    - side_above_1away = 0.9^3 = 0.729\n",
    "        - index finger types key a row or two above middle finger key, or\n",
    "        - little finger types key a row or two above ring finger key (same hand)\n",
    "    - middle_above_ring = 0.9\n",
    "        - middle finger types key a row or two above ring finger key (same hand)\n",
    "    - ring_above_middle = 0.9^3 = 0.729\n",
    "        - ring finger types key a row or two above middle finger key (same hand)\n",
    "    - lateral = 0.9\n",
    "        - lateral movement of (index or little) finger outside of 8 vertical columns\n",
    "    \n",
    "Distance:\n",
    "    \n",
    "    - skip_row_3away = 0.9       \n",
    "        - index and little fingers type two keys that skip over home row (same hand)\n",
    "        - (e.g., one on bottom row, the other on top row)\n",
    "    - skip_row_2away = 0.9^3 = 0.729\n",
    "        - little and middle or index and ring fingers type two keys that skip over home row (same hand)\n",
    "    - skip_row_1away = 0.9^5 = 0.59049\n",
    "        - little and ring or middle and index fingers type two keys that skip over home row (same hand)\n",
    "\n",
    "Repetition:\n",
    " \n",
    "    - skip_row_0away = 0.9^4 = 0.6561\n",
    "        - same finger types two keys that skip over home row\n",
    "    - same_finger = 0.9^5 = 0.59049\n",
    "        - use same finger again for a different key\n",
    "        - cannot accompany outward, side_above, or adjacent_shorter_above \n",
    "\n",
    "Strength: Accounted for by the strength matrix (minimum value for the little finger = 0.9)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example flow values for left side home block\n",
    "   \n",
    "No penalty (for same hand, both keys in the same row in an inward roll or repeating the same key):\n",
    "\n",
    "    2=>2, 2=>3, 3=>4, 2=>4, 1=>4\n",
    "\n",
    "    1  2  3  4\n",
    "    5  6  7  8\n",
    "    9 10 11 12\n",
    "\n",
    "Penalty = 0.9:\n",
    "\n",
    "    outward: 2=>1, 3=>1, 3=>2, 4=>1, 4=>2, 4=>3, 6=>5, 7=>6, 7=>5, 8=>7, 8=>6, 8=>5,... \n",
    "    middle_above_ring: 6=>3, 10=>7 \n",
    "    side_above_3away: 1=>8, 5=>4, 5=>12, 9=>8\n",
    "    index_above: 1=>4, 2=>4, 3=>4, 4=>4\n",
    "\n",
    "Penalty = 0.9^2:\n",
    "\n",
    "    middle_above_ring * outward: 3=>6, 7=>10\n",
    "    side_above_3away * outward: 8=>1, 4=>5, 12=>5, 8=>9\n",
    "    side_above_2away: 1=>7, 6=>4, 5=>11, 10=>8    \n",
    "    skip_row_3away * side_above_3away: 1=>12, 9=>4\n",
    "    skip_row_2away: 2=>12, 9=>3\n",
    "    ring_above_middle 2=>7, 6=>11\n",
    "    side_above_2away * outward: 7=>1, 4=>6, 11=>5, 8=>10\n",
    "    side_above_1away: 1=>6, 7=>4, 5=>10, 11=>8\n",
    "\n",
    "Penalty = 0.9^3:\n",
    "\n",
    "    skip_row_3away * side_above_3away * outward: 12=>1, 4=>9\n",
    "\n",
    "Penalty = 0.9^4:\n",
    "\n",
    "    ring_above_middle * outward: 7=>2, 11=>6\n",
    "    side_above_1away * outward: 4=>7, 6=>1, 10=>5, 4=>7\n",
    "\n",
    "Penalty = 0.9^5:\n",
    "\n",
    "    same_finger: 4=>8, 8=>4, 1=>5, 5=>1, 5=>9, 9=>5, 2=>6, 6=>2,...\n",
    "    skip_row_2away * side_above_2away: 10=>4, 1=>11\n",
    "    skip_row_1away: 1=>10, 9=>2, 3=>12\n",
    "\n",
    "Penalty = 0.9^6:\n",
    "\n",
    "    skip_row_2away * side_above_2away * outward: 4=>10, 11=>1\n",
    "    skip_row_1away * outward: 10=>1, 2=>9, 12=>3\n",
    "\n",
    "Penalty = 0.9^8\n",
    "\n",
    "    skip_row_1away * ring_above_middle: 2=>11\n",
    "    skip_row_1away * side_above_1away: 1=>10, 11=>4\n",
    "\n",
    "Penalty = 0.9^9\n",
    "\n",
    "    skip_row_1away * ring_above_middle * outward: 11=>2\n",
    "    skip_row_0away * same_finger: 1=>9, 9=>1, 4=>12, 12=>4, 2=>10, 10=>2, 3=>11, 11=>3     \n",
    "    skip_row_1away * side_above_1away * outward: 10=>1, 4=>11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load code/load_flow_matrices.py\n",
    "# Penalizing factors for 24 keys  (1 = no penalty; set to less than 1 to penalize):\n",
    "\n",
    "# Dexterity\n",
    "side_above_3away = 0.9     # index and little finger type two keys, one or more rows apart (same hand)\n",
    "side_above_2away = 0.81    # index finger types key a row or two above ring finger key, or\n",
    "                           # little finger types key a row or two above middle finger key (same hand)\n",
    "side_above_1away = 0.729   # index finger types key a row or two above middle finger key, or\n",
    "                           # little finger types key a row or two above ring finger key (same hand)\n",
    "middle_above_ring = 0.9    # middle finger types key a row or two above ring finger key (same hand)\n",
    "ring_above_middle = 0.729  # ring finger types key a row or two above middle finger key (same hand)\n",
    "lateral = 0.9              # lateral movement of (index or little) finger outside of 8 vertical columns\n",
    "\n",
    "# Direction\n",
    "outward = 0.9              # outward roll of fingers from the index to little finger (same hand)\n",
    "\n",
    "# Distance\n",
    "skip_row_3away = 0.9       # index and little fingers type two keys that skip over home row (same hand)\n",
    "                           # (e.g., one on bottom row, the other on top row)\n",
    "skip_row_2away = 0.729     # little and middle or index and ring fingers type two keys that skip over home row (same hand)\n",
    "skip_row_1away = 0.59049   # little and ring or middle and index fingers type two keys that skip over home row (same hand)\n",
    "\n",
    "# Repetition\n",
    "skip_row_0away = 0.6561    # same finger types two keys that skip over home row\n",
    "same_finger = 0.59049      # use same finger again for a different key\n",
    "\n",
    "\n",
    "# Unused or redundant parameters\n",
    "same_hand = 1.0            # (addressed by splitting up the most frequent letters across left/right sides above)\n",
    "not_home_row = 1.0         # at least one key not on home row\n",
    "side_top = 1.0             # index or little finger types top corner key\n",
    "shorter_above = 1.0        # (taken care of by side_above_[1,2,3]away parameters)\n",
    "adjacent_offset = 1.0      # (taken care of by side_above_1away, middle_above_ring, ring_above_middle parameters)\n",
    "inside_top = 1.0           # index finger types top corner key (taken care of by side_above_1away parameter)\n",
    "index_above = 1.0          # index finger types top corner key (unless other bigram key is in the top row for the same hand)\n",
    "                           # (taken care of by side_above_[1,2,3]away parameters)\n",
    "\n",
    "\n",
    "def create_24x24_flow_matrix(not_home_row, side_top, side_above_3away, side_above_2away, side_above_1away, \n",
    "                             middle_above_ring, ring_above_middle, outward, skip_row_3away, \n",
    "                             skip_row_2away, skip_row_1away, skip_row_0away, same_finger, lateral, \n",
    "                             same_hand, shorter_above, adjacent_offset, inside_top, index_above):\n",
    "\n",
    "    all_24_keys = [1,2,3,4, 5,6,7,8, 9,10,11,12, 13,14,15,16, 17,18,19,20, 21,22,23,24]\n",
    "\n",
    "    # Create a matrix and multiply by flow factors that promote easy interkey transitions:\n",
    "    T = np.ones((24, 24))\n",
    "\n",
    "    # 7.  Promote alternating between hands over uncomfortable transitions with the same hand.\n",
    "    if same_hand < 1.0:\n",
    "    #    1  2  3  4   13 14 15 16  \n",
    "    #    5  6  7  8   17 18 19 20 \n",
    "    #    9 10 11 12   21 22 23 24\n",
    "        for i in range(0,12):\n",
    "            for j in range(0,12):\n",
    "                T[i,j] *= same_hand\n",
    "        for i in range(12,24):\n",
    "            for j in range(12,24):\n",
    "                T[i,j] *= same_hand\n",
    "\n",
    "    # 8.  Promote little-to-index-finger roll-ins over index-to-little-finger outwards.\n",
    "    #    1  2  3  4   13 14 15 16  \n",
    "    #    5  6  7  8   17 18 19 20 \n",
    "    #    9 10 11 12   21 22 23 24\n",
    "    if outward < 1.0:\n",
    "\n",
    "        # same-row roll-outs:\n",
    "        roll_ins = [[1,2],[2,3],[3,4], [5,6],[6,7],[7,8], [9,10],[10,11],[11,12],\n",
    "                    [16,15],[15,14],[14,13], [20,19],[19,18],[18,17], [24,23],[23,22],[22,21]]\n",
    "        for x in roll_ins:\n",
    "            T[x[1]-1, x[0]-1] *= outward\n",
    "\n",
    "        # same-row roll-outs, skipping keys:\n",
    "        roll_ins_skip_keys = [[1,3],[2,4],[1,4], [5,7],[6,8],[5,8], [9,11],[10,12],[9,12],\n",
    "                              [16,14],[15,13],[16,13], [20,18],[19,17],[20,17], [24,22],[23,21],[24,21]]\n",
    "        for x in roll_ins_skip_keys:\n",
    "            T[x[1]-1, x[0]-1] *= outward\n",
    "\n",
    "        # adjacent-row roll-outs:\n",
    "        roll_ins_adj_rows = [[1,6],[1,7],[1,8],[2,7],[2,8],[3,8], [5,2],[5,3],[5,4],[6,3],[6,4],[7,4],\n",
    "                             [5,10],[5,11],[5,12],[6,11],[6,12],[7,12], [9,6],[9,7],[9,8],[10,7],[10,8],[11,8],\n",
    "                             [16,19],[16,18],[16,17],[15,18],[15,17],[14,17], [20,15],[20,14],[20,13],[19,14],[19,13],[18,13],\n",
    "                             [20,23],[20,22],[20,21],[19,22],[19,21],[18,21], [24,19],[24,18],[24,17],[23,18],[23,17],[22,17]]\n",
    "        for x in roll_ins_adj_rows:\n",
    "            T[x[1]-1, x[0]-1] *= outward\n",
    "\n",
    "        # upper<->lower row roll-outs:\n",
    "        roll_ins_skip_home = [[1,10],[1,11],[1,12],[2,11],[2,12],[3,12], [9,2],[9,3],[9,4],[10,3],[10,4],[11,4],\n",
    "                              [16,23],[16,22],[16,21],[15,22],[15,21],[14,21], [24,15],[24,14],[24,13],[23,14],[23,13],[22,13]]\n",
    "        for x in roll_ins_skip_home:\n",
    "            T[x[1]-1, x[0]-1] *= outward\n",
    "\n",
    "    # 9.  Avoid stretching shorter fingers up and longer fingers down.\n",
    "    #    1  2  3  4   13 14 15 16  \n",
    "    #    5  6  7  8   17 18 19 20 \n",
    "    #    9 10 11 12   21 22 23 24\n",
    "    if index_above < 1.0:\n",
    "        for x in [4]:\n",
    "            for y in [4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]:\n",
    "                T[x-1, y-1] *= index_above\n",
    "                T[y-1, x-1] *= index_above\n",
    "        for x in [13]:\n",
    "            for y in [1,2,3,4,5,6,7,8,9,10,11,12,13,17,18,19,20,21,22,23,24]:\n",
    "                T[x-1, y-1] *= index_above\n",
    "                T[y-1, x-1] *= index_above\n",
    "    if inside_top < 1.0:\n",
    "        for x in [4,13]:\n",
    "            for j in range(0,24):\n",
    "                T[x-1, j] *= inside_top\n",
    "                T[j, x-1] *= inside_top\n",
    "    if side_top < 1.0:\n",
    "        for x in [1,4,13,16]:\n",
    "            for j in range(0,24):\n",
    "                T[x-1, j] *= side_top\n",
    "                T[j, x-1] *= side_top\n",
    "    if side_above_1away < 1.0:\n",
    "        for x in [1]:\n",
    "            for y in [6,10]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [5]:\n",
    "            for y in [10]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [4]:\n",
    "            for y in [7,11]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [8]:\n",
    "            for y in [11]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [13]:\n",
    "            for y in [18,22]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [17]:\n",
    "            for y in [22]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [16]:\n",
    "            for y in [19,23]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [20]:\n",
    "            for y in [23]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "    if side_above_2away < 1.0:\n",
    "        for x in [1]:\n",
    "            for y in [7,11]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [5]:\n",
    "            for y in [11]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [4]:\n",
    "            for y in [6,10]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [8]:\n",
    "            for y in [10]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [13]:\n",
    "            for y in [19,23]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [17]:\n",
    "            for y in [23]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [16]:\n",
    "            for y in [18,22]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [20]:\n",
    "            for y in [22]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "    if side_above_3away < 1.0:\n",
    "        for x in [1]:\n",
    "            for y in [8,12]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [5]:\n",
    "            for y in [12]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [4]:\n",
    "            for y in [5,9]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [8]:\n",
    "            for y in [9]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [13]:\n",
    "            for y in [20,24]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [17]:\n",
    "            for y in [24]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [16]:\n",
    "            for y in [17,21]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [20]:\n",
    "            for y in [21]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "    if shorter_above < 1.0:\n",
    "        for x in [1]:\n",
    "            for y in [6,7,8,10,11,12]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [2]:\n",
    "            for y in [7,11]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [4]:\n",
    "            for y in [6,7,10,11]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "\n",
    "        for x in [5]:\n",
    "            for y in [10,11,12]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [6]:\n",
    "            for y in [11]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [8]:\n",
    "            for y in [10,11]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "\n",
    "        for x in [16]:\n",
    "            for y in [17,18,19,21,22,23]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [15]:\n",
    "            for y in [18,22]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [13]:\n",
    "            for y in [18,19,22,23]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "\n",
    "        for x in [20]:\n",
    "            for y in [21,22,23]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [19]:\n",
    "            for y in [22]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [17]:\n",
    "            for y in [22,23]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "\n",
    "    if ring_above_middle < 1.0:\n",
    "        ring_above_middles =  [[2,7],[6,11],[2,11],\n",
    "                            [15,18],[19,22],[15,22]]\n",
    "        for x in ring_above_middles:\n",
    "            T[x[0]-1, x[1]-1] *= ring_above_middle\n",
    "            T[x[1]-1, x[0]-1] *= ring_above_middle\n",
    "\n",
    "    if middle_above_ring < 1.0:\n",
    "        middle_above_rings =  [[6,3],[10,7],[10,3],\n",
    "                            [19,14],[23,18],[23,14]]\n",
    "        for x in middle_above_rings:\n",
    "            T[x[0]-1, x[1]-1] *= middle_above_ring\n",
    "            T[x[1]-1, x[0]-1] *= middle_above_ring\n",
    "\n",
    "    # 10. Avoid using the same finger.\n",
    "    #    1  2  3  4   13 14 15 16  \n",
    "    #    5  6  7  8   17 18 19 20 \n",
    "    #    9 10 11 12   21 22 23 24\n",
    "    if same_finger < 1.0:\n",
    "        same_fingers = [[1,5],[5,9],[1,9], [2,6],[6,10],[2,10], [3,7],[7,11],[3,11], [4,8],[8,12],[4,12],\n",
    "                        [13,17],[17,21],[13,21], [14,18],[18,22],[14,22], [15,19],[19,23],[15,23], [16,20],[20,24],[16,24]] \n",
    "        for x in same_fingers:\n",
    "            T[x[0]-1, x[1]-1] *= same_finger\n",
    "            T[x[1]-1, x[0]-1] *= same_finger\n",
    "\n",
    "    # 11. Avoid the upper and lower rows.\n",
    "    #    1  2  3  4   13 14 15 16  \n",
    "    #    5  6  7  8   17 18 19 20 \n",
    "    #    9 10 11 12   21 22 23 24\n",
    "    if not_home_row < 1.0:\n",
    "        not_home_row_keys = [1,2,3,4, 9,10,11,12, 13,14,15,16, 21,22,23,24]\n",
    "        for x in not_home_row_keys:\n",
    "            for j in range(0,23):\n",
    "                T[x-1, j] *= not_home_row\n",
    "                T[j, x-1] *= not_home_row\n",
    "\n",
    "    # 12. Avoid skipping over the home row.\n",
    "    #    1  2  3  4   13 14 15 16  \n",
    "    #    5  6  7  8   17 18 19 20 \n",
    "    #    9 10 11 12   21 22 23 24\n",
    "    if skip_row_0away < 1.0:\n",
    "        skip_top = [1, 2, 3, 4, 13,14,15,16] \n",
    "        skip_bot = [9,10,11,12, 21,22,23,24] \n",
    "        for ix, x in enumerate(skip_top):\n",
    "            y = skip_bot[ix]\n",
    "            T[x-1, y-1] *= skip_row_0away\n",
    "            T[y-1, x-1] *= skip_row_0away\n",
    "    if skip_row_1away < 1.0:\n",
    "        skip_top = [1, 2, 2, 3, 3, 4, 13,14,14,15,15,16] \n",
    "        skip_bot = [10,9,11,10,12,11, 22,21,23,22,24,23] \n",
    "        for ix, x in enumerate(skip_top):\n",
    "            y = skip_bot[ix]\n",
    "            T[x-1, y-1] *= skip_row_1away\n",
    "            T[y-1, x-1] *= skip_row_1away\n",
    "    if skip_row_2away < 1.0:\n",
    "        skip_top = [1,  2,3, 4, 13,14,15,16] \n",
    "        skip_bot = [11,12,9,10, 23,24,21,22] \n",
    "        for ix, x in enumerate(skip_top):\n",
    "            y = skip_bot[ix]\n",
    "            T[x-1, y-1] *= skip_row_2away\n",
    "            T[y-1, x-1] *= skip_row_2away\n",
    "    if skip_row_3away < 1.0:\n",
    "        skip_top = [1, 4, 13,16] \n",
    "        skip_bot = [12,9, 24,21] \n",
    "        for ix, x in enumerate(skip_top):\n",
    "            y = skip_bot[ix]\n",
    "            T[x-1, y-1] *= skip_row_3away\n",
    "            T[y-1, x-1] *= skip_row_3away\n",
    "\n",
    "    Flow24x24 = T\n",
    "\n",
    "    # Normalize matrix with min-max scaling to a range with maximum = 1:\n",
    "    newMin = np.min(Flow24x24) / np.max(Flow24x24)\n",
    "    newMax = 1.0\n",
    "    Flow24x24 = newMin + (Flow24x24 - np.min(Flow24x24)) * (newMax - newMin) / (np.max(Flow24x24) - np.min(Flow24x24))\n",
    "\n",
    "    return Flow24x24\n",
    "\n",
    "Flow24x24 = create_24x24_flow_matrix(not_home_row, side_top, \n",
    "    side_above_3away, side_above_2away, side_above_1away, middle_above_ring, ring_above_middle, outward, \n",
    "    skip_row_3away, skip_row_2away, skip_row_1away, skip_row_0away, same_finger, lateral, same_hand, \n",
    "    shorter_above, adjacent_offset, inside_top, index_above)\n",
    "\n",
    "# Print:\n",
    "print_matrix_info(matrix_data=Flow24x24, matrix_label=\"Flow24x24\", nkeys=24, nlines=30)\n",
    "heatmap(data=Flow24x24, title=\"Flow24x24\", xlabel=\"Key 1\", ylabel=\"Key 2\", print_output=print_output)\n",
    "\n",
    "# Save:\n",
    "if print_output:\n",
    "    file = open(\"Flow24x24.txt\", \"w+\")\n",
    "    file.write(str(Flow24x24))\n",
    "    file.close()\n",
    "\n",
    "#    1  2  3  4   13 14 15 16  \n",
    "#    5  6  7  8   17 18 19 20 \n",
    "#    9 10 11 12   21 22 23 24\n",
    "\n",
    "\n",
    "\n",
    "def create_32x32_flow_matrix(not_home_row, side_top, side_above_3away, side_above_2away, side_above_1away, \n",
    "                             middle_above_ring, ring_above_middle, outward, skip_row_3away, \n",
    "                             skip_row_2away, skip_row_1away, skip_row_0away, same_finger, lateral, \n",
    "                             same_hand, shorter_above, adjacent_offset, inside_top, index_above):\n",
    "\n",
    "    all_32_keys = [1,2,3,4, 5,6,7,8, 9,10,11,12, 13,14,15,16, 17,18,19,20, 21,22,23,24, \n",
    "                   25,26,27, 28,29,30, 31,32]\n",
    "\n",
    "    # Create a matrix and multiply by flow factors that promote easy interkey transitions:\n",
    "    T = np.ones((32, 32))\n",
    "\n",
    "    if lateral < 1.0:\n",
    "        for x in all_32_keys:\n",
    "            for y in [25,26,27, 28,29,30, 31,32]:\n",
    "                T[x-1, y-1] *= lateral\n",
    "                T[y-1, x-1] *= lateral    \n",
    "\n",
    "    # 7.  Promote alternating between hands over uncomfortable transitions with the same hand.\n",
    "    if same_hand < 1.0:\n",
    "        for i in [1,2,3,4,5,6,7,8,9,10,11,12, 25,26,27]:\n",
    "            for j in [1,2,3,4,5,6,7,8,9,10,11,12, 25,26,27]:\n",
    "                T[i-1,j-1] *= same_hand\n",
    "        for i in [13,14,15,16,17,18,19,20,21,22,23,24, 28,29,30,31,32]:\n",
    "            for j in [13,14,15,16,17,18,19,20,21,22,23,24, 28,29,30,31,32]:\n",
    "                T[i-1,j-1] *= same_hand\n",
    "\n",
    "    # 8.  Promote little-to-index-finger roll-ins over index-to-little-finger outsward rolls.\n",
    "    # Penalize (index, little) finger lateral movements:\n",
    "    #  1  2  3  4 25   28 13 14 15 16 31 \n",
    "    #  5  6  7  8 26   29 17 18 19 20 32\n",
    "    #  9 10 11 12 27   30 21 22 23 24\n",
    "    if outward < 1.0:\n",
    "\n",
    "        # same-row roll-outs:\n",
    "        roll_ins = [[1,2],[2,3],[3,4], [5,6],[6,7],[7,8], [9,10],[10,11],[11,12],\n",
    "                    [4,25],[8,26],[12,27],\n",
    "                    [16,15],[15,14],[14,13], [20,19],[19,18],[18,17], [24,23],[23,22],[22,21],\n",
    "                    [13,28],[17,29],[21,30], [31,16],[32,20]]\n",
    "        for x in roll_ins:\n",
    "            T[x[1]-1, x[0]-1] *= outward\n",
    "\n",
    "        # same-row roll-outs, skipping keys:\n",
    "        roll_ins_skip_keys = [[1,3],[2,4],[1,4], [5,7],[6,8],[5,8], [9,11],[10,12],[9,12],\n",
    "                              [1,25],[2,25],[3,25],\n",
    "                              [5,26],[6,26],[7,26],\n",
    "                              [9,27],[10,27],[11,27],\n",
    "                              [16,14],[15,13],[16,13], [20,18],[19,17],[20,17], [24,22],[23,21],[24,21],\n",
    "                              [16,28],[15,28],[14,28],\n",
    "                              [20,29],[19,29],[18,29],\n",
    "                              [24,30],[23,30],[22,30],\n",
    "                              [31,15],[31,14],[31,13],[31,28],\n",
    "                              [32,19],[32,18],[32,17],[32,29]]\n",
    "        for x in roll_ins_skip_keys:\n",
    "            T[x[1]-1, x[0]-1] *= outward\n",
    "\n",
    "        # adjacent-row roll-outs:\n",
    "        #  1  2  3  4 25   28 13 14 15 16 31 \n",
    "        #  5  6  7  8 26   29 17 18 19 20 32\n",
    "        #  9 10 11 12 27   30 21 22 23 24\n",
    "        roll_ins_adj_rows = [[1,6],[1,7],[1,8],[2,7],[2,8],[3,8], \n",
    "                             [5,2],[5,3],[5,4],[6,3],[6,4],[7,4],\n",
    "                             [5,10],[5,11],[5,12],[6,11],[6,12],[7,12], \n",
    "                             [9,6],[9,7],[9,8],[10,7],[10,8],[11,8],\n",
    "                             [5,25],[6,25],[7,25],[8,25],\n",
    "                             [5,27],[6,27],[7,27],[8,27],\n",
    "                             [1,26],[2,26],[3,26],[4,26],\n",
    "                             [9,26],[10,26],[11,26],[12,26],\n",
    "                             [16,19],[16,18],[16,17],[15,18],[15,17],[14,17], \n",
    "                             [20,15],[20,14],[20,13],[19,14],[19,13],[18,13],\n",
    "                             [20,23],[20,22],[20,21],[19,22],[19,21],[18,21], \n",
    "                             [24,19],[24,18],[24,17],[23,18],[23,17],[22,17],\n",
    "                             [16,29],[15,29],[14,29],[13,29],\n",
    "                             [24,29],[23,29],[22,29],[21,29],\n",
    "                             [20,28],[19,28],[18,28],[17,28],\n",
    "                             [20,30],[19,30],[18,30],[17,30],\n",
    "                             [31,20],[31,19],[31,18],[31,17],[31,29],\n",
    "                             [32,16],[32,15],[32,14],[32,13],[32,28],\n",
    "                             [32,24],[32,23],[32,22],[32,21],[32,30]]\n",
    "        for x in roll_ins_adj_rows:\n",
    "            T[x[1]-1, x[0]-1] *= outward\n",
    "\n",
    "        # upper<->lower row roll-outs:\n",
    "        roll_ins_skip_home = [[1,10],[1,11],[1,12],[1,27],[2,11],[2,12],[2,27],[3,12],[3,27],[4,27], \n",
    "                              [9,2],[9,3],[9,4],[9,25],[10,3],[10,4],[10,25],[11,4],[11,25],[12,25],\n",
    "                              [16,23],[16,22],[16,21],[16,30],[15,22],[15,21],[15,30],[14,21],[14,30],[13,30],\n",
    "                              [24,15],[24,14],[24,13],[24,28],[23,14],[23,13],[23,28],[22,13],[22,28],[21,28],\n",
    "                              [31,24],[31,23],[31,22],[31,21],[31,30]]\n",
    "        for x in roll_ins_skip_home:\n",
    "            T[x[1]-1, x[0]-1] *= outward\n",
    "\n",
    "    # 9.  Avoid stretching shorter fingers up and longer fingers down.\n",
    "    #  1  2  3  4 25   28 13 14 15 16 31 \n",
    "    #  5  6  7  8 26   29 17 18 19 20 32\n",
    "    #  9 10 11 12 27   30 21 22 23 24\n",
    "    if index_above < 1.0:\n",
    "        for x in [4]:\n",
    "            for y in [4,5,6,7,8,26,9,10,11,12,27,28,13,14,15,16,31,29,17,18,19,20,32,30,21,22,23,24]:\n",
    "                T[x-1, y-1] *= index_above\n",
    "                T[y-1, x-1] *= index_above\n",
    "        for x in [25]:\n",
    "            for y in [25,5,6,7,8,26,9,10,11,12,27,28,13,14,15,16,31,29,17,18,19,20,32,30,21,22,23,24]:\n",
    "                T[x-1, y-1] *= index_above\n",
    "                T[y-1, x-1] *= index_above\n",
    "        for x in [13]:\n",
    "            for y in [1,2,3,4,25,5,6,7,8,26,9,10,11,12,27,13,29,17,18,19,20,32,30,21,22,23,24]:\n",
    "                T[x-1, y-1] *= index_above\n",
    "                T[y-1, x-1] *= index_above\n",
    "        for x in [28]:\n",
    "            for y in [1,2,3,4,25,5,6,7,8,26,9,10,11,12,27,28,29,17,18,19,20,32,30,21,22,23,24]:\n",
    "                T[x-1, y-1] *= index_above\n",
    "                T[y-1, x-1] *= index_above\n",
    "    if inside_top < 1.0:\n",
    "        for x in [4,25,28,13]:\n",
    "            for j in range(0,32):\n",
    "                T[x-1, j] *= inside_top\n",
    "                T[j, x-1] *= inside_top\n",
    "    if side_top < 1.0:\n",
    "        for x in [1,4,25,28,13,16,31]:\n",
    "            for j in range(0,32):\n",
    "                T[x-1, j] *= side_top\n",
    "                T[j, x-1] *= side_top\n",
    "    if side_above_1away < 1.0:\n",
    "        for x in [1]:\n",
    "            for y in [6,10]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [5]:\n",
    "            for y in [10]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [4,25]:\n",
    "            for y in [7,11]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [8,26]:\n",
    "            for y in [11]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [13,28]:\n",
    "            for y in [18,22]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [17,29]:\n",
    "            for y in [22]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [16,31]:\n",
    "            for y in [19,23]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "        for x in [20,32]:\n",
    "            for y in [23]:\n",
    "                T[x-1, y-1] *= side_above_1away\n",
    "                T[y-1, x-1] *= side_above_1away\n",
    "    if side_above_2away < 1.0:\n",
    "        for x in [1]:\n",
    "            for y in [7,11]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [5]:\n",
    "            for y in [11]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [4,25]:\n",
    "            for y in [6,10]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [8,26]:\n",
    "            for y in [10]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [13,28]:\n",
    "            for y in [19,23]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [17,29]:\n",
    "            for y in [23]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [16,31]:\n",
    "            for y in [18,22]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "        for x in [20,32]:\n",
    "            for y in [22]:\n",
    "                T[x-1, y-1] *= side_above_2away\n",
    "                T[y-1, x-1] *= side_above_2away\n",
    "    if side_above_3away < 1.0:\n",
    "        for x in [1]:\n",
    "            for y in [8,12,26,27]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [5]:\n",
    "            for y in [12,27]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [4,25]:\n",
    "            for y in [5,9]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [8,26]:\n",
    "            for y in [9]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [13,28]:\n",
    "            for y in [20,24,32]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [17,29]:\n",
    "            for y in [24]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [16,31]:\n",
    "            for y in [17,21,29,30]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "        for x in [20,32]:\n",
    "            for y in [21,30]:\n",
    "                T[x-1, y-1] *= side_above_3away\n",
    "                T[y-1, x-1] *= side_above_3away\n",
    "\n",
    "\n",
    "    #  1  2  3  4 25   28 13 14 15 16 31 \n",
    "    #  5  6  7  8 26   29 17 18 19 20 32\n",
    "    #  9 10 11 12 27   30 21 22 23 24\n",
    "    if shorter_above < 1.0:\n",
    "        for x in [1]:\n",
    "            for y in [6,7,8,26,10,11,12,27]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [2]:\n",
    "            for y in [7,11]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [4]:\n",
    "            for y in [6,7,10,11]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [25]:\n",
    "            for y in [6,7,10,11]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "\n",
    "        for x in [5]:\n",
    "            for y in [10,11,12,27]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [6]:\n",
    "            for y in [11]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [8]:\n",
    "            for y in [10,11]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [26]:\n",
    "            for y in [10,11]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "\n",
    "        for x in [16]:\n",
    "            for y in [29,17,18,19,30,21,22,23]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [31]:\n",
    "            for y in [29,17,18,19,30,21,22,23]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [15]:\n",
    "            for y in [18,22]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [13]:\n",
    "            for y in [18,19,22,23]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [28]:\n",
    "            for y in [18,19,22,23]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "\n",
    "        for x in [20]:\n",
    "            for y in [30,21,22,23]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [32]:\n",
    "            for y in [30,21,22,23]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [19]:\n",
    "            for y in [22]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [17]:\n",
    "            for y in [22,23]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "        for x in [29]:\n",
    "            for y in [22,23]:\n",
    "                T[x-1, y-1] *= shorter_above\n",
    "                T[y-1, x-1] *= shorter_above\n",
    "\n",
    "    if ring_above_middle < 1.0:\n",
    "        ring_above_middles =  [[2,7],[6,11],[2,11],\n",
    "                            [15,18],[19,22],[15,22]]\n",
    "        for x in ring_above_middles:\n",
    "            T[x[0]-1, x[1]-1] *= ring_above_middle\n",
    "            T[x[1]-1, x[0]-1] *= ring_above_middle\n",
    "\n",
    "    if middle_above_ring < 1.0:\n",
    "        middle_above_rings =  [[6,3],[10,7],[10,3],\n",
    "                            [19,14],[23,18],[23,14]]\n",
    "        for x in middle_above_rings:\n",
    "            T[x[0]-1, x[1]-1] *= middle_above_ring\n",
    "            T[x[1]-1, x[0]-1] *= middle_above_ring\n",
    "\n",
    "    # 10. Avoid using the same finger.\n",
    "    #  1  2  3  4 25   28 13 14 15 16 31 \n",
    "    #  5  6  7  8 26   29 17 18 19 20 32\n",
    "    #  9 10 11 12 27   30 21 22 23 24\n",
    "    if same_finger < 1.0:\n",
    "        same_fingers = [[1,5],[5,9],[1,9], [2,6],[6,10],[2,10], \n",
    "                        [3,7],[7,11],[3,11], [4,8],[8,12],[4,12],\n",
    "                        [25,26],[26,27],[25,27], [28,29],[29,30],[28,30], [31,32],\n",
    "                        [4,25],[4,26],[4,27], [8,25],[8,26],[8,27], [12,25],[12,26],[12,27],\n",
    "                        [13,28],[13,29],[13,30], [17,28],[17,29],[17,30], [21,28],[21,29],[21,30],\n",
    "                        [31,16],[31,20],[31,24], [32,16],[32,20],[32,24],\n",
    "                        [13,17],[17,21],[13,21], [14,18],[18,22],[14,22], \n",
    "                        [15,19],[19,23],[15,23], [16,20],[20,24],[16,24]] \n",
    "        for x in same_fingers:\n",
    "            T[x[0]-1, x[1]-1] *= same_finger\n",
    "            T[x[1]-1, x[0]-1] *= same_finger\n",
    "\n",
    "    # 11. Avoid the upper and lower rows.\n",
    "    if not_home_row < 1.0:\n",
    "        not_home_row_keys = [1,2,3,4,25, 9,10,11,12,27, 28,13,14,15,16,31, 30,21,22,23,24]\n",
    "        for x in not_home_row_keys:\n",
    "            for j in range(0,32):\n",
    "                T[x-1, j] *= not_home_row\n",
    "                T[j, x-1] *= not_home_row\n",
    "                \n",
    "    # 12. Avoid skipping over the home row.\n",
    "    #  1  2  3  4 25   28 13 14 15 16 31 \n",
    "    #  5  6  7  8 26   29 17 18 19 20 32\n",
    "    #  9 10 11 12 27   30 21 22 23 24\n",
    "    if skip_row_0away < 1.0:\n",
    "        skip_top = [1, 2, 3, 4, 4,25,25, 28,28,13,13,14,15,16,31] \n",
    "        skip_bot = [9,10,11,12,27,12,27, 30,21,30,21,22,23,24,24] \n",
    "        for ix, x in enumerate(skip_top):\n",
    "            y = skip_bot[ix]\n",
    "            T[x-1, y-1] *= skip_row_0away\n",
    "            T[y-1, x-1] *= skip_row_0away\n",
    "    if skip_row_1away < 1.0:\n",
    "        skip_top = [1, 2, 2, 3, 3, 4, 4,25, 28,13,13,14,14,15,15,16,31] \n",
    "        skip_bot = [10,9,11,10,12,11,27,11, 22,30,22,21,23,22,24,23,23] \n",
    "        for ix, x in enumerate(skip_top):\n",
    "            y = skip_bot[ix]\n",
    "            T[x-1, y-1] *= skip_row_1away\n",
    "            T[y-1, x-1] *= skip_row_1away\n",
    "    if skip_row_2away < 1.0:\n",
    "        skip_top = [1,  2,3, 4,25, 28,13,14,15,16,31] \n",
    "        skip_bot = [11,12,9,10,10, 23,23,24,21,22,22] \n",
    "        for ix, x in enumerate(skip_top):\n",
    "            y = skip_bot[ix]\n",
    "            T[x-1, y-1] *= skip_row_2away\n",
    "            T[y-1, x-1] *= skip_row_2away\n",
    "    if skip_row_3away < 1.0:\n",
    "        skip_top = [1, 4,25, 28,13,16,16,31,31] \n",
    "        skip_bot = [12,9, 9, 24,24,21,30,21,30] \n",
    "        for ix, x in enumerate(skip_top):\n",
    "            y = skip_bot[ix]\n",
    "            T[x-1, y-1] *= skip_row_3away\n",
    "            T[y-1, x-1] *= skip_row_3away\n",
    "                \n",
    "    Flow32x32 = T\n",
    "\n",
    "    # Normalize matrix with min-max scaling to a range with maximum = 1:\n",
    "    newMin = np.min(Flow32x32) / np.max(Flow32x32)\n",
    "    newMax = 1.0\n",
    "    Flow32x32 = newMin + (Flow32x32 - np.min(Flow32x32)) * (newMax - newMin) / (np.max(Flow32x32) - np.min(Flow32x32))\n",
    "\n",
    "    return Flow32x32\n",
    "\n",
    "Flow32x32 = create_32x32_flow_matrix(not_home_row, side_top, \n",
    "    side_above_3away, side_above_2away, side_above_1away, middle_above_ring, ring_above_middle, outward, \n",
    "    skip_row_3away, skip_row_2away, skip_row_1away, skip_row_0away, same_finger, lateral, same_hand, \n",
    "    shorter_above, adjacent_offset, inside_top, index_above)\n",
    "\n",
    "# Print:\n",
    "print_matrix_info(matrix_data=Flow32x32, matrix_label=\"Flow32x32\", nkeys=32, nlines=30)\n",
    "heatmap(data=Flow32x32, title=\"Flow32x32\", xlabel=\"Key 1\", ylabel=\"Key 2\", print_output=print_output)\n",
    "\n",
    "# Save:\n",
    "if print_output:\n",
    "    file = open(\"Flow32x32.txt\", \"w+\")\n",
    "    file.write(str(Flow32x32))\n",
    "    file.close()\n",
    "\n",
    "#  1  2  3  4 25   28 13 14 15 16 31 \n",
    "#  5  6  7  8 26   29 17 18 19 20 32\n",
    "#  9 10 11 12 27   30 21 22 23 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WMvP493uDzSU"
   },
   "source": [
    "## Combine Strength and Flow matrices  <a name=\"strengthflow\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 695
    },
    "colab_type": "code",
    "id": "UP7FUBR2DzSX",
    "outputId": "5dc11788-2c69-4f69-ab60-a07ac17e092f"
   },
   "outputs": [],
   "source": [
    "# %load code/combine_scoring_matrices.py\n",
    "# 24 keys:\n",
    "Factors24x24 = Flow24x24\n",
    "if apply_strength:\n",
    "    Factors24x24 = Strength24x24 * Factors24x24\n",
    "\n",
    "# Print:\n",
    "print_matrix_info(matrix_data=Factors24x24, matrix_label=\"Factors24x24\", nkeys=24, nlines=30)\n",
    "heatmap(data=Factors24x24, title=\"Factors24x24\", xlabel=\"Key 1\", ylabel=\"Key 2\", print_output=print_output)\n",
    "\n",
    "# Save:\n",
    "if print_output:\n",
    "    file = open(\"Factors24x24.txt\", \"w+\")\n",
    "    file.write(str(Factors24x24))\n",
    "    file.close()\n",
    "\n",
    "\n",
    "# 32 keys:\n",
    "Factors32x32 = Flow32x32\n",
    "if apply_strength:\n",
    "    Factors32x32 = Strength32x32 * Factors32x32\n",
    "\n",
    "# Print:\n",
    "print_matrix_info(matrix_data=Factors32x32, matrix_label=\"Factors32x32\", nkeys=32, nlines=30)\n",
    "heatmap(data=Factors32x32, title=\"Factors32x32\", xlabel=\"Key 1\", ylabel=\"Key 2\", print_output=print_output)\n",
    "\n",
    "# Save:\n",
    "if print_output:\n",
    "    file = open(\"Factors32x32.txt\", \"w+\")\n",
    "    file.write(str(Factors32x32))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four steps\n",
    "\n",
    "We will assign letters to keys by choosing the arrangement with the highest score according to our scoring model. However, there are over four hundred septillion, or four hundred trillion trillion (26! = 403,291,461,126,605,635,584,000,000, or 4.032914611 E+26) possible arrangements of 26 letters (24! = 6.204484017 E+23), so we will arrange the letters in four steps, based on ergonomics principles. These consist of (Step 1) assigning the eight most frequent letters to different keys, optimizing assignment of the remaining (Step 2) eight most frequent letters, and (Step 3) eight least frequent letters (besides Z and Q), and (Step 4) exchanging letters. \n",
    "\n",
    "## Step 1: Define the shape of the key layout to minimize lateral finger movements<a name=\"step1\">\n",
    "\n",
    "We will assign 24 letters to 8 columns of keys separated by two middle columns reserved for punctuation. These 8 columns require no lateral finger movements when touch typing, since there is one column per finger. The most comfortable keys include the left and right home rows (keys 5-8 and 17-20), the top-center keys (2,3 and 14,15) that allow the longer middle and ring fingers to uncurl upwards, as well as the bottom corner keys (9,12 and 21,24) that allow the shorter fingers to curl downwards. We will assign the two least frequent letters, Z and Q (or J), to the two hardest-to-reach keys lying outside the 24-key columns in the upper right (25 and 26):\n",
    "\n",
    "        Left:            Right:\n",
    "     1  2  3  4       13 14 15 16 25\n",
    "     5  6  7  8       17 18 19 20 26\n",
    "     9 10 11 12       21 22 23 24\n",
    "\n",
    "We will consider the most comfortable keys to be those typed by either hand on the home row, by the ring and middle finger above the home row, and by the index and little finger below the home row, with a preference for the strongest (index and middle) fingers:\n",
    "    \n",
    "     -  2  3  -        - 14 15  -  \n",
    "     5  6  7  8       17 18 19 20  \n",
    "     9  -  - 12       21  -  - 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "REInHU9tdYLP"
   },
   "source": [
    "## Step 2: Arrange the most frequent letters based on comfort and bigram frequencies  <a name=\"step2\">\n",
    "\n",
    "In prior experiments using the methods below, all vowels consistently automatically clustered together. Below, we will arrange vowels on one side and the most frequent consonants to the other side to encourage balance and alternation across hands. Since aside from the letters Z and Q there is symmetry across left and right sides, we will decide later which side the vowels and which side the most frequent consonants should go.\n",
    "\n",
    "### Vowels\n",
    "    \n",
    "**E**, T, **A, O, I**, N, S, R, H, L, D, C, U, M, F, P, G, W, Y, B, V, K, X, J, Q, Z\n",
    "\n",
    "The highest frequency bigrams that contain two vowels are listed below in bold, with more than 10 billion instances in Peter Norvig's analysis of Google data:\n",
    "\n",
    "**OU, IO, EA, IE**, AI, IA, EI, UE, UA, AU, UI, OI, EO, OA, OE \n",
    "    \n",
    "     OU  24,531,132,241\n",
    "     IO  23,542,263,265\n",
    "     EA  19,403,941,063\n",
    "     IE  10,845,731,320\n",
    "     AI   8,922,759,715\n",
    "     IA   8,072,199,471   \n",
    "     EI   5,169,898,489\n",
    "     UE   4,158,448,570       \n",
    "     UA   3,844,138,094   \n",
    "     AU   3,356,322,923\n",
    "     UI   2,852,182,384\n",
    "     OI   2,474,275,212\n",
    "     EO   2,044,268,477\n",
    "     OA   1,620,913,259\n",
    "     OE   1,089,254,517 \n",
    "   \n",
    "We will assign the most frequent vowels with over 100 billion instances in Norvig's analysis (E,A,O,I) to four of the six most comfortable keys on the left side of the keyboard (keys 2,3,5,6,7,8). We will assign the letter E, the most frequent in the English language, to either of the strongest (index and middle) fingers on the home row, and assign the other three vowels such that (1) the home row keys typed by the index and middle fingers are not left vacant, and any top-frequency bigram (more than 10 billion instances in Norvig's analysis) (1) does not use the same finger and (2) reads from left to right (ex: EA, not AE) for ease of typing (roll-in from little to index finger vs. roll-out from index to little finger). These constraints lead to three arrangements of the four vowels:\n",
    "\n",
    "    - - O -    - - O -    - - - -    \n",
    "    - I E A    I - E A    I O E A\n",
    "    - - - -    - - - -    - - - -\n",
    "\n",
    "### Consonants\n",
    "\n",
    "On the right side of the keyboard, we will assign four of the five most frequent consonants (with over 150 billion instances in Norvig's analysis: T, N, S, R, and H) to the four home row keys. We will assign the letter T, the most frequent consonant in the English language, to either of the strongest (index and middle) fingers on the home row. As with the left side, letters are placed so that top-frequency bigrams read from right to left (ex: IO, not OI) for ease of typing. The top-frequency bigrams (more than 10 billion instances in Norvig's analysis) include: TH, ND, ST, NT, CH, NS, CT, TR, RS, NC, and RT (below 10 billion instances these bigrams start to occur in reverse, such as RT and TS): \n",
    "    \n",
    "     TH 100,272,945,963  3.56% \n",
    "     ND  38,129,777,631  1.35%\n",
    "     ST  29,704,461,829  1.05%\n",
    "     NT  29,359,771,944  1.04%\n",
    "     CH  16,854,985,236  0.60%\n",
    "     NS  14,350,320,288   \n",
    "     CT  12,997,849,406\n",
    "     TR  12,006,693,396       \n",
    "     RS  11,180,732,354   \n",
    "     NC  11,722,631,112\n",
    "     RT  10,198,055,461   \n",
    "    \n",
    "The above constraints lead to four arrangements of the consonants:\n",
    "\n",
    "    - - - -    - - - -    - - - -    - - - -\n",
    "    H T S N    H T S R    R T S N    H T N R\n",
    "    - - - -    - - - -    - - - -    - - - -\n",
    "\n",
    "We will assign the fifth consonant to a vacant key on the left home row if there is a vacancy, otherwise to the key below the right index finger (any other assignment requires the same finger to type a high-frequency bigram). The resulting 17 initial layouts, each with 15 unassigned keys, are represented below with the three rows on the left and right side of the keyboard as a linear string of letters, with unassigned keys denoted by -.\n",
    "    \n",
    "    --O- HIEA ----    ---- RTSN ----\n",
    "    --O- RIEA ----    ---- HTSN ----\n",
    "    --O- NIEA ----    ---- HTSR ----\n",
    "    --O- SIEA ----    ---- HTNR ----\n",
    "    --O- IHEA ----    ---- RTSN ----\n",
    "    --O- IREA ----    ---- HTSN ----\n",
    "    --O- INEA ----    ---- HTSR ----\n",
    "    --O- ISEA ----    ---- HTNR ----\n",
    "    --O- -IEA ----    ---- RTSN H---\n",
    "    --O- -IEA ----    ---- HTSN R---\n",
    "    --O- -IEA ----    ---- HTSR N---\n",
    "    --O- I-EA ----    ---- RTSN H---\n",
    "    --O- I-EA ----    ---- HTSN R---\n",
    "    --O- I-EA ----    ---- HTSR N---\n",
    "    ---- IOEA ----    ---- RTSN H---\n",
    "    ---- IOEA ----    ---- HTSN R---\n",
    "    ---- IOEA ----    ---- HTSR N---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Optimize assignment of the remaining letters <a name=\"step3\">\n",
    "    \n",
    "We want to assign letters to the 17 unassigned keys in each of the above 12 layouts based on our scoring model. That would mean scoring all possible arrangements for each layout and choosing the arrangement with the highest score, but since there are over 355 trillion (17!) possible ways of arranging 17 letters, we will break up the assignment into two stages for the most frequent and least frequent remaining letters. \n",
    "    \n",
    "### Most frequent letters\n",
    "We will compute scores for every possible arrangement of the seven most frequent of the remaining letters (in bold below) assigned to vacancies among the most comfortable sixteen keys.\n",
    "\n",
    "E, T, A, O, I, N, S, R, H, **L, D, C, U, M, F, P**, G, W, Y, B, V, K, X, J, Q, Z\n",
    "\n",
    "        Left:            Right:\n",
    "     -  2  3  -        - 14 15  -\n",
    "     5  6  7  8       17 18 19 20\n",
    "     9  -  - 12       21  -  - 24\n",
    "\n",
    "Since there are 5,040 (7!) possible combinations of eight letters for each of the 17 layouts, we need to score and evaluate 85,680 layouts. To score each arrangement of letters, we construct a frequency matrix where we multiply a matrix containing the frequency of each ordered pair of letters (bigram) by our flow and strength matrices to compute a score.\n",
    "    \n",
    "### Least frequent letters\n",
    "Next we will compute scores for every possible (40,320 = 8!) arrangement of the least frequent eight letters (in bold below, besides Z and Q) in the remaining keys, after substituting in the 17 results of the above for an additional 685,440 layouts:\n",
    "\n",
    "E, T, A, O, I, N, S, R, H, L, D, C, U, M, F, P, **G, W, Y, B, V, K, X, J**, Q, Z\n",
    "\n",
    "        Left:            Right:\n",
    "     1  -  -  4       13  -  - 16\n",
    "     -  -  -  -        -  -  -  -\n",
    "     - 10 11  -        - 22 23  -\n",
    "     \n",
    "### Further optimize layouts by exchanging more letters\n",
    "\n",
    "If we relax the above fixed initializations and permit further exchange of letters, then we can search for even higher-scoring layouts. As a final optimization step we exchange letters, eight keys at a time (8! = 40,320) selected twice in 14 different ways, in each of the above 17 layouts, to score a total of 19,192,320 more combinations. We allow the following keys to exchange letters:\n",
    "\n",
    "    1. Top rows\n",
    "    2. Bottom rows\n",
    "    3. Top and bottom rows on the right side\n",
    "    4. Top and bottom rows on the left side\n",
    "    5. Top right and bottom left rows\n",
    "    6. Top left and bottom right rows\n",
    "    7. Center of the top and bottom rows on both sides\n",
    "    8. The eight corners\n",
    "    9. Left half of the top and bottom rows on both sides\n",
    "    10. Right half of the top and bottom rows on both sides\n",
    "    11. Left half of non-home rows on the left and right half of the same rows on the right\n",
    "    12. Right half of non-home rows on the left and left half of the same rows on the right\n",
    "    13. Top center and lower sides\n",
    "    14. Top sides and lower center\n",
    "    15. Repeat 1-14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NOTE: This procedure takes a long time.\n",
    "\n",
    "    --O- HIEA ----    ---- RTSN ----\n",
    "    --O- RIEA ----    ---- HTSN ----\n",
    "    --O- NIEA ----    ---- HTSR ----\n",
    "    --O- SIEA ----    ---- HTNR ----\n",
    "    --O- IHEA ----    ---- RTSN ----\n",
    "    --O- IREA ----    ---- HTSN ----\n",
    "    --O- INEA ----    ---- HTSR ----\n",
    "    --O- ISEA ----    ---- HTNR ----\n",
    "    --O- -IEA ----    ---- RTSN H---\n",
    "    --O- -IEA ----    ---- HTSN R---\n",
    "    --O- -IEA ----    ---- HTSR N---\n",
    "    --O- I-EA ----    ---- RTSN H---\n",
    "    --O- I-EA ----    ---- HTSN R---\n",
    "    --O- I-EA ----    ---- HTSR N---\n",
    "    ---- IOEA ----    ---- RTSN H---\n",
    "    ---- IOEA ----    ---- HTSN R---\n",
    "    ---- IOEA ----    ---- HTSR N---\n",
    "\n",
    "\"\"\"\n",
    "fixed_letter_lists1 = [\n",
    "    ['O','H','I','E','A','R','T','S','N'],\n",
    "    ['O','R','I','E','A','H','T','S','N'],\n",
    "    ['O','N','I','E','A','H','T','S','R'],\n",
    "    ['O','S','I','E','A','H','T','N','R'],\n",
    "    ['O','I','H','E','A','R','T','S','N'],\n",
    "    ['O','I','R','E','A','H','T','S','N'],\n",
    "    ['O','I','N','E','A','H','T','S','R'],\n",
    "    ['O','I','S','E','A','H','T','N','R'],\n",
    "    ['O','I','E','A','R','T','S','N','H'],\n",
    "    ['O','I','E','A','H','T','S','N','R'],\n",
    "    ['O','I','E','A','H','T','S','R','N'],\n",
    "    ['O','I','E','A','R','T','S','N','H'],\n",
    "    ['O','I','E','A','H','T','S','N','R'],\n",
    "    ['O','I','E','A','H','T','S','R','N'],\n",
    "    ['I','O','E','A','R','T','S','N','H'],\n",
    "    ['I','O','E','A','H','T','S','N','R'],\n",
    "    ['I','O','E','A','H','T','S','R','N']]\n",
    "\n",
    "# Keys for step 1:\n",
    "#     -  2  3  -        - 14 15  -\n",
    "#     5  6  7  8       17 18 19 20\n",
    "#     9  -  - 12       21  -  - 24\n",
    "keys1  = [2,3,   5,6,7,8, 9,12,  14,15, 17,18,19,20, 21,24]\n",
    "\n",
    "# Indices for step 1:\n",
    "#     -  0  1  -        -  8  9  -\n",
    "#     2  3  4  5       10 11 12 13\n",
    "#     6  -  -  7       14  -  - 15\n",
    "fixed_letter_index_lists1 = [[1, 2,3,4,5, 10,11,12,13],\n",
    "                             [1, 2,3,4,5, 10,11,12,13],\n",
    "                             [1, 2,3,4,5, 10,11,12,13],\n",
    "                             [1, 2,3,4,5, 10,11,12,13],\n",
    "                             [1, 2,3,4,5, 10,11,12,13],\n",
    "                             [1, 2,3,4,5, 10,11,12,13],\n",
    "                             [1, 2,3,4,5, 10,11,12,13],\n",
    "                             [1, 2,3,4,5, 10,11,12,13],\n",
    "                             [1,   3,4,5, 10,11,12,13, 14],\n",
    "                             [1,   3,4,5, 10,11,12,13, 14],\n",
    "                             [1,   3,4,5, 10,11,12,13, 14],\n",
    "                             [1, 2,  4,5, 10,11,12,13, 14],\n",
    "                             [1, 2,  4,5, 10,11,12,13, 14],\n",
    "                             [1, 2,  4,5, 10,11,12,13, 14],\n",
    "                             [   2,3,4,5, 10,11,12,13, 14],\n",
    "                             [   2,3,4,5, 10,11,12,13, 14],\n",
    "                             [   2,3,4,5, 10,11,12,13, 14]]\n",
    "open_letter_index_lists1  = [[0, 6,7, 8,9, 14,15],\n",
    "                             [0, 6,7, 8,9, 14,15],\n",
    "                             [0, 6,7, 8,9, 14,15],\n",
    "                             [0, 6,7, 8,9, 14,15],\n",
    "                             [0, 6,7, 8,9, 14,15],\n",
    "                             [0, 6,7, 8,9, 14,15],\n",
    "                             [0, 6,7, 8,9, 14,15],\n",
    "                             [0, 6,7, 8,9, 14,15],\n",
    "                             [0, 2, 6,7, 8,9, 15],\n",
    "                             [0, 2, 6,7, 8,9, 15],\n",
    "                             [0, 2, 6,7, 8,9, 15],\n",
    "                             [0, 3, 6,7, 8,9, 15],\n",
    "                             [0, 3, 6,7, 8,9, 15],\n",
    "                             [0, 3, 6,7, 8,9, 15],\n",
    "                             [0,1,  6,7, 8,9, 15],\n",
    "                             [0,1,  6,7, 8,9, 15],\n",
    "                             [0,1,  6,7, 8,9, 15]]\n",
    "\n",
    "# All 24 key indices:\n",
    "#     0  1  2  3       12 13 14 15\n",
    "#     4  5  6  7       16 17 18 19\n",
    "#     8  9 10 11       20 21 22 23\n",
    "# Open indices:\n",
    "#     0  -  -  3       12  -  - 15\n",
    "#     -  -  -  -        -  -  -  -\n",
    "#     -  9 10  -        - 21 22  -\n",
    "fixed_letter_indices2 = [1,2, 4,5,6,7, 8,11, 13,14, 16,17,18,19, 20,23]\n",
    "open_letter_indices2  = [0,3, 9,10, 12,15, 21,22]\n",
    "fixed_letter_index_lists3 = [[2, 4,5,6,7, 16,17,18,19],\n",
    "                             [2, 4,5,6,7, 16,17,18,19],\n",
    "                             [2, 4,5,6,7, 16,17,18,19],\n",
    "                             [2, 4,5,6,7, 16,17,18,19],\n",
    "                             [2, 4,5,6,7, 16,17,18,19],\n",
    "                             [2, 4,5,6,7, 16,17,18,19],\n",
    "                             [2, 4,5,6,7, 16,17,18,19],\n",
    "                             [2, 4,5,6,7, 16,17,18,19],\n",
    "                             [2,   5,6,7, 16,17,18,19, 20],\n",
    "                             [2,   5,6,7, 16,17,18,19, 20],\n",
    "                             [2,   5,6,7, 16,17,18,19, 20],\n",
    "                             [2, 4,  6,7, 16,17,18,19, 20],\n",
    "                             [2, 4,  6,7, 16,17,18,19, 20],\n",
    "                             [2, 4,  6,7, 16,17,18,19, 20],\n",
    "                             [   4,5,6,7, 16,17,18,19, 20],\n",
    "                             [   4,5,6,7, 16,17,18,19, 20],\n",
    "                             [   4,5,6,7, 16,17,18,19, 20]]\n",
    "\n",
    "# Loop through initialized layouts with assigned vowels and consonants \n",
    "top_layouts = []\n",
    "nlists = len(fixed_letter_lists1)\n",
    "for ilist, fixed_letters1 in enumerate(fixed_letter_lists1):\n",
    "    #if ilist in [0,1,2,3]:\n",
    "    fixed_letter_indices1 = fixed_letter_index_lists1[ilist]\n",
    "    fixed_letter_indices3 = fixed_letter_index_lists3[ilist]\n",
    "    open_letter_indices1 = open_letter_index_lists1[ilist]\n",
    "\n",
    "    print('Layout {0}'.format(nlists))\n",
    "    print(*fixed_letters1)\n",
    "\n",
    "    # Most frequent letters\n",
    "    top_permutation1, letter_permutations1, scores1 = permute_optimize_keys(fixed_letters1, fixed_letter_indices1, \n",
    "                                                        open_letter_indices1, letters24, keys1, Factors24x24, \n",
    "                                                        bigrams, bigram_frequencies, verbose=False, ntop=0)\n",
    "\n",
    "    fixed_letters2 = top_permutation1\n",
    "\n",
    "    # Least frequent letters\n",
    "    top_permutation2, letter_permutations2, scores2 = permute_optimize_keys(fixed_letters2, fixed_letter_indices2, \n",
    "                                                        open_letter_indices2, letters24, keys24, Factors24x24, \n",
    "                                                        bigrams, bigram_frequencies, verbose=False, ntop=0)\n",
    "\n",
    "    # Further optimize layouts by exchanging more letters\n",
    "    top_permutation3 = exchange_letters(top_permutation2, fixed_letter_indices3, letters24, keys24, \n",
    "                                        Factors24x24, bigrams, bigram_frequencies, verbose=True, ntop=0)\n",
    "\n",
    "    top_layouts.append(top_permutation3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Import optimized layouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "use_above_top_layouts = False\n",
    "print_layouts = False\n",
    "if not use_above_top_layouts:\n",
    "    top_layouts = [\n",
    "    ['B','Y','O','U','H','I','E','A','V','K','J','X','L','D','G','F','R','T','S','N','C','M','W','P'],\n",
    "    ['W','Y','O','U','R','I','E','A','G','X','J','K','L','D','C','B','H','T','S','N','M','F','V','P'],\n",
    "    ['J','P','O','U','N','I','E','A','B','K','Y','X','M','C','G','V','H','T','S','R','L','D','F','W'],\n",
    "    ['J','P','O','U','S','I','E','A','G','K','Y','X','M','C','W','V','H','T','N','R','D','L','F','B'],\n",
    "    ['J','P','O','U','I','H','E','A','B','K','Y','X','L','D','G','F','R','T','S','N','C','M','V','W'],\n",
    "    ['J','W','O','U','I','R','E','A','G','X','K','Y','L','D','C','B','H','T','S','N','M','F','V','P'],\n",
    "    ['J','P','O','U','I','N','E','A','B','X','K','Y','M','C','G','V','H','T','S','R','L','D','F','W'],\n",
    "    ['J','G','O','U','I','S','E','A','P','X','K','Y','M','C','W','V','H','T','N','R','D','L','F','B'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','K','J','X','L','D','F','B','R','T','S','N','H','M','V','W'],\n",
    "    ['B','Y','O','U','C','I','E','A','G','X','J','K','L','D','W','V','H','T','S','N','R','M','F','P'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','K','J','X','M','L','F','B','H','T','S','R','N','D','V','W'],\n",
    "    ['J','G','O','U','I','C','E','A','B','X','Y','K','L','D','F','V','R','T','S','N','H','M','W','P'],\n",
    "    ['J','G','O','U','I','C','E','A','B','X','Y','K','L','D','W','V','H','T','S','N','R','M','F','P'],\n",
    "    ['P','G','O','U','I','C','E','A','K','X','J','Y','M','L','F','B','H','T','S','R','N','D','V','W'],\n",
    "    ['J','G','U','K','I','O','E','A','P','X','Y','F','L','D','V','B','R','T','S','N','H','M','C','W'],\n",
    "    ['J','G','U','X','I','O','E','A','W','K','Y','F','L','D','C','B','H','T','S','N','R','M','V','P'],\n",
    "    ['J','G','U','K','I','O','E','A','P','X','Y','F','M','L','B','W','H','T','S','R','N','D','V','C']]\n",
    "if print_layouts:\n",
    "    print('Layouts:\\n')\n",
    "    for layout in top_layouts:\n",
    "        print(layout)\n",
    "        #print(*layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank optimized layouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load code/rank_layouts.py\n",
    "layout_strings = []\n",
    "scores = []\n",
    "for layout in top_layouts:\n",
    "    layout_string = ' '.join(layout)\n",
    "    score = score_layout(Factors24x24, layout, bigrams, bigram_frequencies, verbose=False)\n",
    "    #print('    {0}    {1}'.format(layout_string, score))\n",
    "    layout_strings.append(layout_string)\n",
    "    scores.append(score)\n",
    "\n",
    "# Establish which layouts are within a small difference of the top-scoring layout \n",
    "#    - half of the smallest difference between two flow penalties, ignoring strength: (0.9^9 - 0.9^10)/2\n",
    "#    - divided by the number of key pairs: 24^2\n",
    "delta_flow = (0.9**8 - 0.9**9)\n",
    "factor = ((24**2 - 1) + (1-delta_flow)) / (24**2)\n",
    "print('    The smallest difference between two flow penalties: (0.9^8 - 0.9^9) = {0}'.format(delta_flow))\n",
    "print('    ...divided by the number of key pairs (24^2) = {0}'.format(factor))\n",
    "scores_sorted, ranks_sorted, Isort = rank_within_epsilon(scores, factor, factor=True, verbose=False)\n",
    "layouts_sorted = []\n",
    "layout_strings_sorted = []\n",
    "for i in Isort:\n",
    "    layouts_sorted.append(top_layouts[i])\n",
    "    layout_strings_sorted.append(layout_strings[i])\n",
    "print('\\nRank:   Layout                                             Score\\n')\n",
    "for i, rank in enumerate(ranks_sorted):\n",
    "    print('    {0}:  {1}    {2}'.format(rank, layout_strings_sorted[i], scores_sorted[i]))\n",
    "\n",
    "print('\\nLayouts tied for first place, with letter frequencies:\\n')\n",
    "print('Rank:   Layout                                             Score\\n')\n",
    "first_ranks = []\n",
    "first_layouts = []\n",
    "first_layout_strings = []\n",
    "first_scores = []\n",
    "for i, rank in enumerate(ranks_sorted):\n",
    "    if rank == 1:\n",
    "        first_ranks.append(rank)\n",
    "        first_layouts.append(layout_strings_sorted[i])\n",
    "        first_layout_strings.append(layouts_sorted[i])\n",
    "        first_scores.append(scores_sorted[i])    \n",
    "Isort2 = np.argsort([-x for x in first_scores])\n",
    "first_ranks_sorted = []\n",
    "first_layouts_sorted = []\n",
    "first_layout_strings_sorted = []\n",
    "first_scores_sorted = []\n",
    "for i in Isort2:\n",
    "    first_ranks_sorted.append(first_ranks[i])\n",
    "    first_layouts_sorted.append(first_layouts[i])\n",
    "    first_layout_strings_sorted.append(first_layout_strings[i])\n",
    "    first_scores_sorted.append(first_scores[i])\n",
    "for i, first_layout in enumerate(first_layouts):\n",
    "    print('    {0}:  {1}    {2}'.format(first_ranks_sorted[i], \n",
    "                                        first_layout,  # first_layout_strings_sorted[i], \n",
    "                                        first_scores_sorted[i]))\n",
    "# Print layouts:\n",
    "for i, layout_string in enumerate(first_layout_strings_sorted):\n",
    "    layout = first_layouts_sorted[i]\n",
    "    print('')\n",
    "    print_layout24(layout_string)\n",
    "    print('')\n",
    "    print_layout24_instances(layout_string, letters24, instances24, bigrams, bigram_frequencies)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized layouts after further exchange of letters\n",
    "\n",
    "The layouts generated without the not_home_row or side_top parameters have fewer than half the number of same-finger bigrams than layouts generated with those parameters, so we will proceed with the top-scoring layout among the layouts immediately below.\n",
    "\n",
    "Ranking factor:\n",
    "\n",
    "    The smallest difference between two flow penalties: (0.9^8 - 0.9^9) = 0.04304672100000001\n",
    "    ...divided by the number of key pairs (24^2) = 0.999925266109375\n",
    "\n",
    "Rank:   Layout                                             Score\n",
    "\n",
    "    1:  P Y O U C I E A G K J X L D F B R T S N H M V W    0.7079134589554652\n",
    "    1:  B Y O U C I E A G X J K L D W V H T S N R M F P    0.7078676989043136\n",
    "    2:  J G O U I C E A B X Y K L D F V R T S N H M W P    0.7078208372363046\n",
    "    2:  B Y O U H I E A V K J X L D G F R T S N C M W P    0.7078164910125013\n",
    "    2:  J G O U I C E A B X Y K L D W V H T S N R M F P    0.7077802597858632\n",
    "    3:  P Y O U C I E A G K J X M L F B H T S R N D V W    0.707765513186795\n",
    "    3:  J P O U I H E A B K Y X L D G F R T S N C M V W    0.7077426951024633\n",
    "    4:  P G O U I C E A K X J Y M L F B H T S R N D V W    0.7076779754232723\n",
    "    5:  J P O U S I E A G K Y X M C W V H T N R D L F B    0.707608035505442\n",
    "    6:  J G U K I O E A P X Y F L D V B R T S N H M C W    0.707560090465515\n",
    "    6:  W Y O U R I E A G X J K L D C B H T S N M F V P    0.7075589351593826\n",
    "    6:  J G O U I S E A P X K Y M C W V H T N R D L F B    0.707549787929756\n",
    "    6:  J G U X I O E A W K Y F L D C B H T S N R M V P    0.7075212659110061\n",
    "    7:  J W O U I R E A G X K Y L D C B H T S N M F V P    0.7074562433695609\n",
    "    7:  J P O U I N E A B X K Y M C G V H T S R L D F W    0.7074435243752765\n",
    "    7:  J P O U N I E A B K Y X M C G V H T S R L D F W    0.707432984110794\n",
    "    7:  J G U K I O E A P X Y F M L B W H T S R N D V C    0.7074108195944783\n",
    "\n",
    "Above layouts that tied for first place, with letter frequencies (2nd layout identical to Engram v2.0):\n",
    "Rank:   Layout                                             Score\n",
    "\n",
    "    1:  P Y O U C I E A G K J X L D F B R T S N H M V W    0.7079134589554652\n",
    "    1:  B Y O U C I E A G X J K L D W V H T S N R M F P    0.7078676989043136\n",
    "\n",
    "                        left: 1.73T  right: 1.83T (6.09%)\n",
    "    P Y O U  L D F B     76  59 272  97  145 136  86  53\n",
    "    C I E A  R T S N    119 270 445 287  224 331 232 258\n",
    "    G K J X  H M V W     67  19   6   8  180  90  38  60\n",
    "\n",
    "    High load: right index\n",
    "    Total same-finger bigram frequencies: 31,002,467,582\n",
    "\n",
    "\n",
    "                        left: 1.70T  right: 1.85T (8.90%)\n",
    "    B Y O U  L D W V     53  59 272  97  145 136  60  38\n",
    "    C I E A  H T S N    119 270 445 287  180 331 232 258\n",
    "    G X J K  R M F P     67   8   6  19  224  90  86  76\n",
    "\n",
    "    High load: right index\n",
    "    Total same-finger bigram frequencies: 31,422,990,907"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: rank variations of top-scoring layouts\n",
    "\n",
    "As an alternative to simply choosing the top-scoring layout, we can generate variations of this layout and find those variants within a small difference of one another and select from among these variants. For this, we select keys to vary, compute scores for every combination of the letters assigned to these keys, and select among those that are tied for first place. Below we vary those keys with different letters on the right side of the two layouts tied for first place above and some additional letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rank_variations = True\n",
    "if rank_variations:\n",
    "\n",
    "    #  P Y O U  L D F B\n",
    "    #  C I E A  R T S N\n",
    "    #  G K J X  H M V W\n",
    "\n",
    "    #  - Y O U  - D - -\n",
    "    #  C I E A  - T N S\n",
    "    #  G K J X  - M - -\n",
    "\n",
    "    fixed_letters = ['Y','O','U', 'C','I','E','A', 'G','K','J','X', 'D', 'T','N','S', 'M']\n",
    "    fixed_letter_indices = [1,2,3, 4,5,6,7, 8,9,10,11, 13, 17,18,19, 21]\n",
    "    open_letter_indices  = [0, 12,14,15, 16, 20,22,23]\n",
    "\n",
    "    top_permutation, letter_permutations, scores = permute_optimize_keys(fixed_letters, fixed_letter_indices, \n",
    "                                                        open_letter_indices, letters24, keys24, Factors24x24, \n",
    "                                                        bigrams, bigram_frequencies, verbose=False, ntop=0)\n",
    "    nletters = len(fixed_letter_indices) + len(open_letter_indices)\n",
    "    layout_variants = []\n",
    "    for ipermutation, letter_permutation in enumerate(letter_permutations):\n",
    "        letters = np.array(['E' for x in range(nletters)])  # KEEP to initialize!\n",
    "        for imove, open_letter_index in enumerate(open_letter_indices):\n",
    "            letters[open_letter_index] = letter_permutation[imove]\n",
    "        for ifixed, fixed_letter_index in enumerate(fixed_letter_indices):\n",
    "            letters[fixed_letter_index] = fixed_letters[ifixed]\n",
    "        layout_variants.append(letters)\n",
    "\n",
    "    layout_strings = []\n",
    "    for layout in layout_variants:\n",
    "        layout_string = ' '.join(layout)\n",
    "        layout_strings.append(layout_string)\n",
    "\n",
    "    scores_sorted, ranks_sorted, Isort = rank_within_epsilon(scores, factor, factor=True, verbose=False)\n",
    "    layouts_sorted = []\n",
    "    layout_strings_sorted = []\n",
    "    for i in Isort:\n",
    "        layouts_sorted.append(layout_strings[i])\n",
    "        layout_strings_sorted.append(layout_variants[i])\n",
    "\n",
    "    print('Rank:   Layout                                             Score\\n')\n",
    "    for i, rank in enumerate(ranks_sorted):\n",
    "        if rank == 1:\n",
    "            print('    {0}:  {1}    {2}'.format(rank, layouts_sorted[i], scores_sorted[i]))\n",
    "\n",
    "    # Print layouts:\n",
    "    Ifirst_place = []\n",
    "    layouts_first_place = []\n",
    "    layout_strings_first_place = []\n",
    "    for i, rank in enumerate(ranks_sorted):\n",
    "        if rank == 1:\n",
    "            layout_string = layout_strings_sorted[i]\n",
    "            layout = layouts_sorted[i]\n",
    "            print('')\n",
    "            print_layout24(layout_string)\n",
    "            print('')\n",
    "            print_layout24_instances(layout_string, letters24, instances24, bigrams, bigram_frequencies)\n",
    "\n",
    "            Ifirst_place.append(i)\n",
    "            layouts_first_place.append(layout)\n",
    "            layout_strings_first_place.append(layout_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All layouts tied for first place share the following:\n",
    "\n",
    "    - Y O U  - D - -\n",
    "    C I E A  - T N S\n",
    "    G K J X  - M - -\n",
    "\n",
    "    P Y O U  L D - -\n",
    "    C I E A  R T N S\n",
    "    G K J X  H M - -\n",
    "    \n",
    "Rank:   Layout                                             Score\n",
    "\n",
    "    1:  P Y O U C I E A G K J X L D F B R T N S H M V W    0.7078532697594836\n",
    "    1:  P Y O U C I E A G K J X L D F B R T N S H M W V    0.7078465816187631\n",
    "    1:  P Y O U C I E A G K J X L D F V R T N S H M W B    0.707843281779618\n",
    "    1:  P Y O U C I E A G K J X L D B F R T N S H M V W    0.707839898618387\n",
    "    1:  P Y O U C I E A G K J X L D B V R T N S H M W F    0.7078394052939737\n",
    "    1:  P Y O U C I E A G K J X L D B V R T N S H M F W    0.707837401869966\n",
    "    1:  P Y O U C I E A G K J X L D F V R T N S H M B W    0.7078344782483439\n",
    "    1:  P Y O U C I E A G K J X L D V B R T N S H M W F    0.7078340188188887\n",
    "    1:  P Y O U C I E A G K J X L D B F R T N S H M W V    0.7078335772655139\n",
    "    1:  P Y O U C I E A G K J X L D V B R T N S H M F W    0.7078319275403739\n",
    "    1:  P Y O U C I E A G K J X L D V F R T N S H M W B    0.7078248192431345\n",
    "    1:  P Y O U C I E A G K J X L D V F R T N S H M B W    0.7078155330483633\n",
    "    1:  B Y O U C I E A G K J X L D P F R T N S H M V W    0.7078117485234954\n",
    "    1:  B Y O U C I E A G K J X L D P V R T N S H M W F    0.7078101950525125\n",
    "    1:  B Y O U C I E A G K J X L D F V R T N S H M W P    0.7078097819698796\n",
    "    1:  B Y O U C I E A G K J X L D P V R T N S H M F W    0.7078081384714445\n",
    "    1:  B Y O U C I E A G K J X L D P F R T N S H M W V    0.7078051519586024\n",
    "    1:  P Y O U C I E A G K J X L D F W R T N S H M V B    0.7078045454062365\n",
    "\n",
    "    P Y O U  L D F B\n",
    "    C I E A  R T N S\n",
    "    G K J X  H M V W\n",
    "\n",
    "     76  59 272  97  145 136  86  53\n",
    "    119 270 445 287  224 331 258 232\n",
    "     67  19   6   8  180  90  38  60\n",
    "\n",
    "    left: 1.725T  right: 1.831T (6.09%)\n",
    "    Total same-finger bigram frequencies:     34,284,948,668\n",
    "    Total bigram inward roll frequencies:    770,118,522,869\n",
    "\n",
    "    P Y O U  L D F B\n",
    "    C I E A  R T N S\n",
    "    G K J X  H M W V\n",
    "\n",
    "     76  59 272  97  145 136  86  53\n",
    "    119 270 445 287  224 331 258 232\n",
    "     67  19   6   8  180  90  60  38\n",
    "\n",
    "    left: 1.725T  right: 1.831T (6.09%)\n",
    "    Total same-finger bigram frequencies:     33,725,499,458\n",
    "    Total bigram inward roll frequencies:    770,677,972,079\n",
    "\n",
    "    P Y O U  L D F V\n",
    "    C I E A  R T N S\n",
    "    G K J X  H M W B\n",
    "\n",
    "     76  59 272  97  145 136  86  38\n",
    "    119 270 445 287  224 331 258 232\n",
    "     67  19   6   8  180  90  60  53\n",
    "\n",
    "    left: 1.725T  right: 1.831T (6.09%)\n",
    "    Total same-finger bigram frequencies:     33,725,499,458\n",
    "    Total bigram inward roll frequencies:    770,677,972,079\n",
    "\n",
    "    P Y O U  L D B F\n",
    "    C I E A  R T N S\n",
    "    G K J X  H M V W\n",
    "\n",
    "     76  59 272  97  145 136  53  86\n",
    "    119 270 445 287  224 331 258 232\n",
    "     67  19   6   8  180  90  38  60\n",
    "\n",
    "    left: 1.725T  right: 1.831T (6.09%)\n",
    "    Total same-finger bigram frequencies:     31,806,030,022\n",
    "    Total bigram inward roll frequencies:    772,597,441,515\n",
    "\n",
    "    P Y O U  L D B V\n",
    "    C I E A  R T N S\n",
    "    G K J X  H M W F\n",
    "\n",
    "     76  59 272  97  145 136  53  38\n",
    "    119 270 445 287  224 331 258 232\n",
    "     67  19   6   8  180  90  60  86\n",
    "\n",
    "    left: 1.725T  right: 1.831T (6.09%)\n",
    "    Total same-finger bigram frequencies:     31,002,467,582\n",
    "    Total bigram inward roll frequencies:    773,401,003,955\n",
    "    \n",
    "We will choose this fifth layout tied for first place as our candidate winner, since it only differs from the original and above layouts by four letter assignments, but has the lowest number of same-finger bigrams as well as a load distribution that better matches our comfortable keys as defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Stability Tests <a name=\"step4\">\n",
    "    \n",
    "We will run three stability tests on the winning layout variants tied for first place:\n",
    "    \n",
    "    1. Compare ranking of all final layouts after removing each scoring parameter\n",
    "    2. Compare ranking of all final layouts based on interkey speed\n",
    "    3. Compare score of the winning layout after rearranging random letters \n",
    "\n",
    "In the first test we remove each Engram scoring parameter one at a time and rescore all of the final layouts to see if this affects their ranking. In the second test, we rescore all of the final layouts, replacing the factor matrix with either the flow matrix or the inter-key speed matrix to see if this affects their ranking. The third test is to see if rearranging random sets of eight of the 16 non-initialized letters in every possible combination improves the score of the winning layout. We repeat this test 1,000 times (up to 40,320,000 combinations).\n",
    "\n",
    "### Stability Test 1: Compare ranking of all final layouts after removing each scoring parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rank_variations:\n",
    "    test_layouts = layouts_first_place\n",
    "    test_layout_strings = layout_strings_first_place\n",
    "else:\n",
    "    test_layouts = top_layouts    \n",
    "    test_layout_strings = top_layouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load code/test/remove_parameters_rescore.py\n",
    "params0 = [side_above_3away, side_above_2away, side_above_1away, middle_above_ring, ring_above_middle, \n",
    "           outward, skip_row_3away, skip_row_2away, skip_row_1away, skip_row_0away, same_finger]\n",
    "param_names = ['side_above_3away', 'side_above_2away', 'side_above_1away', \n",
    "               'middle_above_ring', 'ring_above_middle', 'outward', 'skip_row_3away', \n",
    "               'skip_row_2away', 'skip_row_1away', 'skip_row_0away', 'same_finger']\n",
    "params_lists = []\n",
    "for i in range(len(params0)):\n",
    "    params_list = params0.copy()\n",
    "    params_list[i] = 1.0\n",
    "    params_lists.append(params_list)\n",
    "\n",
    "for iparam, P in enumerate(params_lists):\n",
    "\n",
    "    print('\\nRemove parameter {0}:'.format(param_names[iparam]))\n",
    "\n",
    "    data_matrix_param = create_24x24_flow_matrix(not_home_row, side_top,\n",
    "                                                 P[0],P[1],P[2],P[3],P[4],P[5],P[6],P[7],P[8],P[9],P[10],\n",
    "                                                 1,1,1,1,1,1)\n",
    "    if apply_strength:\n",
    "        data_matrix_param = Strength24x24 * data_matrix_param\n",
    "\n",
    "    param_scores = []\n",
    "    for letters in test_layout_strings:\n",
    "        score = score_layout(data_matrix_param, letters, bigrams, bigram_frequencies, verbose=False);\n",
    "        param_scores.append(score)\n",
    "            \n",
    "    param_scores_sorted, param_ranks_sorted, Isort_param = rank_within_epsilon(param_scores, factor, factor=True, verbose=False)\n",
    "    param_layouts_sorted = []\n",
    "    param_layout_strings_sorted = []\n",
    "    for i in Isort_param:\n",
    "        param_layouts_sorted.append(test_layouts[i])\n",
    "        param_layout_strings_sorted.append(test_layout_strings[i])\n",
    "\n",
    "    print('Rank:   Layout                                             Score\\n')\n",
    "    for i, rank in enumerate(param_ranks_sorted):\n",
    "        if rank == 1:\n",
    "            if rank_variations:\n",
    "                print('    {0}:  {1}    {2}'.format(rank, layouts_first_place[i], param_scores_sorted[i]))\n",
    "            else:\n",
    "                print('    {0}:  {1}    {2}'.format(rank, layout_strings_sorted[i], param_scores_sorted[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Stability Test 1 results: \n",
    "\n",
    "We removed each of 12 scoring parameters one by one and ranked the new scores for the 17 top-scoring layouts, and the selected layout remained tied for first place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Stability Test 2: Compare ranking of all final layouts based on strength and interkey speed\n",
    "\n",
    "The strength matrix is calculated above and references a publication documenting \n",
    "measured finger strengths relevant for typing.\n",
    "\n",
    "The speed matrix contains left-right averaged versions of the normalized interkey stroke times derived from the study (averaged to compensate for right-handedness of participants in the study):\n",
    "\n",
    "\"Estimation of digraph costs for keyboard layout optimization\", \n",
    "A Iseri, Ma Eksioglu, International Journal of Industrial Ergonomics, 48, 127-138, 2015.\n",
    "\n",
    "To establish which layouts are within a negligible difference of each other after replacing Factors24x24 with the speed matrix, we define an epsilon of 24.3 ms for a single bigram (of the 24^2 possible bigrams), one tenth of the range of times recorded in the study above, which is less than a quarter of the fastest measured digraph tapping speed (30,000/228 = 131.58 ms) recorded in that study:\n",
    "\n",
    "    \"Digraph-tapping rate changes dramatically across the digraph types. The range is between 82 and 228 taps per 30 s. The difference is nearly three times between the slowest and the fastest digraphs. From this result it can be concluded that the assignment of letter pairs on the correct digraph keys on the keyboard can have a high impact on the typing speed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load code/test/score_strength_of_layouts.py\n",
    "data_matrix_strength = Strength24x24\n",
    "strength_scores = []\n",
    "for letters in test_layout_strings:\n",
    "    score = score_layout(data_matrix_strength, letters,  bigrams, bigram_frequencies, verbose = False) \n",
    "    strength_scores.append(score)\n",
    "\n",
    "strength_scores_sorted, strength_ranks_sorted, Isort_strength = rank_within_epsilon(strength_scores, \n",
    "                                                                    factor, factor=True, verbose=False)\n",
    "print('\\nRank:   Layout                                             Strength score        Score\\n')\n",
    "for i, rank in enumerate(strength_ranks_sorted):\n",
    "    if rank == 1:\n",
    "        print('    {0}:  {1}    {2}'.format(rank, test_layouts[Isort_strength[i]], \n",
    "                                            strength_scores_sorted[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load code/test/score_speed_of_layouts.py\n",
    "data_matrix_speed = Speed24x24\n",
    "\n",
    "print('epsilon    = {0}'.format(epsilon))\n",
    "\n",
    "speed_scores = []\n",
    "for letters in test_layout_strings:\n",
    "    score = score_layout(data_matrix_speed, letters,  bigrams, bigram_frequencies, verbose = False) \n",
    "    speed_scores.append(score)\n",
    "\n",
    "speed_scores_sorted, speed_ranks_sorted, Isort_speed = rank_within_epsilon(speed_scores, epsilon, factor=False, verbose=False)\n",
    "\n",
    "print('\\nRank:   Layout                                             Speed score           Score\\n')\n",
    "for i, rank in enumerate(speed_ranks_sorted):\n",
    "    if rank == 1:\n",
    "        print('    {0}:  {1}    {2}'.format(rank, test_layouts[Isort_speed[i]], \n",
    "                                            speed_scores_sorted[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stability Test 2 results: \n",
    "\n",
    "The candidate layout is tied for first place after replacing Factors24x24 with the strength or speed matrix and re-ranking the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign letters Z and Q and test left/right swap\n",
    "\n",
    "Test to see if equal or higher scores are obtained for the following:\n",
    "\n",
    "    1. Assign Z and either Q or J to keys 112 and 113\n",
    "    2. Swap left and right sides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layouts_26letters = [\n",
    "    ['P','Y','O','U','C','I','E','A','G','K','J','X','L','D','B','V','R','T','N','S','H','M','W','F', \"'\",',','-', '\"','.','?', 'Z','Q'],\n",
    "    ['P','Y','O','U','C','I','E','A','G','K','J','X','L','D','B','V','R','T','N','S','H','M','W','F', \"'\",',','-', '\"','.','?', 'Q','Z'],\n",
    "    ['V','B','D','L','S','N','T','R','F','W','M','H','U','O','Y','P','A','E','I','C','X','J','K','G', \"'\",',','-', '\"','.','?', 'Z','Q'],\n",
    "    ['V','B','D','L','S','N','T','R','F','W','M','H','U','O','Y','P','A','E','I','C','X','J','K','G', \"'\",',','-', '\"','.','?', 'Q','Z']]\n",
    "data_matrix = Factors32x32\n",
    "scores_26letters = []\n",
    "for layout_26letters in layouts_26letters:\n",
    "    scores_26letters.append(score_layout(data_matrix, layout_26letters, bigrams, bigram_frequencies, verbose=False))\n",
    "\n",
    "scores_26letters_sorted, ranks_26letters_sorted, Isort_26letters = rank_within_epsilon(scores_26letters, \n",
    "                                                                        factor, factor=True, verbose=False)\n",
    "print('\\nRank:   Layout                                             Score\\n')\n",
    "for i, rank in enumerate(ranks_26letters_sorted):\n",
    "    layout = ' '.join(layouts_26letters[Isort_26letters[i]])\n",
    "    print('    {0}:  {1}    {2}'.format(rank, layout, scores_26letters_sorted[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All layouts tied for first place:\n",
    "\n",
    "    Rank                                                                   Score\n",
    "    1:  P Y O U C I E A G K J X L D B V R T N S H M W F ' , - \" . ? Q Z    0.616907977127662\n",
    "    1:  P Y O U C I E A G K J X L D B V R T N S H M W F ' , - \" . ? Z Q    0.6169079014104276\n",
    "    1:  V B D L S N T R F W M H U O Y P A E I C X J K G ' , - \" . ? Q Z    0.6169026556983308\n",
    "    1:  V B D L S N T R F W M H U O Y P A E I C X J K G ' , - \" . ? Z Q    0.6168954862757922\n",
    "    \n",
    "We will declare the first the winner:\n",
    "\n",
    "    P Y O U  L D B V Q\n",
    "    C I E A  R T N S Z\n",
    "    G K J X  H M W F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner24 = ['P','Y','O','U','C','I','E','A','G','K','J','X','L','D','B','V','R','T','N','S','H','M','W','F']\n",
    "winner32 = ['P','Y','O','U','C','I','E','A','G','K','J','X','L','D','B','V','R','T','N','S','H','M','W','F', \"'\",',','-', '\"','.','?', 'Z','Q']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stability Test 3. Compare score of the winning layout after rearranging random letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_test3 = False\n",
    "if run_test3:\n",
    "    original_score = score_layout(Factors24x24, winner24, bigrams, bigram_frequencies, verbose=False) \n",
    "    nunber_of_tests = 1000\n",
    "    size_random_set = 8\n",
    "    indices = [0,1,2,3, 8,9,10, 12,14,15, 19, 20,21,22,23]\n",
    "    #  0  1  2  3       12  - 14 15\n",
    "    #  -  -  -  -        -  -  - 19\n",
    "    #  8  9 10  -       20 21 22 23\n",
    "\n",
    "    print(original_score)\n",
    "\n",
    "    for i in range(nunber_of_tests):\n",
    "        letters_copy = winner24.copy()    \n",
    "        random_indices = []\n",
    "        while np.size(random_indices) < size_random_set:\n",
    "            random_index = indices[np.int( np.round( (np.size(indices) - 1) * np.random.random(1) )[0])]\n",
    "            if random_index not in random_indices:\n",
    "                random_indices.append(random_index)   \n",
    "        for irand in random_indices:\n",
    "            letters_copy[np.int(irand)] = ''\n",
    "\n",
    "        top_permutation_test1, letter_permutations_test1, scores_test1 = permute_optimize(letters_copy, \n",
    "                            letters24, keys24, Factors24x24, bigrams, bigram_frequencies, verbose=False, ntop=0)\n",
    "\n",
    "        print(i)\n",
    "        if ''.join(top_permutation_test1) != ''.join(winner24) and max(scores_test1) > original_score:\n",
    "            print(max(scores_test1))\n",
    "            print(*top_permutation_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TPW3wZw2DzT7"
   },
   "source": [
    "## Step 5: Arrange non-letter characters in easy-to-remember places <a name=\"step5\">\n",
    "    \n",
    "Now that we have all 26 letters accounted for, we turn our attention to non-letter characters, taking into account frequency of punctuation and ease of recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "ul_j8VsZDzT7"
   },
   "source": [
    "### Frequency of punctuation marks\n",
    "\n",
    "  - Statistical values of punctuation frequency in 20 English-speaking countries (Table 1): <br>\n",
    "Sun, Kun & Wang, Rong. (2018). Frequency Distributions of Punctuation Marks in English: Evidence from Large-scale Corpora. English Today. 10.1017/S0266078418000512. <br> \n",
    "https://www.researchgate.net/publication/328512136_Frequency_Distributions_of_Punctuation_Marks_in_English_Evidence_from_Large-scale_Corpora\n",
    "  <br>\"frequency of punctuation marks attested for twenty English-speaking countries and regions... The data were acquired through GloWbE.\"\n",
    "  \"The corpus of GloWbE (2013) is a large English corpus collecting international English from the internet, containing about 1.9 billion words of text from twenty different countries. For further information on the corpora used, see https://corpus.byu.edu/.\"\n",
    "  \n",
    "  - Google N-grams and Twitter analysis: <br>\n",
    "\"Punctuation Input on Touchscreen Keyboards: Analyzing Frequency of Use and Costs\" <br>\n",
    "S Malik, L Findlater - College Park: The Human-Computer Interaction Lab. 2013 <br>\n",
    "https://www.cs.umd.edu/sites/default/files/scholarly_papers/Malik.pdf <br>\n",
    " \"the Twitter corpora included substantially higher punctuation use than the Google corpus,  <br>\n",
    " comprising 7.5% of characters in the mobile tweets and 7.6% in desktop versus only 4.4%...  <br>\n",
    "With the Google corpus,only 6 punctuation symbols (. - ( ) ) appeared more frequently than [q]\"\n",
    "\n",
    "  - \"Frequencies for English Punctuation Marks\" by Vivian Cook <br>\n",
    "http://www.viviancook.uk/Punctuation/PunctFigs.htm  <br>\n",
    " \"Based on a writing system corpus some 459 thousand words long.  <br> \n",
    " This includes three novels of different types (276 thousand words),  <br>\n",
    " selections of articles from two newspapers (55 thousand), <br> \n",
    "one bureaucratic report (94 thousand), and assorted academic papers <br>\n",
    "on language topics (34 thousand). More information is in <br>\n",
    "Cook, V.J. (2013) Standard punctuation and the punctuation of the street <br>\n",
    "in M. Pawlak and L. Aronin (eds.), Essential Topics in Applied Linguistics and Multilingualism,  <br>\n",
    " Springer International Publishing Switzerland (2013), 267-290\"\n",
    "\n",
    "  - \"A Statistical Study of Current Usage in Punctuation\": <br>\n",
    "Ruhlen, H., & Pressey, S. (1924). A Statistical Study of Current Usage in Punctuation. The English Journal, 13(5), 325-331. doi:10.2307/802253\n",
    "\n",
    "  - \"Computer Languages Character Frequency\"\n",
    "by Xah Lee.  <br>\n",
    "Date: 2013-05-23. Last updated: 2020-06-29. <br>\n",
    "http://xahlee.info/comp/computer_language_char_distribution.html <br>\n",
    "NOTE: biased toward C (19.8%) and Py (18.5%), which have high use of \"_\".\n",
    "\n",
    "Frequency: \n",
    "\n",
    "             Sun:     Malik:   Ruhlen:    Cook:            Xah:\n",
    "              /1M   N-gram %   /10,000   /1,000       All%  JS%   Py%\n",
    "\n",
    "    .    42840.02      1.151       535     65.3       6.6   9.4  10.3\n",
    "    ,    44189.96                  556     61.6       5.8   8.9   7.5\n",
    "    \"                  2.284        44     26.7       3.9   1.6   6.2\n",
    "    '     2980.35      0.200        40     24.3       4.4   4.0   8.6\n",
    "    -     9529.78      0.217        21     15.3       4.1   1.9   3.0\n",
    "    ()    4500.81      0.140         7                7.4   9.8   8.1\n",
    "    ;     1355.22      0.096        22      3.2       3.8   8.6\n",
    "    z                  0.09                   -         -\n",
    "    :     3221.82      0.087        11      3.4       3.5   2.8   4.7\n",
    "    ?     4154.78      0.032        14      5.6       0.3\n",
    "    /                  0.019                          4.0   4.9   1.1\n",
    "    !     2057.22      0.013         3      3.3       0.4\n",
    "    _                  0.001                         11.0   2.9  10.5\n",
    "    =                                                 4.4  10.7   5.4\n",
    "    *                                                 3.6   2.1\n",
    "    >                                                 3.0         1.4\n",
    "    $                                                 2.7   1.6\n",
    "    #                                                 2.2         3.2\n",
    "    {}                                                1.9   4.2\n",
    "    <                                                 1.3\n",
    "    &                                                 1.3\n",
    "    \\                                                 1.2         1.1\n",
    "    []                                                0.9   1.9   1.2\n",
    "    @                                                 0.8\n",
    "    |                                                 0.6\n",
    "    +                                                 0.6   1.9\n",
    "    %                                                 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sdl3lLOfDzT8"
   },
   "source": [
    "### Add punctuation keys and number keys\n",
    "\n",
    "We will assign the most frequent punctuation according to Sun, et al (2018) to the six keys in the middle two columns:  . , \" ' - ? ; : () ! _\n",
    "\n",
    "            P Y O U  '   \"   L D B V Q\n",
    "            C I E A  ,   .   R T N S Z\n",
    "            G K J X  -   ?   H M W F\n",
    "\n",
    "We will use the Shift key to group similar punctuation marks (separating and joining marks in the left middle column and closing marks in the right middle column):\n",
    "\n",
    "            P Y O U  '(  \")  L D B V Q\n",
    "            C I E A  ,;  .:  R T N S Z\n",
    "            G K J X  -_  ?!  H M W F\n",
    " \n",
    "**Separating marks (left)**: The comma separates text in lists; the semicolon can be used in place of the comma to separate items in a list (especially if these items contain commas); open parenthesis sets off an explanatory word, phrase, or sentence. \n",
    "\n",
    "**Joining marks (left)**: The apostrophe joins words as contractions; the hyphen joins words as compounds; the underscore joins words in cases where whitespace characters are not permitted (such as in variables or file names). \n",
    "\n",
    "**Closing marks (right)**: A sentence usually ends with a period, question mark, or exclamation mark. The colon ends one statement but precedes the following: an explanation, quotation, list, etc. Double quotes and close parenthesis closes a word, clause, or sentence separated by an open parenthesis.\n",
    "\n",
    "**Number keys**: \n",
    "The numbers are flanked to the left and right by [square brackets], and {curly brackets} accessed by the Shift key. Each of the numbers is paired with a mathematical or logic symbol accessed by the Shift key:\n",
    "    \n",
    "    { | = ~ +   <  >   ^ & % * } \\\n",
    "    [ 1 2 3 4   5  6   7 8 9 0 ] /\n",
    "\n",
    "    1: | (vertical bar or \"pipe\" represents the logical OR operator: 1 stroke, looks like the number one)\n",
    "    2: = (equal: 2 strokes, like the Chinese character for \"2\")\n",
    "    3: ~ (tilde: \"almost equal\", often written with 3 strokes, like the Chinese character for \"3\")\n",
    "    4: + (plus: has four quadrants; resembles \"4\")\n",
    "    5 & 6: < > (\"less/greater than\"; these angle brackets are directly above the other bracket keys)\n",
    "    7: ^ (caret for logical XOR operator as well as exponentiation; resembles \"7\")\n",
    "    8: & (ampersand: logical AND operator; resembles \"8\")\n",
    "    9: % (percent: related to division; resembles \"9\")\n",
    "    0: * (asterisk: for multiplication; resembles \"0\") \n",
    "\n",
    "The three remaining keys in many common keyboards (flanking the upper right hand corner Backspace key) are displaced in special keyboards, such as the Kinesis Advantage and Ergodox. For the top right key, we will assign the forward slash and backslash: / \\\\. For the remaining two keys, we will assign two symbols that in modern usage have significance in social media: the hash/pound sign and the \"at sign\". The hash or hashtag identifies digital content on a specific topic (the Shift key accesses the dollar sign). The \"at sign\" identifies a location or affiliation (such as in email addresses) and acts as a \"handle\" to identify users in popular social media platforms and online forums.\n",
    "\n",
    "The resulting Engram layout:\n",
    "\n",
    "          { | = ~ +   <  >   ^ & % * } \\\n",
    "          [ 1 2 3 4   5  6   7 8 9 0 ] /\n",
    "\n",
    "            P Y O U  '(  \")  L D B V Q\n",
    "            C I E A  ,;  .:  R T N S Z\n",
    "            G K J X  -_  ?!  H M W F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "engram-layout.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
